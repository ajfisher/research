slug,title,tags,text,predicted_tags,top5_tags,top5_probs,candidate_missing_from_top5,low_confidence_actual_tags,missing_tags,potential_misapplied_tags,has_tags,predicted_positive
2007-02-15-please-nokia-slap-me-again-no-really.md,Please nokia slap me again - no really,"['business', 'mobile', 'nokia']","Please nokia slap me again - no really
I love Nokia phones. In fact you could probably say that I have had a love
affair with Nokia devices for over the last 10 years ever since my first one. Typically they sum up everything that is important to me about technology -
that it must look great and must function well too. Nokia just always seem to
push my buttons when it comes to putting down my cash and getting a new phone.
Don't get me wrong, I've dabbled with the dark side of Ericsson and then Sony
Ericsson, I'd love to love a Motorola - really I would, but there is just
something about that Finnish company that every 12 months when it's time for an
upgrade makes me want to give them another chance. Over the last few years, incredibly though, their products have got worse... My last three phones have been a 6600, an 7710 and now an N73. Every one of these have had internet, bluetooth, big screens, cameras and all
the usual gubbins. Why then have they got progressively worse in terms of functions? My 6600 had terrible battery and would often crash. My 7710 had great battery,
would often crash and didn't support most web page content even though it was a
wide screen touchscreen that was supposed to have a fully featured web browser. My n73 is even worse, admittedly though the Carl Zeiss lense on the 3mp camera
is a piece of art and takes crystal clear photos. The web browser is much
improved thanks to the Mozilla engine and the 3G connection I have which
renders web pages at high speed. The battery life is awesome as well. The only
problem with this one is that I can't make or receive phone calls without it
crashing - literally to a black screen of death - about 80% of the time. Vodafone won't acknowledge a problem because Nokia won't so there's no sending
it back - I pity everyone who has tried and had their phone returned a couple
of weeks later saying ""there's no problem"". It isn't just me either check this
out in google:
[http://www.google.co.uk/search?hl=en&q=problems+nokia+N73+crash&meta](http://www.google.co.uk/search?hl=en&q=problems+nokia+N73+crash&meta)
and you'll see the extent of the problem. So taking a punt before xmas I bought an n770 internet tablet. Again a fine and
beautiful bit of kit, but again with it's fair share of bugs - not least a
*very* buggy version of opera which Nokia has decided not to support any more,
leaving it's internet tablet with a very bad internet web browser - ouch - 250
quid not well spent... well at least I can[ make a robot out of
it](http://www.pocketpicks.co.uk/latest/index.php/2007/01/17/meet-the-puppy-robot-with-a-nokia-770-tablet-for-a-head/). So I'm looking around again and I know that just like a jilted lover who
somehow thinks that ""things will be different this time"" I'll be back at
Nokia's bosum probably with an N95 in my hand... mmmm just look at the screen
and the slidey-outy-bit... 5mp camera, 3G with 11 GPRS slots for quick
downloading... I really don't need to make a phone call.","['business', 'mobile', 'nokia']","['mobile', 'business', 'nokia', 'web', 'development']","[0.6388046854473928, 0.6019687120344541, 0.5859533802903255, 0.31919495389719665, 0.3088934448970427]","['development', 'web']",[],[],[],True,3
2007-03-05-fuzzys-where-its-at-or-will-be-eventually.md,Fuzzy's where it's at... or will be eventually,"['algorithms', 'ecommerce', 'retail']","Fuzzy's where it's at... or will be eventually
I'm working on a project at the moment that took a remarkable turn recently.
Most clients we work on are fairly staid in their use of technology - which
suits our company as we are firm believers of the Keep It Simple Stupid
methodology of programming. I was in a meeting with a client who is a large retailer and we were talking
about ""filters"" for being able to reduce sets of data returned from the database.
Things like ""style"", ""size"", ""price"" etc - not dissimilar to
[Dabs](http://www.dabs.com) or any one of a thousand other online retailers.
Off the cuff I just said ""wouldn't it be good to use fuzzy logic on the filters
so instead of black and white result you get the shades of grey as well"". To be
honest I'm not even sure why I mentioned it... Imagine my surprise when the client said ""Show me""... Out came the pen and
paper and 15 minutes later he was sold on the idea and I was left to code an example. Fuzzy logic is a funny old beast - it is based around this notion that instead
of black and white you deal in shades of grey - black and white are just
extreme examples of the shades of gray. So <b>black might equal 0 and white might
be 1 but in between we can have 0.5 or even 0.3218956</b> if you so desire...
everything belongs to every group at least in part - even if that part is tiny,
or even 0. I love fuzzy logic - I played with it a lot at Uni when I was studying Neural
Networks - but it has never made it into mainstream web use - mostly because
it is so difficult to implement with a database unless you do a lot of extra
background work. Background work most clients won't pay for. It does make a big difference though - take this as an example: Say you have two products, Product A is £295 and Product B is £305. Now suppose you have a filter, or a search query that says ""Give me everything
less than £300"" Obviously Product A gets returned but Product B wont if you are using discrete
maths as it isn't 100% lower than £300. In the fuzzy view of the world though we can say ""Give me everything
approximately less than £300"". Now <b>depending on your exact specification of
what ""approximately"" means Product B may well be returned</b>. Indeed most people
prepared to spend £300 will probably spend £320 so we could say Product B has a
95% fit for this result. As we get closer to £320 the relevance gets less so it
is less likely to be returned. Ahh, I hear you say, I can do this by just pushing my filter up. Yes you can but
then £321 is left out altogether again. Maybe £321 is not as relevant as £305
but it is more or less as relevant as £320 on this scale. Fuzzy logic has made huge strides in engineering particularly with control
systems for things like washing machines (if a load is heavy use more water,
if light use less) and airconditioning units (if it is hot turn on harder than
if I am more or less where I need to be) but it has never caught on big time
on the web. I think that now that fundamental systems are starting to get in place
(e-commerce etc is nowhere near as difficult as it used to be) then we will
start seeing clients and programmers starting to use their brains a bit more
and looking at how we can deliver the best experience for our customers.","['algorithms', 'ecommerce', 'retail']","['algorithms', 'retail', 'ecommerce', 'web', 'development']","[0.5895715453266043, 0.5873653501030803, 0.5855298598824135, 0.3308451924520318, 0.314650914158283]","['development', 'web']",[],[],[],True,3
2007-04-23-why-is-css-such-a-painful-tool.md,Why is CSS such a painful tool?,"['css', 'development', 'standards']","Why is CSS such a painful tool?
Looking at the title above you'd be expecting to see a rant covering the lines of CSS is rubbish, it doesn't work properly and why can't we go back to the days of nested tables and lots of little shim images. I love CSS though, I love the fact that I don't need an editor to edit code any more [trying to do complex layouts in the past it was mandatory to use Dreamweaver to get any degree of speed], I adore that my code is more or less semantically correct and that it searches well. Being a techie and advising people on hosting I also love the fact that all that bandwidth isn't being wasted on buffer code in HTML to do trivial layouts that isn't then cached. We all know CSS has it's quirks, particularly in IE but the one thing that gets on my goat more than anything else with CSS is that it is a layout language developed by a bunch of people that aren't programmers or designers. They are wannabe web typographists who happen to have the time to come up with and enhance a spec that the rest of us are then forced to use. This gripe raises its head with me every once in a while but really badly today. This is because we're developing a site that is really thematic in terms of look and feel and the various sections really have their own colour coding. The overall behaviour is the same from one section to another in order to maintain consistency but things like backgrounds, titles and link colours shift to the new pallette. The really painful thing with this is the inevitable rehashing of styles down the page - particularly if it is a really stylised design with a lot of lines in it etc. You find yourself constantly typing the same border: 1px solid #123456 or color: #abcdef over and over again. Then when you are in a new section all these items have to be re-instantiated. What I would give for some variables - say something like this: Then in my CSS I could generate a selector and then apply the relevant style variable. I wouldn't even need any conditional logic to be happy just a quick and dirty token replacement function to make it work. Admittedly I could set this up by just making a CSS file a PHP file instead and returning text/css instead of text/html etc but what happens if I'm using ASP or I have to do something that is just quick and dirty HTML for a couple of pages... or what about the performance hit if my site is serving up 1000 page views a minute [or more]. As a CSS advocate I tell people that it is faster to dish pages with CSS as it is cached, but then this method will kill most caching strategies. We're now at the point where even if this was something that was deemed as being useful by the [W3C](http://www.w3c.org) powers that be we won't see it incorporated until at least the CSS 3.0 spec - which should be coming to a web browser near you some time about 2011/12 and probably won't have wide support until about 2015 - if [NASA have their way](http://www.nasa.gov/home/hqnews/2006/dec/HQ_06361_ESMD_Lunar_Architecture.html) they'll almost have landed a man on the moon again by then! So please, W3C - we are in this mire because of a lack of consulation of developers who are implementing the standards you set out. Perhaps getting a development edition of a browser that incorporates these standards at an early stage so they can be played with would be a good direction of resources for the next phase of growth...","['css', 'development', 'standards']","['development', 'css', 'standards', 'web', 'media']","[0.6368813260112796, 0.6034664805914554, 0.5996371042493344, 0.34097417836715227, 0.30559134411778427]","['media', 'web']",[],[],[],True,3
2007-04-24-the-things-we-take-for-granted.md,The things we take for granted,"['design', 'ux']","The things we take for granted
I had one of those amazing moments as a techie last night where you get so gobsmacked by something that you think about it even a day or so later. I was doing something on a mate's computer. Fair enough he isn't the most computer literate person in the world but he gets by - he's online and uses the web, email etc to get things done - he's even bought things online too. So he falls firmly in the ""average user"" category - certainly into the definition of the average use we use when we spec out systems and I'd say anyone that works at a software house or digital agency would look at Dean in the same way. So what gobsmacked me? The scroll wheel on his mouse... I was editing a large file for him and scrolling quickly up and down using either the scroll wheel to flick me around the document or doing that windows thing where you depress the button and flick the mouse and you start scanning the document up or down at various speeds. Dean was sitting there amazed and just said ""I had no idea you could do that"". Initially I thought he was talking about the editing in the config file I was hacking but it turns out he didn't even realise there was a little wheel in there - as far as he was concerned it was a place to rest his finger and was part of the design of the mouse. This got me thinking about all these things we as techies take for granted - not the big things like being able to get your email on your mobile phone or being able to mashup 10 different data sources to produce something new and novel or even build a website from scratch using nothing but a text editor. I'm talking about things like people not knowing their mice can do different things, that your phone probably can browse the web as well as make calls. My wife still can't even write a text message. I come across people even now who don't have internet connections and plenty who are still on dialup. As our industry grows, how does this moving ""average user"" impact on the people who are below average? Do we create a digital divide not necessarily based on the ""haves and have nots"" but on the basis of ""cans and cannots""? Seeing things like this has made me wonder again about people's perception and their interaction with their computing environment. I remember sitting in on a user testing session way back and seeing someone have one of those moments where they ""got"" the way the web worked - you could tell because she said ""That's why that text has a line under it - I always wondered about that"". Anyone who's got a relli who is a timid computer user knows that they don't do things with it because they are afraid they'll break it. Trying to get them to do anything outside their comfort zone is really difficult. With computers getting cheaper and cheaper and the next influx of users coming on board, we that build systems and interfaces must be sure to remember that the ""average user"" isn't getting smarter or more stupid - they will initially be less experienced and turning away these less experienced users may result in less traffic / sales whatever further down the line if someone else comes along that will hold their hand and guide them through the process. In 10-15 years this won't be an issue - but it is now.","['design', 'ux']","['ux', 'design', 'web', 'media', 'rant']","[0.5886016637843664, 0.5856018685262006, 0.32665845699947554, 0.3149572377380856, 0.309075511898087]","['media', 'rant', 'web']",[],[],[],True,2
2007-04-29-when-css-goes-bad.md,When CSS goes bad,"['css', 'development', 'standards']","When CSS goes bad
If you do a lot of CSS work you'll have seen particular bugs time after time and how to deal with them, however when things do go wrong [and they will trust me] finding bug related information can be a nightmare. For instance, today I was doing some work on a site and it has had a bug for a few days now in IE. The typical peekaboo bug - if you haven't seen it, it is typically an IE6 thing whereby you rollover a link or element set to have a :hover state and then as well as the effect you want [bgcolor changing for example] something else happens too. In my case I was rolling over a navigation item which then duly changed colour and then chopped off the page at the bottom of the screen. Even more interestingly it only did it when I had my secondary [nested] navigation up. If it was only the primary it didn't do it. More interesting again was that when I had the two navs up, mousing over the primary one caused the page to disappear and mousing over the secondary caused the page to reappear... argh. Needless to say with a bug and change list spanning a couple sheets of A4 this was just left for a while. A quick google for [peekaboo bug](http://www.google.co.uk/search?hl=en&q=peekaboo+bug&meta=) didn't net much that was useful. Same with [position is everything](http://www.positioniseverything.net) - and this is the problem - nomeclature of bugs and their effects can be so difficult to find in CSS as you have a mix of designers, researchers and techies all calling things different things. Typically my best bet has always been to try and describe the effect in as many different ways as possible on the basis of matching someone elses exact phrasing - as you can imagine this is like trying to hit a dart board on the moon from Earth with your eyes closed. Perhaps someone will sit down and come up with an accurate way of dealing with web browser bugs that classifies them much like we have with CERT [Computer Emergency Response Team] who [classify vulnerabilities](http://www.kb.cert.org/vuls/) in OSes and Software. This would make life a lot easier when a bug was found, especially when it is a variation on an existing one like the peekaboo one I had this morning. In the end the document which helped me out was this one - [http://www.satzansatz.de/cssd/onhavinglayout.html](http://www.satzansatz.de/cssd/onhavinglayout.html) although it did take some trial and error to work out which element needed to have it applied. It works fine now though and my bug / change list is down under a page which is even better....","['css', 'development', 'standards']","['development', 'css', 'standards', 'web', 'mobile']","[0.6413273964850046, 0.5958651295194097, 0.5948450417280965, 0.3425397476663008, 0.3037440092501155]","['mobile', 'web']",[],[],[],True,3
2007-04-30-super-computer-required-to-simulate-half-a-mouse-brain.md,Super computer required to simulate half a mouse brain,"['ai', 'supercomputers']","Super computer required to simulate half a mouse brain
Scientists have published that the've used the [IBM Blue Gene L supercomputer](http://www.llnl.gov/asc/computing_resources/bluegenel/bluegene_home.html) to simulate half of a typical mouse's brain. More accurately they've simulated about half the neurons and just over half the number of synaptic connections for 10 seconds - which because the simulation was running at about a tenth of normal speed showed about 1 second's worth of realtime information. You can read the whole story [here](http://news.bbc.co.uk/1/hi/technology/6600965.stm) Don't get me wrong, the guys at Nevada Uni have my utmost respect. I studied a lot about cognition and neural networks when I was at Uni, in fact I specialised in it with a degree in Computer Science and Psychology so I have a fair grasp of how hard this is to do. What gets me going though is the reasons behind doing it. As can be seen here, [the top Supercomputer](http://www.top500.org/lists/2006/11) in the world can be brought to its knees by modelling half a mouse brain for a very limited period of time. The reason for this is the sheer number of connections (synapses) that occur between neurons - a single neuron in a mouse can influence the behaviour of about 8,000 other neurons. It doesn't take long for the cascade to build up and your computations to start slowing down. What I find most interesting is that Blue Gene is designed to simulate molecular interactions particularly associated with the degradation of US Nuclear Weapons but it grinds to a halt with half a mouse brain. I must say that when I was playing with this over 10 years ago we were talking about ant or fruit fly brains which are merely hundreds of neurons in size and our computers were falling over. Given that baseline, the achievement these guys have made is incredible, although using the most powerful computer on the planet just shows you how far we are from modelling a human brain. Human brains typically have about a 100 billion neurons with many thousands of synapses. Rough estimates put the number of connections at about a quadrillion synapses which for those of you that like zeros looks like this: 1,000,000,000,000,000 Also to note was that when this is done typically one uses random assignation for where the synapses end up, it isn't a true model of how a brain works as there would be too much information to configure and would have to be done by hand. In these models the neurons are loaded into the system then randomly assigned a number of dendrites which randomly point to other neurons. You don't get real behaviour as in hearing and vision and the like but you do get a sense of how the flow of stimulus and response works. My own conclusion from my studies and keeping abreast of the topic since leaving formal education behind is that small neural networks specialised to a particular task are more likely to have results than large scale applications like this. Even mother nature adopted this process as you can see in evolutionary history that old structures are built upon by new, more specialised ones - you only need to look at a reptilian brain and compare it with our own, particularly the basal ganglia cluster to see the similarities in structure and function. In pulling these structures together you can then start achieving something that is greater than the sum of its parts.","['ai', 'supercomputers']","['ai', 'supercomputers', 'web', 'development', 'mobile']","[0.5943653256776652, 0.5883603680788058, 0.31736116588491925, 0.31385684097611766, 0.3069893954269575]","['development', 'mobile', 'web']",[],[],[],True,2
2007-05-03-drmed-for-life.md,DRMed for Life,"['drm', 'media', 'piracy', 'rant']","DRMed for Life
In the news recently has been the whole thing about not only the copy
protection on [HD-DVD and Blu-Ray disks being
cracked](http://www.infoworld.com/article/06/12/29/HNdrmhacked_1.html) but
people posting digg links with decryption keys in them. I can understand Digg's
position in removing said posts until the community kicked off and [they then
decided they'll go down with the ship ](http://blog.digg.com/?p=74)if they got
prosecuted. Hurrah for someone over there seeing sense. One part of my brain always goes ""Hooray for the hackers"" whenever we hear
stories about DRM being hacked in whatever guise it has been created. Another
part of my brain, probably the more rational side I guess, does kick in
afterwards and say that putting these things out in the wild will enable more
software / media piracy and will incur costs for the companies that produce it
which will make them either raise costs or step up counter-piracy methods. I
never get to the ""woe is me"" stage like most media company execs do as they are
truly multi-billion dollar organisations so it's hardly going to come out of
the mail boy's pay cheque and they are unlikely to go bust. What I do question properly though is the rationale that got us here in the
first place. Since the 60s with tape-to-tape reels starting to replace vinyl
records, music, film and software piracy has got bigger and bigger. What has
happened though is nothing short of an arms race. Consistent through this
entire arms race have been three key points: That me, or anyone else, once they have bought a product has the right to
play or use it for their own personal enjoyment whenever they see fit. This
is the argument that most consumers will use - I might buy a CD album but I
want to play it on my MP3 player. I might buy a DVD but I want to play it on
my Linux laptop as well as on my TV. Companies that produce consumable media assume that anyone that wants to
copy a product is inherently up to no good and they are now labelled as
pirates and are probably taking the music / film / software and selling it
in backstreet market stalls. The profligacy of piracy is directly related to the first two points and how
policed piracy is within the community. One can directly see that paid for knock off copies of movies and music is
completely against the law as you are selling someone's work and is tantamount
to counterfeiting. However, a framework for dealing with these people exists
within the law and we are starting to see this go down. The media companies will tell you that it's because of their anti-copy
protection, however in reality it is because of better policing and it being
viewed as a black market operation and it having been historically a move
away from ""hard crimes"" that has occurred over the last 20 years. This argument doesn't wash at all with consumers. Once I purchase a piece of
media it is mine to use how I want on whatever device I choose. The barriers that are being put up by the media companies in their zero
tolerance to consumers is assuring their position as the ""big bad ogre"" in all
of this. Were they to engage with the consumers who are most likely to want to
move content from one form to another they would probably be able to reach a
solution. Indeed were they to strip all DRM from their content altogether and then spend
the money on producing better content or else supporting better policing they
would probably turn a larger profit. In the words of Nixon, ""I am not a crook"" - but I do want to watch Spiderman 3
when it comes out possibly on my TV from my XBOX, on my Linux Laptop, Windows
Media centre and my PDA. At the moment I'll be lucky if one of those four work
so I probably won't buy it at all. _Update 2024-12-31: Minor edits to fix typos and broken links_","['drm', 'media', 'piracy', 'rant']","['media', 'rant', 'piracy', 'drm', 'web']","[0.6315940771367403, 0.6258936412077327, 0.5912361234300917, 0.591235238733706, 0.3132434560904941]",['web'],[],[],[],True,4
2007-07-03-is-180-good-value-for-wii-sports.md,Is £180 good value for Wii Sports?,"['consumer electronics', 'gaming', 'media']","Is £180 good value for Wii Sports?
I am definitely a [Nintendo](http://www.nintendo.com/) fan boy. I've had every Nintendo console released on the market plus so many Game & Watches it's not funny. Call me sentimental but Nintendo has been a part of and is one of the definers of my life. So obviously when the [Wii ](http://wii.nintendo.com/)came out there was no question I was going to get one. The new controllers are awesome and just show you what a massive difference can be made in [computer-human interaction](http://en.wikipedia.org/wiki/Human-computer_interaction) by adding a couple of extra components and removing some wires. But for some reason this time I didn't get one on launch or near to launch date. The reason? Because I didn't see any games I'd play. In the end it wasn't until June that I finally went and got one. The reason? My wife said she wanted to play Wii Sports! This obviously made it easier to add another console under the TV in the lounge room so in it went. Now if you haven't played it, Wii Sports ships with the console so in that regard it is free. In it there are a series of very well built games ostensibly to demonstrate the different ways the controller can be used. Tennis, Golf, Baseball, Ten Pin and Boxing all make an appearance. My other half and child love it. For my wife it is a change of all the things she hates about computer games (pushing buttons that bear no relation to the action on screen) and my child (who is nearly three) just likes swinging the controller and playing with mum and dad. But something inside of me just isn't loving my Wii. I walk into GAME and check out all the releases and there's nothing I want badly enough to part with £40 for. I got Zelda more because I thought I should rather than because I thought it was amazing and it is a fantastic piece of software engineering but it has the feel of a MMORPG grind about it so whilst I've nearly finished it now it has left me tepid in a way that Ocarina of Time never did. At present the Wii is the most sold ""next gen"" console and regular ""sold out"" signs at GAME down the road suggest they are still selling like hot cakes. Back to my original question though which was; is £180 good value for Wii Sports? Personally I'm more likely to play a bit of Wii Tennis when I get home than watch TV. In real terms my wife and I have played a good dozen hours of Wii Sports each (mostly together) otherwise we'd have gone to the cinema or something which would be £15 a ticket for 2 hours. That alone is about £180 by itself and when you pass the controller over to a neice or nephew or child of a friend who hasn't got one you do get that warm techie buzz about someone ""getting it"" for the first time and I think that is probably worth £180 any day of the week.","['consumer electronics', 'gaming', 'media']","['media', 'gaming', 'consumer electronics', 'web', 'mobile']","[0.6241689278457385, 0.5988290985283986, 0.5895219089448417, 0.3211199297145301, 0.31202650618900024]","['mobile', 'web']",[],[],[],True,3
2007-08-25-jquery-saves-the-day.md,JQuery saves the day?,"['css', 'javascript', 'web']","JQuery saves the day?
If you haven't come across it yet there is a javascript library called [JQuery](http://jquery.com/) which is being developed as an open source project, designed to give us better control over our web pages and the things we can do with them. Thankfully [John Resig, Karl Sedburg and the others](http://docs.jquery.com/About/Contributors) have steered slightly away from the profligacy of AJAX libraries doing the rounds at the moment and produced a library that actually deals with some of the problems you face as a web developer or a designer - namely things like clients saying ""I'd really like the first paragraph after each header to be blue instead of black"". Now before I get shot down in a burst of ""you can do that using classes in your p-tags"" I'll say this - I don't want to, I shouldn't have to and it makes for ugly and unmaintainable code. Doing this just [papers over the gaping holes left in CSS ](http://technologytreason.blogspot.com/2007/04/why-is-css-such-painful-tool.html)and makes your HTML even less semantic than it already is. This is where jQuery comes in. The biggest area of development in this library has been in developing ""content selectors"" similar to the [CSS selector specification](http://www.w3.org/TR/CSS21/selector.html). The brilliant thing about these selectors is that we don't have to wait until browsers with CSS 3 in them turn up before we can use them - thus saving us about 5-6 years of waiting time. I'm a fan of Javascript in small doses - I'm not a fan of large scale AJAX where it is pointless to be loading information that you can get on a click anyway, 99% of my clients want to ensure accessibility and often Javascript breaks that. On a UI where responsiveness is key then AJAX is 100% appropriate but for the majority of sites it's a gimmick. However in this context we have a javascript library that can add depth to the interface and add consistency and markers that could only be achieved by a lot of proprietary hacks. This benefits usability without sacrificing accessibility and portability. If JavaScript is switched off you lose nothing that wasn't there before anyway; if it is then you get a whole lot more texture to the site. Watch this space as I think there will be a lot of development on this library over the next 12 months.","['css', 'javascript', 'web']","['web', 'javascript', 'css', 'development', 'internet']","[0.6545906230560015, 0.6130660583243231, 0.6086177409637381, 0.3434137458318494, 0.30232445938034047]","['development', 'internet']",[],[],[],True,3
2007-10-14-jquery-slideshow.md,JQuery Slideshow,"['css', 'development', 'javascript', 'web']","JQuery Slideshow
It seems JQuery is definitely gaining some traction as a useful library - not least because of the development of the [ThickBox Gallery library ](http://jquery.com/demo/thickbox/)by [Cody Lindley](http://www.codylindley.com/) which is seeing huge amounts of use around the web at the moment as a means for displaying galleries for product or photos without being constrained by the page template you are building for and by maintaining the semantic integrity of the HTML you have put into the page. The last cool feature is that you don't have to use the dreaded pop up which brings into play the whole pop-up-blocker issues. It seems redundant to talk about the ThickBox stuff other than to say it's a great bit of kit and well worth checking out if you need gallery display functionality, I've got my own little bit of JQuery code to document here. This came about due to a client wanting a gallery then not wanting a gallery because they didn't want to maintain all the thumbnails etc and so it evolved into a ""slideshow"". They didn't want to use flash due to the cost, but they were already using JQuery for other parts of their site anyway. As such I decided to have a go with building a JQuery slideshow with the animation API. For this example I'm assuming some degree of javascript familiarity so I can get to the guts of the code. Obviously you'll need the [JQuery library ](http://jquery.com/)- I'm using the current 1.2.1 version that is compressed so it's a light download. Next up we need a page with an image in it with an an id called ""bigimage"". We also need some javascript to set up an array with the image names in it that we want to load so let's do that: We need to trap the moment the document becomes ready to work with so we set up the special document ready function: What this function does is set the opacity of the image to 0 (ie invisible) then we get a reference to it in standard javascript and finally attach an event to it which fires on the onLoad event for the image (more about this in a minute). The addEvent function is given below and is a worker function to add an event handler for a particular object. Why do we want to add an event for the onLoad of the image? The answer to this lies in how we want to do the animation. Potentially we could have hundreds of images in an array. This slideshow fades an image in, displays it for several seconds, fades out, loads the next image and starts again. By trapping the onLoad event of the image we can use this event to start the animation sequence which finished with an instruction to load the next image. Only once the image is fully loaded does the sequence begin again. So our Document Ready method sets up the onLoad event handler, anim() which is listed below: This function is called every time a new image has finished loading, bringing the image from 0 opacity to 100% over a 1500 msec interval. Next it holds the opacity at 100% for 5 seconds and finally fades out over 1.5 seconds after which is calls the function animNext(). animNext is a function that deals with determining the next image in the sequence (in my case, wrapping back to the start if we get to the end) and then displaying it purely by changing bigimage's SRC property. This is pretty straightforward JavaScript so I'll leave it for the reader to do. The key thing here is that by adding an event handler onto a low level object in the document along with a couple of animation commands a reasonable slideshow effect was created which works well for the users and was good for the client as it is maintainable and didn't cost a huge sum as it would have done in flash. It's the ability of JQuery to expose enough variety of basic features to allow you to do this very quickly and easily. I have no doubt that after 10 years of writing javascript that I'd be able to do this all by hand. The questions are ""Do I want to?"" and ""Is it good value for the client if I do?"" - my answer to both of these is ""not on your nelly"".","['css', 'development', 'javascript', 'web']","['web', 'development', 'javascript', 'css', 'internet']","[0.6679756199919895, 0.6415710235594007, 0.6185920235152003, 0.5917347740173672, 0.304680107931991]",['internet'],[],[],[],True,4
2007-10-15-let-the-new-gaming-witch-hunt-begin.md,Let the new gaming witch hunt begin,"['censorship', 'gaming', 'government', 'media', 'rant']","Let the new gaming witch hunt begin
I'm in my thirties now and I've been playing computer games from the age of about four when my dad first brought home the venerable VIC 20 - partly because he was doing a computer science degree at University but mostly because he wanted to tinker. Through my life I've borne witness to the rise of computer gaming as a media format to rival and now surpass film and I've seen countless witch hunts focus on computer games as being the root of many of society's teenage evils - everything from being the cause of the obesity epidemic to turning children into cold blooded murderers and violent criminals. I'd like to think that I'm pretty normal - whilst I have my own individual quirks as everyone does, psychological assessments that I've taken for a couple of employers have branded me pretty average on the whole ""serial killer"" metric. And even though I'm now suffering from the onset of a bit of ""middle-agd-spread"", as a teenager and child I was pretty skinny. In thirty years of gaming I'd say I'm ""above average"" in terms of the amount of time I spent gaming. I wouldn't have hit ""compulsive"" but as a kid I'd spend a good hour or two a day playing on the computer. Conversely though I'd spend an hour or two playing outside per day though the key factor was that I watched virtually no TV. You see my parents had a rule in our house - TV or Computer but not both. When my mum thought we had been spending a bit too much time in front of either she'd pull the plug out of the wall and summarily kick us out the door with the instructions that ""it was a nice day - go enjoy it"" - this held true even if it was raining or the middle of winter! So, in what seems like a biennial event another review of gaming has been started - [the Byron Review](http://www.dfes.gov.uk/byronreview/) this time is being headed up by the very smart Dr Tanya Byron - an expert in Child Behaviour (and TV personality to add some celebrity to the proceedings). Whilst the review is supposed to cover the full range of technology, Gaming and the Internet are always the first things to crop up as being responsible for the decline of morality amongst our youth. What won't be taken into account properly though in my opinion is how the role of the parent has changed in relation to these technologies. My parents looking back on it were pretty good (though I know I didn't think it at the time) in policing our internet and gaming activities (our family had access to the internet through a BBS at my dad's Uni). The modern parent has completely divested themselves of any responsibility for policing their childs' activities. This isn't just limited to gaming and the internet but is a wider social epidemic we are starting to see the symptoms of - everything from anti-social behaviour to academic performance. I know of adults who have bought games for their children aged under 10 that are clearly marked as being 18 certified. All because of pester power and the guilt that they have over not seeing their child because they have to go off and work all day. What scares me is the ""oh well"" attitude of these parents - and the fact that because the console is in their kid's bedroom they don't see the actual content themselves. For me games were played in the living room in full view of the rest of the house. In the face of this blatant irresponsibilty from parents, what can the games industry do? They've created a product they have submitted to the classification board, risking censorship and potentially loss through narrowing their market but then the parents ignore it and go buy the game for their child anyway. After the fact, parents are the ones calling for tougher regulation and a realignment of the game makers moral compass when it comes to producing the content but it is their failure and own moral ambiguity that has caused the problem in the first place. For all the public outcries about video game related violence and exposure to sexual content, there is deafening silence regarding the lack of parenting skills to avoid exactly this situation. My parents could do it as could those of my friends - how have we lost that skill in a single generation?","['censorship', 'gaming', 'government', 'media', 'rant']","['media', 'rant', 'gaming', 'government', 'censorship']","[0.6382982468468964, 0.6099122215007107, 0.5915959801844523, 0.5901435365571789, 0.587453956443767]",[],[],[],[],True,5
2007-11-02-css-structure-what-a-mess.md,CSS Structure - what a mess,"['css', 'development', 'rant', 'standards', 'web']","CSS Structure - what a mess
James posted a message on my blog some weeks ago and it's only now that a penny has dropped in my mind about what we need to deal with the issue of structure in CSS - the problem is we have none. As James points out you end up with a flat mess that with all the best will in the world definitions are hard to find. I've ranted before about the [annoyances of CSS](http://technologytreason.blogspot.com/2007/04/why-is-css-such-painful-tool.html) - particularly to do with the lack of variables or constant definitions without recourse to server side scripting and about the nature of the W3C CSS working group not being well represented by techies - especially as CSS is nearly a language in its own right the same way Regular Expressions are. As the web building fraternity finally weans itself off of dreamweaver and table based design and adopts a more semantic, HTML-lite way of building sites, the CSS files are getting bigger and bigger all the time. At the moment, to get a degree of specificity one has to redeclare selectors: for example. Many CSS zealots would say ""But you can get rid of div#header altogether"" and I can in this instance but what happens if my div#logo doesn't appear in div#header on a page and certainly it's not uncommon to have navigation in a header as well as a sidebar. As can be seen, in order to get specificity we increase verbosity. Anyone that is fully converted to CSS design will tell you this, it's the casual ""div stackers"" who just declare a new class for every element in the document which ruins the HTML. My solution then W3C if you're listening is this. Cascade in the style sheet, cascade in the CSS file. In many programming languages there is a keyword to get you down to the level of an object that you are going to manipluate numerous properties of in one go for example ""with"" in VB. Thus I could say: The CSS equivalent would be: This gives you the specificity required, removing the redundancy and creates a cascade like structure to the document that would also make things much easier to debug what is going on. Structural CSS along with variables would make a massive contribution to the developmental side of CSS as a language that could revolutionise the way we use CSS with the web.","['css', 'development', 'rant', 'standards', 'web']","['web', 'development', 'css', 'standards', 'rant']","[0.6519836658394688, 0.6420796824156415, 0.616280430845671, 0.604767447411335, 0.6031583720512852]",[],[],[],[],True,5
2007-11-02-fah-goes-number-1-but-we-could-do-better.md,FAH goes number 1 but we could do better,"['distributed computing', 'gaming', 'supercomputers']","FAH goes number 1 but we could do better
[Folding at home](http://folding.stanford.edu/) (FAH) has taken the [Guiness World Record ](http://www.guinnessworldrecords.com/)for being the most powerful distributed computing network with a top speed of over 1 petaflop - (a thousand trillion calculations per second). This is a remarkable achievement and shows the immense power that can be brought to bear by spare computing power used in a distributed network. The key here though is massive parallelism which means the various nodes in the network (your PC or PS3) are all doing different jobs at the same time and are at various points through these jobs. This is what made FAH and the old title holder Seti at Home (a search for extraterrestrial life) so scaleable. Individual computers on the network download work units from the central repository, process them individually and then resubmit them back to the central core for post processing. This is in contrast to say the Earth Simulator of Japan, a massive supercomputer capable of running huge simulations with ridiculous numbers of variables and calculations very quickly but where everything is interdependent. Likewise the ultimate aim of the BLUE project from IBM and the US Department of Energy is to be able to simulate all the forces and atoms of a nuclear explosion to simulate what's happening to USA's aging atomic weapons stockpile as they are no longer allowed to perform live tests. This doesn't take anything away from their achievement, however it does go to show just how much wasted processing capacity there is lying around on the network. The FAH project ramped up from 250 Teraflops (trillions of instructions per second) to just over a petaflop by the introduction of 670,000 PS3 owners supplying their hardware, up from the 200,000 PC users who got it to 250 Teraflops. Given that there are over 6 million PS3s in the wild this represents about 10% of the total Ps3 userbase - a quick calculation indicates that PS3 owners alone, should they all connect up to the internet, could provide about 7.5 Petaflops of processing power... this is beore we take into account PCs, XBoxes and Nintendo Wiis. What this illustrates to me is that many of these projects are limited by their publicity and how ""glamourous"" they are. Taking nothing away from the geekiness of searching for ET or the importance of seeing how protein folding will affect drug development in the future, a more elegent solution would be an open framework that users subscribe to which is then used by anyone who wants to create a distributed processing application. For the end user it is seamless and the for the multitude of public projects requiring raw processing cycles it gives them to opportunity to get access to larger numbers than their marketing budget would otherwise provide for. Even private companies could pay to rent processing time thus investing funds back into the project for ongoing development or optimisation.","['distributed computing', 'gaming', 'supercomputers']","['supercomputers', 'gaming', 'distributed computing', 'web', 'development']","[0.5897027088571746, 0.5876617597008439, 0.5817040732940799, 0.31549732277120424, 0.3104792826001498]","['development', 'web']",[],[],[],True,3
2007-11-05-bye-bye-openmoko.md,Bye bye OpenMoko,"['android', 'google', 'mobile', 'nokia', 'os', 'strategy', 'web']","Bye bye OpenMoko
Google announced today that they would be partnering up with a load of other
companies including Samsung, Motorola and LG to produce a new phone ""software
stack"". For those of us in the technology game this basically means Google
plans to release mobile phone operating system to rival that of Microsoft,
Symbian and the various Linux flavours out there already. What I find most annoying about this is that Google has for years now feasted
upon the fruits of the Open Source Community, using many of their projects to
enable additional features and indeed their core search facilities to work.
While it may be argued that the Summer of Code gives back to that community,
there is a sense that rather than sponsoring an existing project like openMoko
(a Linux based, open source version of what Google has announced) they've
decided to go out on their own and start from scratch. Given Google's tremendous resources it won't be long before we see the platform
hit the market. Within the commercial market there is already Maemo (nokia's Internet Tablet
platform which they actually open sourced) and QTopia, a commercial package
available on the GreenPhone which is a development kit and is mostly open
source too. My guess as to why Google didn't run with any of these options is that there
are already thriving communities surrounding them and trying to work with these
existing communities makes it difficult for the Google techies to throw their
weight around. Hey ho. As a developer, mobile development is already a nightmare having to
support various versions of Symbian, MS Windows Mobile, BlackBerry as well as
smaller (but vocal) numbers os Maemo users we are now having to think about
iPhone from Apple so adding ""Google Phone OS"" isn't that much more work. For me, having had a mobile phone for the better part of 15 years and having
had a data capable phone for nearly 10 years I've watches OSes come and go,
killer apps be talked about every 6 months and watching the market mature the
only two things ever to take off properly on a mobile was SMS and now e-mail. I've got an E65 nokia and it is the best phone I've ever owned. Why? Because
the web browser works seamlessly on standard web sites and the email is easy to
use, even without a full keyboard. Oh, and it doesn't crash as do most of the
rest. Spending all this time and money in my opinion by Google is absolute folly, but
then they have virtually limitless cash reserves and they have a staff of many
thousands across the world that they have to retain doing something - they may
as well be making a phone OS as anything else. Who knows this might end speculation that we are about to have Google OS on our
desktop next year as well.","['android', 'google', 'mobile', 'nokia', 'os', 'strategy', 'web']","['mobile', 'web', 'google', 'os', 'strategy']","[0.6455945298180715, 0.6368381918514565, 0.6073173130656557, 0.6064483771869166, 0.5982684369130058]",[],[],[],[],True,7
2007-11-08-why-cant-i-have-100-laptop.md,Why can't I have $100 laptop,"['government', 'hardware']","Why can't I have $100 laptop
Don't you hate it when you can't get something you'd really like? I've been following the [OLPC project](http://www.laptop.org/) more or less since its inception. When I first heard about it I was mostly interested in how they were going to pull off building a laptop for only $100 per unit. After realising they were going to do it I was interested in how useful the machine would actually be (it has no hard drive so it can't be that great right?). After seeing it was running Linux and was designed to be wireless from the start, run on mains or able to wind it up to power the laptop and it was designed to be durable in harsh environments I was mostly interested in how I could lay my hands on one (or two even). My disappointment was immense when the OLPC guys decided not to offer them for sale, and then when they u-turned and started the G1G1 initiative (Give One Get One) I had a momentary blip of joy until they said it would only be available in North America. Why they've not rolled this out to Europe is beyond my comprehesion - I don't even care if I don't have a £ key - I can always map it to a key stroke anyway. And I'd even be happy to Give 2 Get 1 if shipping was the issue. The other thing that amazes me is that given the connectivity of these laptops Western nations aren't falling over themselves to get them for schools - even if they had to pay a higher rate along the lines of the G1G1 programme it would still be cheaper than buying Dell machines into all the schools.","['government', 'hardware']","['hardware', 'government', 'development', 'web', 'internet']","[0.5882597565076078, 0.5874454718099367, 0.32042463140702127, 0.31746381521609934, 0.30026660860430954]","['development', 'internet', 'web']",[],[],[],True,2
2007-11-19-fuzzy-logic-could-book-more-flights.md,Fuzzy logic could book more flights,"['agents', 'algorithms', 'web']","Fuzzy logic could book more flights
I've talked about fuzzy logic for use by the retail sector [in the past](2007/03/fuzzys-where-its-at-or-will-be) and the project I'm involved in there is maturing nicely. This week I've really realised how, as software engineers we need to grasp the nettle and move a lot of service based software toward fuzzy systems for usability reasons. Nearly everyone these days has booked a flight online and when it came time to booking a holiday to Australia this winter, the first thing I did was fire up a browser and head to [expedia](http://www.expedia.co.uk/) and [travelocity](http://www.travelocity.co.uk/). If I was planning to fly on specific dates I would be well catered for and I could get a list of prices and book a flight in a few easy steps. I wasn't planning on flying on a specific date though. I work for myself so can take time off whenever I want in a general sense. Really what I wanted was the cheapest flight from London to Sydney in December. After typing a few different dates in manually I did the sensible thing and called a human travel agent who was very helpful. Unfortunately, as helpful as she was, she only had access to the same systems I did so couldn't tell me the info I needed to know. Mentioning this to friends had the usual ""you can't do that"" response. Can't do it?! I'm the customer I can book when I want. Most airlines operate through the SABRE booking network which is basically a massive database of flights from point to point with availability and prices per leg on it. It sits on top of a nice mature API which makes it easy to program against, and that's where the developers leave it. But as a customer this doesn't fulfill my requirements and this is where engineers need to spend more time thinking fuzzy. In these days of multi-processor and multi-threaded OSes it is not that difficult to build offline agents that could go and find this information out for a customer and then email it back to them. Indeed I wouldn't mind registering to use this sort of service so now the company has my personal details and they can market to me. The agent wouldn't even need to respond with all the availability. It could just give me the cheapest 10 or 20, all from a specific operator etc or those flights routing through Hong Kong as a stop over for example. It also doesn't need to be fast. A deprioritised thread could take a day to get this sort of information and if I'm being that vague then time is hardly an issue. If someone reads this from the travel industry please ask your techies to build this feature. If you are a venture capitalist then give me a call and we can revolutionise the online travel sector! The web has brought us an always on, on-demand, serviced-based method of interacting with our information but the casuality of this has been flexibility. The days of fuzzification are soon to be upon us and coupled with automated agents some amazing new systems will become available that will give us back our flexibility.","['agents', 'algorithms', 'web']","['web', 'algorithms', 'agents', 'development', 'business']","[0.6341126087588619, 0.5882863804243953, 0.5869326980393619, 0.3176456243914912, 0.30912299255736236]","['business', 'development']",[],[],[],True,3
2007-11-21-why-was-data-being-passed-on-a-disc-and-what-was-eds-advice.md,Why was data being passed on a disc and what was EDS' advice?,"['government', 'privacy', 'rant', 'security']","Why was data being passed on a disc and what was EDS' advice?
Readers in the UK will be aware of a Data Protection Act train crash that we have been watching unfold in front of us over the last few days. It turns out that 25 million records of a database managed by [HMRC](http://www.hmrc.gov.uk/) have been lost in the post because they were sent on a couple of disks using unrecorded mail. There has been much speculation about which minister to blame and who in the cabinet (including the Prime Minister) should lose their job but one thing that is mostly missing is the notion of data security. In the UK we have the Data Protection Act - policies enshrined in law to which I am constantly referring when talking to my clients. A typical day for me usually includes quoting something from the DPA at least once. Not least because a client wants to harvest user data and use it for something else that is outside the bounds of what is technically legal. I've done a lot of work for government and I have to say in my experience they have terrible technical practices. Gone are the days of locked down machines with no floppy drives and only CD-Rs. In are mass market units from Dell with the latest in CD/DVD-RW (because they are cheap and mass produced) along with USB connectors that people can hot plug a pen drive into and download whatever they like. The current government has a woeful record on technology projects mostly because they don't understand it and they contract suppliers who talk a good presentation rather than deliver an effective solution. According to the DPA ""Appropriate technical and organisational measures shall be taken against unauthorised or unlawful processing of personal data and against accidental loss or destruction of, or damage to, personal data."" This is why our PM said procedures weren't followed and he is bang on the money there. This relaxed attitude to data, particularly sensitive data, has been demonstrated in this debacle. If the data was going to be put on disc why wasn't it fully encrypted? Indeed, why wasn't there a secure online facility for user data to be interrogated without recourse to physical copies to begin with? In addition the data was supposed to have been ""desensitised"" before sending - a quaint term meaning removal of things like bank details, exact personal date and full address information. To do this EDS wanted to charge money for it. The department didn't want to pay so they took the lot. EDS are complicit in this as much as the people from HMRC are. How hard is it to type into the database ""Select name, age, postcode from person where...."" instead of ""Select * from person where..."" Or else just remove the columns that were sensitive on output. It would have taken me a few minutes so it can't have taken an experienced EDS engineer that long. EDS shouldn't have been charging for that sort of difference - but it sounds more complex so it was an opportunity to get some more cash in - probably. Further EDS should have been saying ""We advise you that the data you are requesting is excessive for the purposes of what you are going to use it for so we'll give you a more secure subset"". That would have rammed home the implications of what the staff at HMRC were asking for. In my history of working with government I have come across this sort of situation many times before. It is well known that government contractors over charge, shaking the fruit out of the infinitely laden money tree whenever they can. Our E-Minister is supposed to deal with this sort of thing but in practice he's a politician who knows as much about IT as my mum. The only way to resolve this problem is for wholesale changes to occur within government (locking down machines) and to make stiffer penalties the punishment for breaches of the DPA. We now have a situation where 25 million adults in the UK are worried that their personal details are going to be used in some sort of mass identity fraud. My view is pragmatic in that the CDs are propably laying in the corner of a sorting office at TNT somewhere - but they could well be in some gangster's tech lab being processed and that is the point of all this security.","['government', 'privacy', 'rant', 'security']","['rant', 'security', 'privacy', 'government', 'web']","[0.6238291722327777, 0.6099273847900156, 0.5909076127375172, 0.5853278345304938, 0.3201188941232141]",['web'],[],[],[],True,4
2007-11-26-adding-cron-jobs-to-a-qnap-server.md,Adding Cron Jobs to a QNAP server,"['development', 'devops', 'linux']","Adding Cron Jobs to a QNAP server
If you haven't come across them yet[ QNAP](http://www.qnap.co.uk/) make these amazing little NAS boxes that are perfect for home or SME use. I've got mine running as a home server but might get one for the office as our old server is on it's last legs and a fully tricked out 1U dell server is a bit of overkill for a glorified file server. The best thing about these devices though it that they run Linux OS utilising [Debian](http://www.debian.org/) Essential and as such they can be configured to do almost anything you want. Out of the box they already come with file serving, media serving, database and web servers. One slight problem though is that the boot up process is not disimilar to that of a live CD. This is great in that it makes the system highly robust and it boots to a known state each time. The problem is that short of rewriting the firmware you can't introduce things into the boot process. What I don't want to do is have to re-run a load of scripts to configure the server how I want it after a power failure or forced reboot. The boys over on the [QNAP forums](http://forum.qnap.com/) are really on the case and one of the chaps has created a nice little framework script which hooks into the boot process and allows the execution of a series of scripts. [You can see his work here](http://www.qnap.box.cx/). After installing this workaround you can add scripts to the scripts folder and take control of your server. One of the things I wanted to do was add items to my cron list and this process is explained below. SSH into your QNAP box Install the custom scripts files at [http://www.qnap.box.cx/](http://www.qnap.box.cx/) as per the directions there. CD to your scripts directory in custom and make a file called joblist.txt in VI (Vi is the only editor you have on the QNAP drive). When in vi make your list of cron jobs using the [standard CRON syntax](http://www.adminschoice.com/docs/crontab.htm). Mine was the following: This will run a backup script I had written at 1:25am everyday. You can add as many or as few as you want. Save your document and exit from Vi. Make your script that will fire on start up. I called mine cron_update.sh In there put the following code: Save and quite out of Vi. You'll notice I've used a variable in here to specify where to find the files. This is because the autorunmaster script is a folder higher so we need to be explicit about where to find things. Go back up a directory to your custom folder. In there edit your autorunmaster.sh file with vi. At the end of the file append: Then save and close the file. Now when you reboot you should have your newly added cron jobs appended to the crontab without removing all the old ones.","['development', 'devops', 'linux']","['development', 'linux', 'devops', 'web', 'internet']","[0.6418831178719757, 0.5913523579488147, 0.5822014906978034, 0.33332362576773533, 0.31222626479845733]","['internet', 'web']",[],[],[],True,3
2007-11-30-pci-dss-will-wreak-havoc-on-smes.md,PCI DSS will wreak havoc on SMEs,"['business', 'rant', 'security']","PCI DSS will wreak havoc on SMEs
One of my clients was asking me about [PCI DSS](http://www.pcisecuritystandards.org/) certification today. Coincidentally I also received our letter about compulsory compliance to the PCI DSS standard. Both of us are what are termed ""Level 4 Merchants"" - that is we process less than 20,000 card transactions through the company in a year. Arguably Level 4 Merchants will probably account for the largest number of business globally as they will incorporate pretty much every SME in PCI compliant countries that takes a card as a form of payment (according to Visa about 27 million businesses). The standard itself is a worthy document - a dozen set in stone compliancy rules to which businesses have to adhere. Most of it is common sense like settin your password on your router to something non-default, make sure card details are encrypted if they are to be stored, that sort of thing. Most businesses in the SME world would, in fact, actually be compliant - mostly because they don't store data. Here's the rub though. Barclaycard sent both my client and I a letter basically saying you have two options on compliance: First you do it yourself or otherwise you get someone to help you (and of course they recommend a company SecurityMetrics to help you do it all - at a discounted rate of course). Obviously the first thing I did was go to the security metrics site and request a quote. As a Level 4 Merchant it will cost me merely $699 per year to be assessed quarterly. However they can tell me do do things to get me up to spec which is then going to cost me more again. At the end of it they give me a pass or fail certification and their audit is completely subjective. After that I went and downloaded the whole specification and read it through twice. Every point I made a note against. Typically, this isn't a document for the feint of heart. I'm lucky first in that I'm a techie and second that I did my formative programming years in a bank specialising in what was then the forerunner of InfoSec. There is not a single line of ""plain english"" in the whole thing. A couple of non-techies I've shown it to got about a page in before giving up. Your average 1-5 employee company owner doesn't have a hope. Thus he'll end up paying $699 per year for what is essentially insurance. Even amongst Level 1 Merchants, understanding and compliance are two different things as you can see on [Evan Schuman's great article about recent stats to come out of the Level 1 camp](http://storefrontbacktalk.com/story/112907pciconfusion). Big companies have the resources to deal with this sort of stuff and they are also more likely to be saving data on customers so for them it is crucial. Whilst no less crucial for small businesses, the fact that a store owner who only takes card payments for people when they are physically in his shop will still have to go through this audit is patently ridiculous. BarclayCard are indemnifying themselves by playing the [FUD](http://www.google.co.uk/search?hl=en&q=define%3A+fud&meta=) card with comments like: To date these penalties have not been passed on to any Level 4 Merchants, but from 30th April 2008 your business will be liable for PCI DSS penalty charges and costs associated if you fail to comply or have a data compromise. Penalty charges can be considerable (in excess of £100,000) so, to protect your business, it is vital that your prepare for PCI DSS compliance by 30th April 2008 and continue to maintain compliance in the future. What the PCI DSS standard fails to deal with however is systematic failure of employee behaviour. It doesn't deal with issues such as people skimming cards if they are taken out of sight nor does it deal with employees writing details down on a piece of paper and passing them on when dealing with mail order, nor does it deal with phishing scams. Indeed I had a card machine problem last week and the support officer at BarclayCard stated: ""Just write the details down on a piece of paper and process them later"" Hardly a piece of advice that should be followed to maintain security. In the end businesses will have to make their own mind up about how to best deal with this new ""virtual legislation"" that is being thrust upon us. To me the whole thing reeks of the rise of the SEO industry piggybacking off Google's search technology. In reality the biggest source of credit card fraud is that caused by skimming details through offline processes such as mail order (which I had done to me recently and my bank caught it on the other end within a day) or else identity theft whereby a new card is created in someone else's name. None of the procedures outlined by the PCI DSS standard deal with these very real and growing issues - all they are doing are lining the pockets of consultant sharks that will feed on the SMEs who don't know any better and penalising the merchants for actually trying to conduct business.","['business', 'rant', 'security']","['rant', 'business', 'security', 'web', 'development']","[0.6174798133058984, 0.6078753475668849, 0.6020139005280974, 0.3221788663349476, 0.30529609131810637]","['development', 'web']",[],[],[],True,3
2007-12-10-net-xslt-and-how-to-import-an-external-xml-document.md,.NET / XSLT and how to import an external XML document,"['development', 'web']",".NET / XSLT and how to import an external XML document
I work with XML and XSLT every day of the week. Indeed working for a company called [XML Infinity ](http://www.xmlinfinity.com/)you can imagine how much we use it. I had one of those incredibly frustrating moments this afternoon that one typically when dealing with badly documented parts of .NET or XSLT. The annoyance in question was to do with loading a document in to an XSL template on the fly. 99.9% of the time you don't bother with this as you have a master XML document which you transform according to the XSL template that is assigned to it. All your XML processing is usually done before you get to this point. There is an xsl function though called document() which you can use to load in an external XML doc to the XSL template and then do work on it. I've used this before but the damn thing wouldn't work. Why not? Because our Transformation Engine wasn't using a loose enough resolver to be able to deal with externally referenced files... grrr. I know why MS did this because it's so the parsing engine doesn't go loading every document under the sun and potentially crashing. That's great but they could have documented it a bit better. The resolution by the way is to create an XmlUrlResolver, give it some credentials (in my case setting it to DefaultCredentials which allows you to access http::, file:: and https:: protocols) and then pass that into your Transform() method. Job done. Not quite. Having finally been given access to an external XML document I then had to contend with XSL's arcane methods of dealing with XML fragments. Again documentation was the issue here. Looking online there are some ridiculously complex ways of parsing an external document when by rights it should be as simple as just dropping the doc in a variable and then processing according to the variable. People were using recursive templates using xsl:copy and all kinds of things. Turns out the way to do it is a little known second parameter. If you do this: All you'll end up with is the text nodes. Not very useful. If you do this, however (note the second parameter): You'll end up with a full fledged XML document complete with nodes and everything put into your $var1 variable and you can then use it to select data according to standard XPATH constructs. If you don't want the whole document you can pass the second argument as an XPATH query and it will just return that nodeset - much easier to deal with. In all the time I've been dealing with XML / XSL I didn't know about this and it was a great pain to figure out. Typically the only reason I was doing this was to mock something up for a client quickly and it then turned into a mammoth effort. Knowing now though will save time subsequently I guess...","['development', 'web']","['development', 'web', 'rant', 'internet', 'media']","[0.642827673780956, 0.6421897043629399, 0.30298010590731494, 0.30235646323796866, 0.2968587737938131]","['internet', 'media', 'rant']",[],[],[],True,2
2007-12-19-sms-bamboozlement.md,SMS Bamboozlement...,"['mobile', 'rant', 'web']","SMS Bamboozlement...
I'm doing some work for a client at the moment who's industry is particularly technophobic. The absolute cutting edge is a bit of YouTube video thrown willy nilly into a page. I'd also point out that design is something that rarely makes an appearance in this particular industry. So it was pretty refreshing when we went to them with a series of ideas from the more commercial sectors of New Media and one of the things they latched onto was SMS. Queue annoyance though when we had already got everything ready to go other than to push the big green ""launch"" button and another company got involved and started talking about location aware services and high end data capture etc. At this point the client dissolved into a mess of indecision - ""Why weren't we doing all of this?"" was the question, to which the answer was ""Because you don't need to - primarily because your text messaging service is built around raising revenue through donations!"" I've had this happen in the past, notably with SEO companies. I do pity the poor clients who get stuck in these situations where they've finally decided to push their technology base along but then get waylaid by all the glittery, flashing and hypnotic LEDs. At the end of the day it is important to remember why you are doing something and not get sidetracked (and not get ripped off). Once a strong foundation of technology is laid there is always something new you can build - you don't have to have every shiny present under the tree to have a great christmas.","['mobile', 'rant', 'web']","['web', 'mobile', 'rant', 'development', 'media']","[0.6395884386862043, 0.6169885655533179, 0.6091719128960957, 0.3096233712252713, 0.3044070763834714]","['development', 'media']",[],[],[],True,3
2007-12-20-my-top-5-jquery-seasonal-wishes.md,My top 5 jQuery seasonal wishes,"['javascript', 'web']","My top 5 jQuery seasonal wishes
I've waxed lyrical about jQuery before, I've been using it a lot to do worker code which I just can't be bothered to hand write any more. Not least because jQuery handles all the little browser inconsistencies for me so the code I actually call into a page is infinitely more maintainable, especially if someone follows behind who maybe isn't so up to speed with JavaScript as I am. However, use a tool for long enough and closeness breeds contempt as they say. In this vein (and regular readers will know I don't do complimentary very often) and in the spirit of seasonal ""Listing programmes"" of every style, these would be the top 5 things I'd like to see incorporated into jQuery in the next year. Documentation - Starting off slowly and easily I'd definitely like to see some better documentation. Ideally I'd like to say that new sublibraries aren't included until their documentation is properly up to scratch. Some areas are very well documented other areas are sketchy at best. Wait(msecs, callback) - part of the effects sublibrary, we have all kinds of effects to enable objects to slide, fade and animate but we don't have a wait command. What I would give to have a command that you can just append to a sequence of animations and then wait for a period of time before calling another function or stepping to the next instruction. As you can see [from my jQuery Slideshow](http://technologytreason.blogspot.com/2007/10/jquery-slideshow.html) the common way to do this is to call animate() with the same instruction as your last step with a callback. It's not big or clever but it does the job. fadeToggle(speed) - again part of the effects sublibrary; we have slideToggle which is a great bit of code, call it and the object either slides open or shut depending on it's state. It would be great to have the same thing with fade rather than writing detection code and then calling fadeIn or fadeOut. State detection - Another worker function would be really useful here to actually determine the state of an object as to whether it is on or off in display terms. I am fully aware I can use document.getElementById(objname).style.display or equally $().css.display() however this will return ""none"" if it's off, but it could also return ""block inline table table-cell list"" etc depending on what it is. Ideally I'd like $().displayState() and it would return ""on or off"" or indeed true or false as a boolean so it would make display code even easier logic wise. And finally, Cast to DOM object. One of the best things about jQuery is it's query language. Using elements from the CSS and Xpath specifications pulling objects out of the document is so much easier than using DOM traversal methods. However sometimes the jQuery functions just aren't enough and we need to cast an object to real JavaScript to play with it - a simple method of doing this would mean the power of a great interrogation language along with the ability to cast to a real DOM object. I fully expect someone to come kick me now telling me I can do some or all of these things and indeed the functions I'm asking for exist already however the documentation as mentioned in number 5 is lacking in some areas so it isn't obvious if it is doable. Obviously this is a little tongue-in-cheek as if I was that worried about these issues I'd write the code myself and submit it to the team for inclusion in the next version. Indeed perhaps that could form the basis of one of my New Year's technology resolutions. Happy Holidays all.","['javascript', 'web']","['web', 'javascript', 'development', 'css', 'mobile']","[0.6533530636131162, 0.6121142410979199, 0.3406929096258714, 0.3038938517113617, 0.2972330227029071]","['css', 'development', 'mobile']",[],[],[],True,2
2007-12-21-potent-messages-of-impotent-industries.md,Potent messages of impotent industries,"['censorship', 'distributed computing', 'drm', 'media', 'piracy', 'rant']","Potent messages of impotent industries
I should probably know better than to open my mouth but the obvious has to be stated on this one. For anyone that is net Savvy enough to know what BitTorrent is, the news that TorrentSpy has just lost its court case against the MPAA isn't exactly surprising. Hearking back all the way to Naptser we seem to have an annual tag teaming of court cases brought about by the RIAA and the MPAA in order to bring these ""nasty pirate companies"" such as TorrentSpy to heel. Sites documenting the ins and outs of the case are plentiful so I won't go into detail. (For more info see the [BBC report](http://news.bbc.co.uk/1/hi/technology/7153323.stm) as it's quite neutral) After every one of these cases new technologies spring up to either to protect people's privacy better or make the technology better (Naptser giving way to Kazaa and others which gave way to the BitTorrent protocol). The recording and movie industries are worried because they are no longer the gate keepers to content and can charge what they like for it. As such the ""dirty pirates"" must be prosecuted even if they are, as in TorrentSpy's case, nothing more than a pointer to where the content is being held. The great amusement in this particular case is that the only reason the MPAA ""won"" in this instance is because of TorrentSpy's refusal to provide the tracker and user data because this was a breach of Dutch Data Protection laws. As such the MPAA won by default. Had this truly been a court case, it would have come to light that TorrentSpy provide a framework for people to post tracker data about any files they have on their machines and indeed they don't have copies of any of the physical files. The MPAA probably would have still had them closed down but their legal case was always going to be shaky. So TorrentSpy will be closed, they will be bankrupted but there will be a dozen smaller companies waiting in the wings to see if they can bleed the MPAA that little bit drier. You see the big problem here is that the MPAA can't let up now. It doesn't have the mechanics in place to distribute online properly (unlike same music where iTunes and others provide the service) not least because of the antiquated territorial boundaries films get sold by. As such we'll be seeing another legal case next year - maybe ISOHunt will be next - and another company collapsed but then dozens more set up for a brief stab at providing content to the people. The quote from the MPAA spokesman is great: ""The court's decision... sends a potent message to future defendants that this egregious behaviour will not be tolerated by the judicial system,"" John Malcolm, the MPAA's executive vice president and director of worldwide anti-piracy operations, said in a statement. ""The sole purpose of TorrentSpy and sites like it is to facilitate and promote the unlawful dissemination of copyrighted content. TorrentSpy is a one-stop shop for copyright infringement."" What's most amusing is that according to many sources, music being downloaded from ""official"" sources is almost as much as that being downloaded illegally. Surprising how given the tools, a cessation of hostility towards the users and a price point that accurately reflects the product being sold and the consumer comes to the party once again. The MPAA still has a lot to learn about the Internet - one wonders how much it will cost them in legal fees in the mean time.","['censorship', 'distributed computing', 'drm', 'media', 'piracy', 'rant']","['media', 'rant', 'piracy', 'drm', 'censorship']","[0.6316274928252612, 0.6218217920183484, 0.589374251998918, 0.5893737742714974, 0.5846780520378437]",[],[],[],[],True,6
2008-01-08-the-warm-glow-of-site-launch.md,The warm glow of site launch,"['media', 'web']","The warm glow of site launch
I've been in this game a long time but there is still nothing sweeter than launching a site after spending a months building it with your team and the client. As a TD, site launch brings a mix of emotion - fatigue from the lack of sleep for the 10 days prior to launch, relief that the site is launching on time and on budget and the client seems happy with it all and finally worry about whether the thing will work as expected, what will everyone else think about it and by god I hope the server doesn't fall over on Day 1 under load... My grandfather was an engineer for Philips and he described to me the same feelings when they were launching a new product so I have a sense that irrespective of discipline, team based endeavours in engineering always foster the same heady mix of emotion fuelled by relief, adrenaline and fatigue. Whilst I am an old hand at this within this industry these days, having been here since the dawning, it is great to watch members of the team for whom this is the first of many site launches in their career and their happiness that it is done and their complete pride in their work. Having seen photos of workers completing railways and other major constructions in the 19th and early 20th century one can't help notice the parallels of young engineers completing a job regardless of whether they are working with steel, glass or lines of code.","['media', 'web']","['web', 'media', 'development', 'internet', 'mobile']","[0.6480472146004113, 0.6165715295391995, 0.31964987499468217, 0.30238902580180266, 0.3004843849905182]","['development', 'internet', 'mobile']",[],[],[],True,2
2008-01-31-the-state-of-oz-technology.md,The state of Oz technology,"['linux', 'mobile', 'security', 'web']","The state of Oz technology
Rarely does an entire country entice me to start ranting (and at this point I'll point out I am in fact Australian) but by crikey Australian technology hasn't really moved in the last 5 years. Now I appreciate this is a sweeping statement and I'll point out that the technology I'm talking about primarily is media based - mobile / web / internet. I have also had the benefit of living in London for the better part of 10 years so I've been at the hub of what is going on. What I don't understand is why is it that for a nation that was at the forefront of new media ten years ago are we now in a position where nothing has shifted for the last 5. SMS is still massively underutilised and the idea of an SMS shortcode in Australia is a joke - 8 digits is only 2 shorter than a mobile number so is hardly short! Indeed everything to do with mobile is still more expensive, slower and less polished than we are used to in Europe. I went to Vodafone when I got here and asked for a pay as you go sim card for my phone that had pay as you go data on it... I was met with blank stares - Telstra and Optus were both the same. General Internet access is similarly expensive and slow compared to what we are used to in Europe. Given a relatively modern telecommunications infrastructure, why telcos are flogging the ADSL route instead of fibre / cable begs the question of why so many roads were dug up in the capital cities to facilitate this in the late 80s and early 90s. What is also interesting is the lack of FOSS out here. Linux is relatively popular but no where like it is in Europe. Indeed corporate America has it's laser telescopic sight firmly trained on the Australian market and even getting Linux hosting is no where as simple as getting a site hosted on a windows server. Linux certification and knowledge is still seen as a specialist skill. Overall I'm disappointed that Australia hasn't maintained it's lead in Internet technologies. In part people like me are to blame for starting our careers here and then being drawn to the brighter lights of the UK and the US where visas are easily come by, pay levels are higher and the ability to work on cutting edge technologies are plentiful. Perhaps we are on the verge of a change in Australia and I hope that some of the ground lost can be regained over the next five years.","['linux', 'mobile', 'security', 'web']","['web', 'mobile', 'linux', 'security', 'development']","[0.6453154555528359, 0.6306672688883231, 0.5975164710596473, 0.5889153653047313, 0.30702606359902856]",['development'],[],[],[],True,4
2008-02-12-why-industries-can-still-be-revolutionised-on-the-web.md,Why industries can still be revolutionised on the web,"['business', 'design', 'media', 'rant', 'strategy', 'ux', 'web']","Why industries can still be revolutionised on the web
I'm a bit of a cynic really. Anyone that's trawled through the depths of this blog will know that I have a fairly acid tongue when it comes to technology. I am a walking example of the phrase ""familiarity breeds contempt"". One of the projects I've been involved in recently has started generating press just by virtue of it being better than anything that has preceded it in this particular industry - I personally would have preferred them to be commenting about the content but any press is good press as they say. By rights I should have a nice warm fuzzy feeling about having a site people talk about and it's always great to receive recognition for a job well done - especially for my more junior staff who have worked damned hard on the site - however it is disappointing that we still exist in an age online where just applying some good design, good information architecture and some well balanced technology is enough to turn an entire sector on it's head. Apologists will hold up their hands and say ""we're a young form of media - it's going to take time"". I however am not in this camp - how much time do we need? Personally I find it untenable that there are still sites being built using non-standards based HTML and CSS, that sites beyond a couple of holding pages are built using things like Dreamweaver and not content managed, that <b>good structural web design is something that still amazes people rather than being the norm</b> and that information architecture still hasn't found its way to the hearts of 95% of the digital agencies that service the web. I am constantly lamenting the state of most industries' websites generally. Take a tour around the leisure industry and find a website for a hotel anywhere in the world. Look at most ecommerce sites for even big retailers and certainly go anywhere online in the government, volunteering or political sectors and you are sure to be assaulted by bad design, bad technology and most importantly bad information architecture. Even five years ago there were excuses that bore merit - changing web standards and platforms, variation of Internet connection speeds and different levels of web penetration in different markets. These excuses don't exist any more. And to be honest why was it when I was learning my craft as a developer all those years ago that I was told about things like usability, information design and later information architecture but the junior developers and designers now are not... This is why there are still industries to revolutionise if you have the contacts, the desire or the contracts to do it. Here is my short list of the biggest problem industries: 1. Tourism and leisure Get some good design and photos, don't use bog standard templates and for goodness sake stop sending my credit card details in unencrypted email. 2. Holiday / travel booking Get some fuzzy logic in your scripting. If I can't fly tomorrow but I can fly the next day tell me without making me guess. Also make it easy for me to bounce back and forth between different trips without having to start again. Remember all those lectures about how to maintain the state of a system in Computer Science... this is what they were for. 3. Retail Keep your site updated with accurate stock levels. I also shouldn't have to go to the end of the check out process to find out what the shipping charges are. Do a detection on my regional settings or IP address and take a best guess and say it's a guess. 95% of the time you'll be right and I'll stop having to go back and forth. 4. Service Media When will you learn that a flash site turns off most people as does a splash page. At least have an alternative HTML site so I can find your phone number / contact email or address. Also remember that table based design was around in 1997 - time to get with the times guys. 5. Volunteering / politics Yes I know you are on a budget but just because someone you know or your favourite intern just happens to have a copy of dreamweaver doesn't make them a professional web designer or developer. More harm than good is done by casual development - find some budget, find someone aligned to your cause and they'll do it cheaper or for kudos value and develop a site worth looking at. 6. Government Just because a turd is shiny doen't make it worth anything. Above all make sure someone in the procuring department knows the difference between HTML and CSS and you won't get shafted. Government expenditure online is extortionate for the value achieved. Given the amount of paperwork done for any bit of government work it is amazing that Information Architecture isn't put right to the centre of the brief... how many people using [direct.gov.uk](http://www.direct.gov.uk/) would that help? So get stuck in and lets see some other industries and sectors turned on their head. It's about time the biggest information resource in history got a bit of a spit polish and had all the kinks straightened.","['business', 'design', 'media', 'rant', 'strategy', 'ux', 'web']","['web', 'media', 'rant', 'business', 'ux']","[0.6517398318298742, 0.6209810995440597, 0.613908093503565, 0.6028078879282964, 0.5886595691573305]",[],[],[],[],True,7
2008-02-20-dvd-jon-strikes-again.md,DVD Jon strikes again,"['drm', 'media', 'piracy', 'rant']","DVD Jon strikes again
[DVD Jon or Jon Lech Johansen](http://en.wikipedia.org/wiki/Jon_Lech_Johansen)
as he is more commonly known gets a lot of love here. This great Norwegian
famously broke the DVD encryption put in place by the big firms with the
release of some software primarily aimed at allowing DVDs to be played on
computers and unlocking the regionality of DVDs and DVD players. When he released DeCSS he ran afoul of the [US
DMCA](http://en.wikipedia.org/wiki/DMCA) and was almost charged, he was then
indicted by Norwegian authorities acting on behalf of the US who actually did
go to court twice to try and convict him of hacking. Both times they failed and
decided not to go to the Supreme Court. Imagine our complete amusement in the office when we find out he's now trying
it on with Apple via iTunes. iTunes is a love it or hate it product - if you are part of the Apple / Steve
Jobs faithful it is obviously the greatest thing on earth, if you know nothing
about technology it's a simple product that allows you to use one of those
""fangled new digital music type thingies"". If you are a techie you see it as a proprietary lock in and try and avoid it
like the plague. The main issue for most techies is you can't play your music
on anything other than your PC / Mac that has iTunes installed and your iPod /
iPhone / iTouch. I've [railed against lock in](/2007/05/03/drmed-for-life/) for time immemorial -
just a quick count of my personal items puts the following music players at
my disposal - mobile phone (x2 because my wife has one that can play music
too), MP3 capable stereo, PC (x3 - my office, my home and laptop), PSP, Xbox, a
real MP3 player and my Nokia Internet Tablet - 10 devices at my personal
disposal that I want to play music from and indeed do play music from. The thing is, I know how to do all of this so I just push the files around on
memory cards or over my network (streaming from my media server for example)
onto the various devices. For many people this isn't possible and Apple's
enforcement of the iTunes lock ins firmly violate the right I have to play my
music (or video) on whatever device I choose at whatever time I choose. I also
vote with my wallet and don't buy tunes from Apple. What DVD Jon has done with his software (available from
[DoubleTwist](http://www.doubletwistventures.com/dt/Home/Index.dt) for free) is
allow you to take files that are locked into iTunes and essentially it plays
the file, re-encoding it into a format you can play on other devices (I haven't
looked properly but presumably OGG or MP3). Just to rub salt into the wound he's going to cause Apple and the US music
industry, he's decided to let you share your files with friends as well. One
wonders how long it will be before a writ arrive from the RIAA and Apple... I'm
sure they'll be racing to get in first. So well done Jon - keep up the good work and keep fighting the good fight -
media we have legitimately purchased is ours to use on any device we own for
our personal use. Eventually the media industry will wake up and realise where they've been going
wrong. Perhaps if EMI had taken notice of the way the world was going they
wouldn't have had to cull a couple of thousand staff.","['drm', 'media', 'piracy', 'rant']","['media', 'rant', 'piracy', 'drm', 'mobile']","[0.6268912877434504, 0.6124060052985133, 0.5917880344121862, 0.5917851912423934, 0.32336738235944906]",['mobile'],[],[],[],True,4
2008-03-15-security-101-the-user-should-be-able-to-authenticate.md,Security 101 : The user should be able to authenticate,"['rant', 'security', 'ux']","Security 101 : The user should be able to authenticate
Are you listening Barclays? I like security - particularly data security and in very particular data security that protects my personal information ([unlike a certain Uk government department a few months back](http://technologytreason.blogspot.com/2007/11/why-was-data-being-passed-on-disc-and.html)). However, I've been around this game long enough, worked for a [bank](http://www.citibank.com/) long enough and built more web applications capturing user data for long enough that I know there is one fundamental truth when it comes to data security and that is: **pragmatism**. When I was at Uni I was told, ""The only secure system is one that has no network connection, no keyboard or mouse and most of all no users"" (and I apologise [Dr Fekete](http://www.it.usyd.edu.au/about/people/staff/fekete.shtml) for bastardising your phrase but you can't have done a bad job for me to remember it 15 years later!). However the flip side of all of this was that depending on the data being protected, the security protocol should be appropriate without undue burden placed upon the user. Which is why logging into [flickr](http://www.flickr.com/) is trivial but logging into your bank should and is a more arduous affair. Banks are very secure enviroments which is good because the last thing I want is some 13 year old [script kiddie](http://en.wikipedia.org/wiki/Script_kiddie) making off with the tens of pounds in my bank account. Having said that, the bank should never make it difficult for me to get to the tens of pounds in my account due to security reasons. At the moment though banks are running very scared and they are nailing the customers because of it. On my recent trip to Australia I had my card stopped no less than three times because Barclays decided that the activity looked fradulent. Initially I thought something serious had happened but a call to Barclays got them to right the problem which was part of their new security measures. The next time it happened was because Barclays decided that it was time for me to come home and that I shouldn't be using my card in a Fraud Capital of the world like Sydney. The third time it happened though it locked my account out entirely and I was told I would have to come into a branch with identification documents to sort it all out - except there aren't any in Australia and I was leaving the next day for Hong Kong. Luckily a very understanding parent lent some cash. I applaud Barclays' sentiments - they really were trying to protect my account, however it would appear as though client / bank trust has disappeared and I can no longer say ""I want access to my money globally"" without alarm systems going off all over the place. If I was backpacking I'd have been in serious trouble as without a bailout I literally had about 10c in my pocket. Upon return to the UK Barclays' statement was along the lines of ""Sorry but we're dealing with a lot of fraud and it's better to be safe than sorry"". Tell this to one of my employees who just had £3K wiped out of their account due to identity theft (spent on local UK products and didn't fire off a single warning) and they are being told they have to prove it wasn't them... In a way I feel sorry for Barclays because they are damned one way or the other - on this issue though it should just be a case of phoning and doing a vocal authentication then saying ""I'm abroad for 4 weeks allow any transactions from xyz country until I say otherwise"". In this manner everything other than DDs occurring in my home country should be treated as fraudulent and everything authorised abroad should be fine... Bring on the chip in my hand is what I say...","['rant', 'security', 'ux']","['rant', 'security', 'ux', 'web', 'media']","[0.6189823209309034, 0.6082028373159978, 0.5859217567992037, 0.3289722349724434, 0.312402694924392]","['media', 'web']",[],[],[],True,3
2008-04-21-can-yahoo-really-get-things-so-wrong.md,Can Yahoo really get things so wrong?,"['censorship', 'internet', 'privacy', 'rant', 'web']","Can Yahoo really get things so wrong?
Yahoo are one of the original dotcoms. They've been around for a **long** time so they should know their business. Imagine my surprise when one of my clients starts complaining that their confirmation emails to yahoo email accounts are permanently being binned as is everything else they send - including personal communications. Like most mail providers, free or otherwise, Yahoo have a spam policy that will look at an inbound email and then drop it in your inbox or spam folder depending on how it is classified. As with most techies I have about a dozen email addresses at various providers in order to test exactly these sorts of issues. Especially given that the goalposts are changing all the time. Sure enough even a personally addressed confirmation email was killed as it came into my yahoo account. ""Ah ha,"" said I, ""they've been blacklisted"". So off one goes and checks the various blacklisting sites and there's nothing there. Hmmm. It transpires that yahoo have just taken it on themselves to block that domain. Weirdly though, a personally addressed mail to me from the client with only the word ""test"" in the subject line is still considered Spam yet an email from some random address that doesn't reply, containing several instances each of the words ""penis"", ""cock"", ""viagra"" and ""cialis"" made it through to my inbox completely unscathed. At this point the phrase about arses and elbows definitely comes to mind. Trying to get Yahoo to do anything about this issue is similarly problematic as there are no feedback channels to deal with this problem at all. So overall we've just had to advise people to not use Yahoo or to check their junk mail periodically and read the mail there. _Update - The folks at Yahoo came to our rescue after tracing through the ""network"" somewhat to find someone that knows someone at Yahoo to help us out. Unfortunately their techies couldn't explain why we'd been black listed either but we are now officially on their whitelist so big thanks to the team for helping us out._","['censorship', 'internet', 'privacy', 'rant', 'web']","['web', 'rant', 'internet', 'censorship', 'privacy']","[0.6398847418647451, 0.6172781137271275, 0.6121078230428265, 0.5899954733725187, 0.5868590114526656]",[],[],[],[],True,5
2008-04-22-phorm-over-function.md,Phorm over function?,"['internet', 'media', 'privacy', 'security', 'web']","Phorm over function?
Phorm is, and will continue to be for some time I think a hugely divisive issue online. [BBC have another story today about it](http://news.bbc.co.uk/1/hi/technology/7359024.stm), this time having spoken to the various security companies like F-Secure, McAffee etc about whether they will flag a message to the user about whether Phorm has been enabled or not. Phorm management have come out saying ""it's only a cookie"", the same as many other sites use to provide tracking (such as Google Analytics), interactivity (such as shopping carts or ID maintenance on numerous retail sites), or a small amount of memory (configuration information for the BBC home page for example). The difference, though, is that the information is being used differently because data is being shared. This is what got the Information Commissioners Office's back up because sharing data between companies without users opting in is a breach of the Data Protection Act - ""But not if it's anonymous data"" say the legal eagles from Phorm - and technically they are correct. This is a case of adopting the letter of the law rather than the spirit of it. Tim Berners-Lee came out saying he would move ISP if he found out they were using Phorm and whilst I admire his line I fear the vast majority of consumers won't care or rather just won't be bothered to switch - just see how many people actually switch bank or utilitiy companies. For me this is a case of the slow erosion of privacy at the hands of our ISPs. In a massively competitive market where margins are being squeezed ever tighter, the sale of their user data to Phorm must have seemed like the proverbial golden goose. It won't take long for someone to cotton onto the flip side of this and market aggressively on the privacy front. Talk Talk made huge inroads as an ISP on the back of their ""The Internet should be free"" campaign with regard to price (being bundled as it was with other services). Who will be the first to play the ""Internet should be private"" card and sign up to a deal **not** using Phorm or other tracking software? In my cynical world view, I think the security firms have realised this and it is 99% of the reason for why they are looking at it all as the anti-spy, -mal and -virus software is worth billions. In real terms Phorm isn't actually that clever a piece of technology - most of what has been achieved is in the brokering of deals between ISPs and content owners and then a bit of clever gluing in the middle. In the end Phorm will either be a great white elephant and just slip off the radar the way many technologies and companies have done or else it may actually be a spur to drive privacy legislation forward in line with our digital behaviour - how long it will take to do this however is the question as government is typically a long way behind technology in terms of law-making.","['internet', 'media', 'privacy', 'security', 'web']","['web', 'media', 'internet', 'security', 'privacy']","[0.6305619977392165, 0.6216993558303909, 0.6037584326384721, 0.6008146709632417, 0.5884597088348644]",[],[],[],[],True,5
2008-04-27-easy-product-or-class-rating-system.md,Easy product or class rating system,"['algorithms', 'development', 'internet', 'web']","Easy product or class rating system
So you've got a lovely little ratings system going on your site. All of a sudden
though you get slashdotted, dugg or just your marketing starts working and you
have thousands of users all rating your products / services / systems / posts /
videos etc and your pages start to creak. ""It's the shared web space you're on,"" say your techies, ""it can't handle the
users"" and duly bounce you to a better hosting environment at triple the cost
along with the migration charges. From time to time I come across this problem when I've either picked up code
from someone else or else a techie asks me how to optimise a page that's running
really slowly. In this particular instance it was caused by a ratings system in
the style of [Amazon](http://www.amazon.com/) or [YouTube](http://www.youtube.com/) -
basically a user is displayed a product and then people rate it as to whether
it's any good. The real problem came when they had a list of products, each of
which had it's individual ratings displayed. The cause of this very slow page however had nothing to do with shared hosting
or otherwise or direct server load - it was all down to some naive coding
executing what my old CS lecturer would call an O(n)2 process. What the coder had done was get a list of products, then for each product gone
back to the database and got a list of all the rankings ever made and then
averaged them out. Nice and simple but frightfully inefficient and that which
caused the problem I've highlighted. This isn't the first time I've seen this and I've been asked how to build them
numerous times as well so here's a well optimised method of doing it in general
terms. Consider first that calculating the average when you insert into the database
is going to be computationally less expensive than calculating it every time
you perform a select when a user hits the page. This sounds obvious but it's
stunning how often it's overlooked. Make two extra fields for your product table, one called average and the other
called user_count or something. On your insert of the rating into the ratings
table, run a trigger or else add some code that will update the product table
with the updated count and a new average calculated from the ratings info. Now when you select the product data you pull down the average and user count
as part of that select and they are just simple static fields, thus adding
no more computational load than the original select or view does already. This gives you a nice little rating system that's not heavy in terms of
processor load. However we can improve things once step further if you aren't
interested in the data. The option I'm providing below is good if you are just after a running average
and don't care about the individual ratings being kept. I did a project
recently where we weren't worried about keeping individual ratings data
because the site wasn't going to be up for very long and it didn't add anything
to our system to have it. This option uses a running weighted average in order to just update the data
in the product table without requiring a ratings table at all. Some useful background maths though: If I have a set {3, 4, 4} and take it's average I need to add the numbers and
divide by the number of entries. Thus this set's average is (3+4+4)/3 = 3.67 Now suppose I've precalculated this average as I've suggested above and stored
it without the individual ratings, I now want to add another rating, 2 to the set. Intuition says to do something like this: (2 + 3.67)/2 = 2.83 which is actually
wrong. Looking at the set {3, 4, 4, 2} we can guestimate that the average is
going to be somewhere more between 3 and 4 than it is 2 and 3 as we've
calculated above. Thankfully a technique from statistics gives us an option here which is to use
a weighted average instead. This is useful for adding sets together that have
different numbers of elements within them but maintain the averages by skewing
the data using proportional averages (or a weighted average). The general formula for this is: Where: `Avg1` is the average of the first set `Avg2` is the average of the second set `n1` is the number of elements in the first set `n2` is the number of elements in the second set In our example this simplifies even further because our second set is actually
only one item. So let's work this through: Which is the answer we're after for our average. As we know all the base line average data in the product table and we know the
value of the rating we're tracking, it's a very simple function to update this
instead of doing another insert into a ratings table and we just keep on doing
it for every rating that has been added. Computationally this is a very inexpensive process and whilst I'm more than
happy to be shown otherwise I think this is about as good as it gets in terms
of optimisation. The key thing is we've now reduced an O(n)2 operation to O(n) which is a
drastic improvement as n gets larger.","['algorithms', 'development', 'internet', 'web']","['web', 'development', 'internet', 'algorithms', 'media']","[0.6354127229567518, 0.6352219248075409, 0.6129446838707527, 0.5793686510471369, 0.31021896526975307]",['media'],[],[],[],True,4
2008-05-02-ubuntu-8-04-truly-desktop-linux.md,Ubuntu 8.04 - truly desktop Linux,"['desktop', 'linux', 'os']","Ubuntu 8.04 - truly desktop Linux
I'm quite an [Ubuntu](http://www.ubuntulinux.com/) fan, having followed the project since more or less it's original inception. Given the general lack of problems with it thus far you'll notice very few entries on this blog about it. Indeed various clients of mine are running Ubuntu servers that are easily maintained, easily managed and just generally easy and have been for several years. It's not necessarily an industrial strength OS - [see Fedora for example](http://fedoraproject.org/) - but for quick deployment, great security and stability and a modifiable tool (thanks to its Debian base) that just gets the job done you don't really need to look much further. But I think that's about to change. You see Ubuntu 8.04 (the latest version that also happens to be a Long Term Support version) has markedly shifted the goalposts of what I expect from a Linux distribution. I've been wanting to be convinced to move to a complete Linux desktop for the better part of 10 years but there's always something holding it back - lack of support for a media type, lack of drivers for particular bit of hardware, issues to do with wireless, no power management for my laptop, I can't run some third party apps like Skype... but that has all now changed - and changed in a massive way. As I'm want to do, every time a new version of Ubuntu comes out it is duly installed on my Acer Travelmate notebook - a very good test of whether an upstart OS ""just works"" or not. The machine is about 2 years old but it has some quirks such as it has an ATI 3D card embedded on it's motherboard that was difficult to get working properly even on XP, it also has an inbuilt webcam - again with proprietary Acer drivers and it has gigabit Ethernet. Oh and it's widescreen. About 9 times in 10 I don't even get to a working desktop without some hackery of graphics drivers, x.org files and I've even had a couple of ""bomb-proof"" distros just not even boot up to a command line. I've been around Linux for a long time and I know what to expect, I'm an enthusiast and advocate so none of this surprises me at all and I'm prepared to work through the issuses. Most of the time I get to a working desktop with some sort of graphical interface that is mostly not widescreen, with no 3d support, sometimes wireless and without the use of the webcam. Linux isn't aimed at desktop use - it's just a side effect of people using it for development who wanted some creature comforts whilst working - notably the [Gnome](http://www.gnome.org/) and [KDE](http://www.kde.org/) bods. Imagine my surprise when I booted Ubuntu 8.04 and I logged into a graphical desktop that detected wireless and gigabit ethernet, properly displayed my screen in widescreen mode, gave me the option to run my ATI drivers easily and then configured the 3D in a few seconds and on top of that gave me a working webcam that I'd never had running under Linux and you could tell from the whoops of joy that here was something worth formatting my hard drive for. Every device I threw at it was auto detected and installed in moments, flash drives, USB devices, a weather station, even an old MP3 player than needed proprietary Sony software to synch on XP. All handled with aplomb and with scarcely a pause by the processor. What the hell was going on? How did we go from solid and okay 7.10 to this awe inspiring 8.04 in just six months? Had Mark Shuttleworth finally given his soul to Beelzebub in exchange for the most promising distro to date? Then the answer came to me in a word: Vista. Vista - that problematic and misbegotten child of Redmond that has been causing havoc in the IT world for nearly a year now. I haven't installed it on a work machine, neither has any other techie I know that wants to ""Get Things Done"". My dad had it and tried it daily for 6 months - he's now back on XP. I know corporate users who've had it on new machines and reverted to XP in order to decrease the amount of support required for users. Shuttleworth and his cabal of Elite Ubuntu coders have recognised a change is in the air - particularly in Europe that is Linux's stronghold - we have an opportunity to put Linux on the desktop of millions of users who might upgrade to Vista but are worried about its impact. Couple this with a slight economic downturn and people are worried their existing hardware just won't work with Vista thus leading to a higher upgrade cost. This latest LTS version gives novice and power users alike the ability to do anything they want with their desktop and it just works. It gives corporate users the knowledge that they have the security of support for 5 years without the rug being pulled out from under them. We bit the bullet this week and put all our support team onto this version exclusively - WinXP was nuked off their machines. The development team are all dual booting but the number of XP desktops seem to be fading from view at a very fast rate as the requirement to just ""drop in"" on Windows becomes less necessary. We've been saying it for nearly a decade but ""this year is the year for desktop Linux"" and with 8.04 Ubuntu the excuses for moving OS can now be left at the door thanks.","['desktop', 'linux', 'os']","['linux', 'os', 'desktop', 'web', 'internet']","[0.6097529657670965, 0.6093293698010883, 0.5899595434339834, 0.32755083145944824, 0.3167567454773108]","['internet', 'web']",[],[],[],True,3
2008-05-09-eeepcs-power-is-in-the-network-not-the-machine.md,EEEPC's power is in the network not the machine,"['internet', 'linux', 'mobile', 'os']","EEEPC's power is in the network not the machine
It's official - I definitely am in love with [ASUS' EEEPC](http://eeepc.asus.com/global/). I liked the idea when they first came out and specifically trawled around Hong Kong computer markets to find one not long after they were launched. It's not the Apple Air or iPhone kind of aesthetic lust, I'm talking about true ""in sickness and in health"" type love when it comes to the EEEPC. Indeed for someone to now take this device off me it really would have to be from my cold, dead, rigamortis-set fingers - and then only with a saw. Go online and look at reviews. They fall into two camps - those who think it's great as a second machine that just happens to do a lot of funky things (see latest Linux Format June edition for a classic example) or those that just don't ""get it"" and wonder why the hell anyone would want a tiny-weenie machine when you can get a low spec dell for a few hundred quid now. There is also a third camp - who are starting to realise that a linux based UMPC is a truly brilliant bit of kit and it's because of the network it sits on not the thing plugged into it. I've had mine for about 5 months and realistically I've installed about half a dozen bits of software - 10 at a push. I can do docs, review spreadsheets, skype, web browse - hell even play games if I want and when hooked to a network I can do all of these things with all of the files I could possibly want. My machine comes home and it auto connects to my home network, syncs to my media server and can play all my media files out of the box. I can check my mail and actually read it without squinting without firing up the laptop. I can connect from home to work via a VPN and mod some files for a client without leaving the sofa or the garden and be doing what is needed before the laptop has finished booting to a desktop. At work I can use it for presentations and taking notes on projects without printing stupid amounts of documentation and hefting my laptop along with me. It's not a replacement computer - it's a tool -  <b>a finely shaped, infinitely configurable tool</b>. All the things I want in my phone but will never get because of the lack of keyboard, mouse and processing power and without it being much bigger. The thing is I'm a techie, if I'm talking a walk down the street phone and wallet are it. If I'm going somewhere then it's satchel with camera, book, PSP and now EEEPC in place of a laptop. ASUS have released details recently of a new version designed to hit off the people who think the EEEPC is too small. I don't know myself. Small is beautiful and in this case perfectly formed.","['internet', 'linux', 'mobile', 'os']","['mobile', 'internet', 'os', 'linux', 'web']","[0.6207401960282234, 0.6111211989622636, 0.605024358091539, 0.6016989321655517, 0.31581652763247553]",['web'],[],[],[],True,4
2009-07-21-the-golden-age-of-mobile-soon-maybe.md,The Golden Age of mobile? Soon maybe...,"['mobile', 'predictions', 'web']","The Golden Age of mobile? Soon maybe...
Some would say that it's already been - during the heady days of GSM Data and WAP, some would say it stalled when European clients pulled all funding from mobile internet apps in the post-dot-com-crash GPRS days, some would say that with the advent of the iPhone we're there in all it's shiny-coverflow-enabled-finger-waggling-goodness. It seems like every second person is now weilding some kind of internet enabled device and in Europe and the US the penetration is even higher than Oz although we are racing for a frontline position showing that reasonable access is more important than either coverage or cost. Half way through 2009 it's interesting to look at some of the predictions for this year - particularly where mobile is concerned and take a quick stock. The big 3 (Apple, MS, RIM) of last year are now well and truly the big 6 with highly competitive offerings from Android who we all knew had aspirations, the re-emergence of Palm with a life-recharging elixr known as Pre and of course Nokia firmly touting its Maemo platform that's been in development for many years and is arguably the most stable and feature rich of all. Costs for data access across the globe are plummeting with Vodafone in the UK offering the first truly unlimited data packages on phones, showing we live in a commodity market that is almost free. EU laws limiting the charges for call and data roaming will see uptake rise as people start using their phones across countries as well. Applications obviously make up a huge part of what our mobile experiences are like and I think if anything 2009 will go down in history as the year of the widget or micro app. Whilst iPhone still only supports Objective-C and Cocoa and their iron control is starting to hinder their progress on this front there are enough people keen to try and make a buck that the ecosystem around applications is phenomenal with over 50,000 available at last count. Nokia, MS, RIM and Palm all have app stores however these are fledgling compared to Apple's and of all the other players Android is the only one that can be considered a contender with approaching 20,000 apps available, the vast majority of which are free. Android has a very hands off approach to this so its interesting to see what makes it through compared to Apple's more militant approach. Being Java based is also helping Android be the largest growing development community too as it's super quick to get up and running. So where will we be in another 6 months? Will we look back and think 2009 is where it all started? I think it's a little premature. We are really at the start right now. Much of what we are doing on phones right now isn't much more than we were doing 5-6 years ago just with a bigger screen and prettier graphics. My money's on 2010 when we see a real rise of Augmented reality applications hit the phones. This is the area that will truly show what carrying the entire Internet around in your pocket can do and has been the spur for this part of computer science this year where it had languished for over a decade. When my phone can alert me when my friends are nearby, interact with environmental sensors, buzz me when a store within 500m is having a sale on an item I'd previously shown interest in, automatically adjust its settings dependent on where I am and the privacy level I want to adopt and filter all of the information on the Internet into a 3 inch screen in a way that is contextual and meaningful then I think we'll consider the Golden Age has started.","['mobile', 'predictions', 'web']","['mobile', 'web', 'predictions', 'media', 'business']","[0.6585547121098221, 0.6324553683508363, 0.5971372857318237, 0.31552437136023703, 0.3134067588507368]","['business', 'media']",[],[],[],True,3
2009-07-26-case-study-django-agile-sportsgirl-redevelopment.md,Case Study: Django + Agile = Sportsgirl redevelopment,"['development', 'ecommerce', 'python', 'retail', 'web']","Case Study: Django + Agile = Sportsgirl redevelopment
I've decided to write this one up because there isn't much on large scale and high speed Django development as yet and this is all still fresh in my head so it's worth getting down on paper (or screen as it were). The agency I work for, [Citrus](http://www.citrus.com.au/), works with [Sportsgirl](http://www.sportsgirl.com.au/), an iconic Australian Fashion Retailer and we were commissioned to help them build a community component to their site to help create a social shopping experience. The [store](https://shop.sportsgirl.com.au/) was already there and was built as a bespoke Flash / .NET application and we had the opportunity to sit this on a different box in the data centre anyway. We thought this would be a fantastic opportunity to use [Django](http://www.djangoproject.com/) and is exactly what it's designed for. Architecturally we are using a LAMP stack using RHEL 5, Apache 2, mySQL (yes I know but it's to do with hosting) and obviously Django. Process wise we actually use an agency version of [Agile](http://en.wikipedia.org/wiki/Agile_software_development) that allows a collaborative effort between Designers, Application Developers and User Interface Developers. Overall we were on a fixed deadline that meant the production phase was less than 8 weeks from sign off to go live including production of the site, interface and design then lock downs for content population and testing. To make this work, everything was based around the platform - we chose as a base Django 1.0 and then layered into it a stripped down version of [Pinax](http://www.pinaxproject.com/) (we currently use v0.5.1 - the current official release, with updated apps) that has user profiles, avatar and gravatar functionality, photologue photo / image management, blog, pyBB forums, user voting and commenting. With an established platform all three teams could start working concurrently much more effectively. This is one of the biggest benefits of Django and working to a framework and platforms like it because code can be prototyped so fast to a development build that everyone can see what they have to play with - Thanks to [@jtauber](http://twitter.com/jtauber) and team at Pinax for that as well. From there it was a case of lots of designing, interface creation, development and review to get it into it's final state ready for testing. During this time we also worked on the flash home page produced by our [flash master](http://twitter.com/craigk) complete with nice collision detection, and full modularity so maintenance on this is all about creative not about development every time there's a refresh (very often on this brand). We'll cover this in more detail at some point. The final phase saw deployment to the live environment which we did in [Amazon EC2](http://aws.amazon.com/) for launch. We did this primarily for scalability reasons as the launch was going to be pretty large and promoted both on and off line. As part of our final testing we also performed a lot of optimisation, this was based around optimising queries Django was making to the DB on both ends and we also then rolled out our delivery optimisations. The first part of this was to implement [memcached](http://www.danga.com/memcached/) which is simply one of the best pieces of software presently available for data driven applications. On launch day we had a cache hit rate of over 80% which meant only 20% of all possible queries were going through to the database. With a couple of hundred thousand people visting the site during the launch phase this was instrumental in keeping particularly RAM usage low on the DB server as well as removing any bottlenecks to the Database due to latency. We used nginx alongside apache to deliver all the static files on the site (not least because the imagery is so hi-res it was killing Apache to serve it!!). I'd often wondered how well this would work with a reasonably trafficked site but I wasn't disappointed. nginx dropped the load off the apache server which struggles for both CPU and memory (even with static files served outside of Django) from peaks on pre-live at 90% CPU and 70% available RAM + SWAP to 25% peaks on CPU and 30% RAM which is what Django was using to deliver pages with Apache's overhead. The site went live on July 8, 2009 coinciding with a very large in store, off line and online campaign that drove quite a bit of traffic to the site. The server functioned exactly as required and with the optimisations peaked at only about 60% utilisation. Overall this was a great project to work on not least because of the Agile process coupled with a technical foundation that allowed us to work even more collaboratively. 8 weeks for a major site launch is hard work for everyone at all levels no matter what their involvement. A great team helps with this but having the benefit of fantastic Open Source platforms to get our clients into market makes this even more achievable. Even less than 2 years ago I'm not sure I'd have attempted what the team achieved.","['development', 'ecommerce', 'python', 'retail', 'web']","['development', 'web', 'retail', 'ecommerce', 'python']","[0.6508741190719931, 0.6478370035768233, 0.5873574131985718, 0.5849599168590927, 0.5770118286048115]",[],[],[],[],True,5
2009-07-29-an-unofficial-endorsement-of-the-android-platform.md,An unofficial endorsement of the Android platform?,"['android', 'google', 'ios', 'mobile', 'os']","An unofficial endorsement of the Android platform?
As [TechCrunch](http://www.techcrunch.com/) reported: [Pigs Fly as Facebook and Google work together on an Android  App](http://www.techcrunch.com/2009/07/28/pigs-fly-as-facebook-and-google-work-together-on-an-android-app/) - there's been a few indicators that this might be  happening, particularly with some random mentions here and there on [Twitter](http://search.twitter.com/search?max_id=2901309107&page=15&q=android+facebook) but no one was really expecting anything to occur given the competitiveness between the two businesses. What's most interesting about this (particularly from my standpoint as an [Android ](http://www.android.com/)user) is  that it will be the only other official mobile client besides [iPhone](http://www.iphone.com/); which  really endorses the Android platform as the second runner to iPhone. And in  acknowledging that, it also indicates that [Facebook](http://www.facebook.com/) are considering that Android will have substantial traction in the coming year - not least when you consider there are two dozen Android based phones [slated to hit the market in the rest of  the year](http://www.google.com.au/search?q=new+android+phones+2009&ie=utf-8&oe=utf-8&aq=t&rls=org.mozilla:en-US:official&client=firefox-a) which could make a serious dent in iPhone's penetration. iPhone  launching with the Facebook client has been largely cited as one of the big  levers in it's sales. Smart phones have been around for a decade and there  have been sleek devices previously ([Nokia 7710](http://en.wikipedia.org/wiki/Nokia_7710) for example was just one big  touch screen 3 years before the iPhone launched) but the mind of the consumer  wasn't fired by the opportunities it could provide to them. You only had to look  at the marketing by the telco's around the iPhone launch to see that the  Facebook client was the Killer App for the smart phone in terms of hooking people  in. It gave them a very tangible benefit to owning what would have been the most  expensive handset they'd have bought to date - ""I can keep in touch with my  friends besides calling them..."" With an official Facebook client for Android, the same endorsement has been conferred and one  of the key marketing differentiators has been removed. I'm tipping late 2010 to  be an interesting time as Apple and Google really go toe to toe and start  slugging it out - which will be fantastic for innovation in this  space.","['android', 'google', 'ios', 'mobile', 'os']","['mobile', 'android', 'google', 'os', 'ios']","[0.6693277013901443, 0.6210940158354269, 0.6184829581574733, 0.6024718283757176, 0.5943539248309883]",[],[],[],[],True,5
2009-10-09-web-directions-south-2009-cloud-sourcing-the-business.md,Web Directions South 2009 - Cloud Sourcing the Business,"['business', 'cloud computing', 'conference', 'presentation']","Web Directions South 2009 - Cloud Sourcing the Business
I recently gave a presentation at Web Directions South which was fantastic (the conference I'm referring to here!). The session was on cloud computing and I hope everyone got something out of it. [I've put the presentation itself over at slideshare](http://www.slideshare.net/andrewjfisher/cloud-presentation-31odp) My speaking notes are below as the presentation won't make much sense without it as it's mostly images or single statements. Introduction Cloud computing is a fast moving part of the IT landscape right now and, media hype aside, it does actually represent a fundamental shift in the way we produce and consume IT services. Cloud computing simplified Partly because of where Cloud Computing resides on the hype curve but also because of it's pace of change, understanding the landscape can sometimes be confusing and it's probably best explained by this slide. Today I'm going to talk about what cloud computing actually is in practice, how cloud sourcing can be used in your business as well as it's future direction and some of the traps you need to be aware of. What is cloud computing? Cloud computing encompasses a huge array of services, technologies and techniques. Marketers would have you believe everything plugged into the Internet is a cloud. To understand the distinct areas of cloud computing let's try a little experiment. Hands up if you are right now using some kind of Cloud Computing Service in your business? Okay so if you are using some kind of infrastructure service such as S3, EC2, vCloud or RackCloud put your hand up. If you're using something like Google App Engine or Force.com actively right now, stick your hands up. Okay, so what about those people using Gmail, Google Docs, Office Live, Hotmail, Twitter or Facebook or something similar to that? So nearly all of you are using cloud services right now without perhaps even realising it. So my work today is done as you're all experts... As you can see, cloud computing covers a lot of different services and disciplines. Partly because of press coverage the things you expect to be Cloud Services such as infrastructure are there but so too are things you don't think of such as google maps or Gmail. The networking company F5 commissioned some research not long ago with many CTO and CIOs of large US businesses on what they considered to be THE definition of cloud computing. They trialled 6 front runners for what cloud computing is. None stood out from the rest as a sufficient or complete definition. Googling Cloud computing will give you a heap of results and nothing really convincing either. Infrastructrure Hardware guys generally believe if there's no infrastructure then it can't be a cloud. Web 2.0 Software guys like me generally take the line that it's all about Web 2.0 style applications. NIST Def The National Institute of Standards and Technology in the US have come up with this working definition. The full thing runs to a couple of pages, but here's the guts of it,. Cloud computing is a pay-per-use model for enabling available, convenient, on-demand network access to a shared pool of configurable computing resources that can be rapidly provisioned and so it goes on... Obviously this is a definition by committee in order to be able to get as wide a consensus as possible NISTs definition is great for someone who is firmly entrenched in the cloud community whether as a vendor, seasoned consumer or consultant but is a bit impenetrable for everyone else coming in. So for the purposes of today let's go with something a little more straightforward. Cloud Computing Definition Cloud computing is: A Network based Service, that is available on demand such that the end consumer considers it not their problem I think it sums up the spirit at least of what NIST is trying to say. Let's dive into this a little. It's a NETWORK BASED SERVICE. Cloud computing provides a service over a network of some kind. Clouds are provided ON DEMAND. It is imperative that you can turn the service on and off as well as scale it up or down as needed. Cloud Computing is all about using a commodity so I should be able to stop using it if I need to or only use it part of the time. Finally Cloud Services are Not My Problem. Or yours. Offering the service is going to be making someone lose sleep somewhere but it shifts the provisioning, management and maintenance issues away from the consumer towards the provider. It's like flicking on a light switch. To make my lights go on I don't need to understand how the power gets across the cables or indeed connect the wires up myself each time I want to make it bright. It's not my problem – someone else looks after this for me. It's like Gas, Water or Electricity. This definition is simple but allows us to explore what cloud look like and some of the ways they can work for you right now. Flowers? Before we get into the actual types of clouds and what they can do specifically, it's worth touching on where these things live. Clouds can be Public or Private. It doesn't matter whether you are available to everyone on the internet or just one little part of it. Service clouds just made available to your business are just as important as the massive public ones that are made available to everyone. Public clouds Public clouds are those located out on the Internet and provided for a fee to parties that wish to consume them. Public Clouds are the ones that are being talked about most out in market such as those provided by Amazon, or Google. I would use a public cloud because I either don't want or don't have the expertise to run one privately. Likewise as a business I can look at a public service and think that will do the job perfectly and I just pay to use it  - why bother going and building my own? Private Clouds Private clouds are typically owned or leased by a single organisation for their purposes only. Private clouds are experiencing very large amounts of growth as many very large organisations such as banks and governments start flexing up their IT to provide more services that can be combined and consumed on demand by internal divisions. Hybrid Clouds Much like a hybrid car where you combine something like eco-friendliness with performance, it's also possible to have Hybrid Clouds As you'd expect Hybrid clouds are where businesses are using a combination of public and private components. This provides a huge amount of flexibility to the business as decisions can be taken around which services you are happy to have public and those you prefer to keep private. So now we know where these clouds are located, it's time to look at what they can do. what can cloud computing do? So now we know where these clouds are located it's time to look at what they can do. Service Remember in our definition I talked about how Cloud Computing was some kind of service delivered over the network? Well unimaginatively every time you're looking at something cloud related you'll always see it called Something as a Service. The word Service in Cloud land is almost interchangeable with commodity and Cloud Computing is really all about taking some piece of technology and providing it in the most commoditised manner possible. Cloud Computing Landscape The current Cloud Computing Landscape is made up of four major service areas- Infrastructure, Platforms, Software and Data. Infrastructure and Software as Services are currently the most well known. These have the highest uptake from consumers at the moment – Amazon's Infrastructure Services alone generates over $250M in revenue a year. However there are more services you can use as seen by platforms and Data so let's take a tour around the Cloud Computing Stack. Infrastructure as a Service This is most commonly used form of Cloud Computing currently. It's commodity hardware or infrastructure that is available for consumers of storage or processing. Server room With infrastructure you can go and put your own servers in your own room and manage them yourself or else you can go and use some else's who have built it on a drastically different scale. Usually these are paid for based on some kind of metering such as GB of storage or hours of processing time. The consumer usually doesn't need to manage the underlying infrastructure, they just put the pieces together and configure it as they like. Infrastructure Clouds have really taken off over the last 18 months or so because of the investment businesses such as Amazon, Go Grid and RackSpace are making in their User Interfaces making it quick and easy to provision storage or full servers or appliances. AWS As you can see, being able to manage your infrastructure services Go Grid Is as simple as clicking a mouse. Using Infrastructure Services. So how can I use this? With Infrastructure Clouds I can go and create everything from a single virtual server to host some site or project  all the way through to creating a virtual data centre – in minutes. Because I am a massive cloud geek I just decided one evening to create and run a Neural Network using 300 machines in Amazon's EC2 cloud – just because I could. It cost me about $50 and worked perfectly. Many Infrastructure vendors also provide storage clouds where you can upload files and pay for the storage and traffic. In practice, these services are great for trial projects or for when you need massive scalability very quickly. Melbourne cup Last year for the Melbourne Cup we deployed a Hybrid Cloud to help with web site demand during the Melbourne Cup carnival. Most of the year, the Victoria Racing Club's website is busy but manageable with pretty average infrastructure. The Melbourne Cup is Australia's biggest sporting, cultural and social event with hundreds of millions of viewers world wide. Over the Melbourne Cup Carnival, the site visits ramps up considerably with over a thousandfold increase in traffic, most of which is over only a couple of days and 90% is during about 6 hours on Melbourne Cup Day. Using Amazon's S3 service as a Content Delivery Network, we hosted all our heavy assets such as images, video and flash files. Amazon's EC2 service was used in order to deploy servers on demand as they were needed for extra capacity. Alongside this we then had a private cloud at Web Central that could be configured how we needed it based on the types of traffic we experienced. The solution proved successful with nearly a million visitors on Cup Day and at peak over 200,000 files being transferred a minute. On top of this though, it was also extremely cost efficient because VRC don't have servers sitting around doing nothing for 360 days a year as all of that extra capacity was switched on just prior to Melbourne Cup and switched off 2 days after. Using Infrastructure Services in these circumstances helps you maintain a great user experience and also makes your costs much more manageable and reduces your provisioning time. A lot businesses are using this right now to help with managing their heavy files. Look where Twitter hosts it's images... S3 Amazon Screen shot That's right – Amazon S3 Given the sheer numbers of people visiting twitter now this makes complete sense for them to be able to manage the costs of image hosting and delivery. At last count they had over 60 Billion items in there which is growing at a rate of about 10 Billion every few months so there's plenty of people using this and similar services out there. The infrastructure services are getting better all the time as competition is driving innovation. Platform as a Service Platform clouds will be immensely popular over the next couple of years. They are 1 level up from Infrastructure services and these clouds take away the ""machine"" part of the cloud giving you a platform fully configured and ready to deploy your application. Diving platform This means developers get the on-demand parts of Infrastructure clouds without having to concern themselves with managing a virtual data centre or configuring machines. Certain assumptions are made at the platform level – for example Google App Engine restricts you to certain languages you can use. However in making these assumptions, it means developer has a defined jumping off point. Google App Engine and Force.com are seeing an explosion of developers who are embracing the platform and coming up with new ways to use it. Logo Slide. At the moment platform clouds are in their infancy however they are growing rapidly. The two most well known and heavily used right now are Google App Engine and Force.com which is the platform underpinning Salesforce.com The single biggest benefit of Platform Clouds is simply Speed to Market. The development process is drastically shortened because many behind the scenes decisions have been taken for you. As such the testing time is shortened because if you're using components of the platform they are already tested so you only need to test your code not the Platform's. Additionally you also don't need to go away and build an entire system stack – databases, servers, APIs etc – it's all there waiting for you to come along and do something with it. Ongoing it means a lot less maintenance as well. Developers are looking at Platform Clouds in order to spend more time working on innovations and less time on replication. As a developer, why would I want to spend time writing yet another application that puts some customer information into a database off the back of a web form and then write some little app that allows the customer service team to make sense of it. It's this behaviour that Platform Clouds are addressing and the side effect is that not only do I get the benefits of having a complete system to work with that's developing new features all the time, I get to produce it quickly. Nucleus Research looked at 17 projects done using Force.com earlier in the year and found that speed of delivery had up to a 10 times increase. The average across all projects was about a 5 times increase in speed. Imagine what you could achieve right now if the projects your business is doing could be in market in one fifth of the time it's currently taking you? Just consider that for a second... Developers are citing similar benefits of App Engine as well as some of the other platforms out there though little official research exists just yet. As these platform clouds really mature over the next year or so the pressure will be on for businesses to start using them a lot more heavily as it will be uncompetitive to build equivalent systems from scratch. Software as a Service Salesforce.com has been the Pin Up of SaaS for a very long time – in many ways they defined what it was and probably started a lot of the Cloud Computing discussion as they showed very early on it was possible to commoditise a service and deliver it over the Internet. The reason Software clouds exist is because in the traditional Software industry there is a dirty little secret – maintenance costs more than innovation. Most Software Vendors have a small team coming up with new ideas and developing software then a massive one looking after the support and maintenance of these new ideas. Software Vendors have product lifecycles where they support certain versions of a product until they can justify not doing it any more and then hopefully force the customer to upgrade. During this lifecycle various customers could be on many different release versions and all of this adds to the cost of support. The heart of Software as a Service is that there is only ever one version of a product, delivered over the Internet and all customers use the same version until the next upgrade. Immediately much of that time used for maintenance and support is available for sales, marketing and innovation. Is it any wonder that Salesforce is now on it's way to dominating the global CRM space. SaaS Collage Most software is now moving in this direction and is a big part of what enables Web 2.0 and is transforming the way developers deliver and maintain software for their user base. Look at software like Google Docs – who'd have thought even a few years back it was even remotely possible to use a spreadheet like Excel in a web browser. Consumers of Software Clouds are generally pretty ignorant of all the underlying platform and infrastructure and are only interested in configuring the application itself. Gmail screenshot. There are many applications of Software Clouds, far too many to go through today and my advice for any business procuring any new piece of software for the organisation is to make sure you seriously consider a Software Service in your selection process. As an example let's look at Gmail. I'm guessing a lot a people here are using GMAIL for your personal email however Google has a fully supported Enterprise edition that works for your domain. You can still use outlook if you want or use the web client or mobile client if you prefer. Email for a business is as important as cashflow however for many businesses the management and in particular cost of management of email is significant. On Premises email is something you have to maintain – backups, mailbox cleanouts, archiving, system upgrades etc are all the standard tasks done by an IT manager whether employed or contracted. Even with all this time spent, email still occasionally goes down. Taylor Woodrow, a large construction business in the UK had much this scenario. They are a large business with about 1,800 employees and they were managing all their email in house using their IT team. Last year Taylor Woodrow switched over to Enterprise Gmail, moving away from their on Premises corporate email they'd had for years. Whilst there are still costs with Gmail such as licenses to pay – Gmail costs $50 per user per year - and you still need someone to administer the accounts the cost savings for the business were massive. Over the year they saved about $2 Million compared to their previous mail software. Given that large organisations have a scale of efficiency and they can get great cost savings per user, the benefits to smaller businesses are proportionately greater. For an Australian business that has between 20 and 50 employees it's estimated that many businesses will save on average about $100,000 a year in total costs due to reduced licenses, man power, backups, hardware requirements etc. That cost saving could be ploughed back into marketing, sales or other IT projects such as building your own Software Cloud. Again, this is just one Software Service example but it shows how it's possible to start realising cost savings and get a better solution. Whilst I'm sure everyone here is broadly happy with their email system, are you now or will you ever be the best email providers? Probably not. Gmail can do it better and cheaper than you can. This is the crux of most Software Services – they can be provided, maintained and constantly upgraded to a much higher standard and for less cost than you can do it for and that's why we seeing them grow so rapidly. Data as a Service Data as a Service is the newest part of the cloud computing landscape and I see this as having the most opportunity to shift how we create and consume data and is the one you can get involved in right now.. NY Times Visualisation Data is being provided everywhere and we are just now starting to see the interesting ways that people can use it. Data as a Service provides the consumer with the ability to retrieve and publish data – whether their own or that which is publicly provided - via the service. The consumer gives no consideration to the underlying software, platform or infrastructure, only whether the data is available or now. Data clouds are being used to expose data out to end consumers such as via Retail or Search APIs so those consumers can take them, remix them and provide them outwards again. Data as a Service is built for mash ups – think about all of those sites with mashups of people's tweets plotted on google maps Zappos or this great Zappo's site that shows what products people are looking at on a map showing where they are located. DaaS Applications. Data Clouds are so new that there aren't that many examples to show you yet though over the next 18 months we'll see an explosion in the data that's being made available. Organisations that are starting to do this are people like the US Government with their Open Government or Government 2.0 initiative. Lower level governments are starting to make their data available such as the San Francisco city government who are making available data sets for things like crime data, highway information, and lists of public trees of all things. Whilst these data clouds are very new we are seeing some interesting business models develop out of them. A US company called Jigsaw has recently become self funding. Jigsaw specialises in managing personal data by crowd sourcing contact information from participants and then they use that data to sell to marketers who want to cleanse their own subscription or marketing lists or who want to acquire new customers with very specific requirements. Other businesses are looking at creating industry based data clouds to manage source information such as where livestock have been reared, transported and eventually slaughtered before making their way to market thus providing a traceable and authentic source for produce certification. Layar The other area where Data Services are starting to appear is in the burgeoning field of Augmented Reality. Consumer ready AR is really being driven by and will continue to be driven by Data Clouds as huge data sets are made available to consumers via their mobile phones or PDAs. Layar for Android and soon for iPhone is one such app that allows data sets to be viewed on your mobile device. Perhaps obviously at the moment this is skewed towards things like tweets, photos from Flickr or Wikipeadia entries that are near to you but this will change as organisations start to make their data available. The examples on screen now show you where your local 7-elevens are and some points of interest in Sydney. This space is very much in its infancy right now but it's definitely an area you can get involved in massively – if you're sitting on data make services available to get at it and watch the things people start doing that you never considered. Cloud stack display again We've taken a tour around the cloud computing landscape and you can see there are a lot of areas that you can use. There are also some extremely niche areas I haven't talked about such as Desktop as a Service where your computing desktop is all cloud sourced however we'll leave them for today. One really interesting thing that I've noticed about Cloud Computing is that as you go up the Cloud Stack consumers tend to USE more of those services at the bottom to PROVIDE more of the those services at the top. There's this knock on effect of one type of cloud computing providing the means for another type to occur and it's this effect that is driving much of the growth of the newer cloud types. Now we've seen what's available let's take a look at the future to see where cloud computing is headed. Cloud Computing Future. Cloud Computing is rapidly changing shape right now. In 5 or 10 years the landscape will be as different again as it was 5 years ago. Industries and consumers will be changed by how they interact with Cloud Services. The fundamental paradigm shift that is occurring will allow IT to go back to being an enabler of business. Taken altogether, cloud computing becomes IT as a Service and businesses that embrace this philosophy will be able to do some great things. Here's some examples. Manufacturing Manufacturing will be changed by almost infinite processing power that can be provided on demand  coupled with advanced computational techniques such as Genetic Programming to explore new product designs and get competitive advantage. Health Services In health, for a long time governments in particular have been trying to make health related IT services better, providing a seamless service from one end of the health system to the other. Hybrid Cloud Services will be at the heart of our new health systems where any health professional will have proper access  to medical records so they can treat patients much better. Start Ups Start up businesses with great ideas will be able to be in market quickly, driving innovation and competing immediately with their bigger competitors, amplifying their disruptive potential within their chosen industries. Science & Research All scientific centres will have access to supercomputer grade processing and storage which will drive new discoveries rather than just those with extreme budgets. Presently a lot of cutting edge science and research is done by centres that have almost unlimited funds. Now those with much more modest budgets will be able to use On Demand and Cost Effective cloud services to help their research. New media All online sites and campaigns will be able to deal with large scale traffic and maintain high levels of availability, not just those with large budgets. Developers will be able to take advantage of this scalability and push the boundaries of the content they can deliver and the applications they can create. New Markets New markets will open by providing guaranteed access to data for consumers such as to their music and videos no matter where they are in the world – this is at the heart of services such as Hulu. Opportunities for businesses guaranteeing management and security of users personal data or industry data in so called ""Data Banks"" will start to present themselves. How much would you pay to have on demand access to all of your personal information all in one place that is searchable and secure? Geography As a side effect of all these Cloud Services becoming available, businesses will no longer suffer from geographic location. Businesses in Australasia, South America and Africa will compete directly against Europe and North America. Competition will be based on knowledge and innovation not on available capital. As you can see, all types of organisation stand to benefit from Cloud Sourcing. Warning sign Whilst I've painted a picture of almost infinite computing resources being available, great bits of software being produced and a veritable mountain of data that's about to come online it's not all rosy. With the pace of change of the technology outstripping everyone's ability to react quickly both within Government and Business, Cloud Computing is currently in a similar position to the Wild Wild Web of the early 90s. Clarity is the most important requirement for any organisation producing or consuming cloud computing services. Here's a short guide to some of the things your business needs to address before you start Cloud Sourcing. Disaster Recover and Risk Management Disaster Recovery & Risk Management are no less important than they are in your business right now! Just because clouds are someone else's problem doesn't mean the risk management and recovery issues AREN'T your responsibility. If you want 100% availability you have to work for it whether you are using Cloud Services or not. 100% availability is only possible by combining services whether at your DC or via the cloud. As an example, GMAIL had a recent outage and caused a Chicken Little style panic that ""The Cloud was falling"". Taken in context however, even with the number of people affected Gmail is still more reliable than corporate non-Cloud email which fails quite often. Disaster and Risk management are no less important just because you are using Gmail or some other cloud email service. You need to have a policy to deal with outages just as you would do normally. SLAs SLAs at the moment are the worst part of the Cloud Computing industry. Some vendors don't have any commitment, some do and there's a lot of variation between. Before committing, you need to assess the Service Level Agreement and decide if it's right for your business and right for the type service you're buying and what you're going to use it for. Some applications don't need highly available Service Levels but others do. Data policies Understanding the operational risk with regards to data is hugely important in a Cloud Computing environment as your data is probably going to be more public than you are used to. Existing data policies may need to be updated due to the additional risk of being in a Cloud Environments. Many Vendors are actually better at managing this than their clients as they are doing it day in and day out. Question Before selecting a vendor it's important to ask the following questions and understand the responses and what they mean for your business 1. How safe is your data? Who has access to the physical machines? Can the DC be cross contaminated? In large data centres it is possible for your data to be available even after you've switched off your service. Can this become available to someone else down the line? Can you access your data to move it if you want to leave? Lock in and standards around this are a massive issue that is still not completely addressed 2. How safe is your uptime? What happens if a major hub is unavailable because of some Internet issue? Who do you call when it all hits the fan at the Vendor end? How is their support provided? How do you support your consumers? Who is monitoring your services? 3. Are there any border concerns? Laws are different between Australia and places such as the US and Europe. Crossing international boundaries may bring with it additional legal requirements or may mean your services or data are subject to different laws than you are used to. Legal counsel here is imperative. Traffic light Don't let me put you off. Forewarned is fore armed and none of the issues are insurmountable with the right policies put in place by your business. If governments are using or considering Cloud Services then you are almost guaranteed that the issues with SLAs, Uptime and Data concerns are being addressed right now. Few businesses are as stringent in their requirements as multinationals and government agencies. Also, bear in mind that many of these issues should be taken into account for any of your current IT services anyway so knowledge and policies you have in place now are still relevant for cloud service provision. The important thing to remember is that you need to assess risk against the possible opportunity and  make an informed business decision before embarking on any IT project. Seismic shift. Cloud Computing is THE single most disruptive technology available to businesses right now. We are in the middle of a fundamental change in the way IT works for the business. This is being driven by the convergence of extremely cheap telecoms alongside sophisticated software and commodity hardware has led to an explosion of available computing power and storage. For the first time in our computing history we are approaching the point where actual deployable computing resources are going to outstrip our ability to use them. This creates a vast pool of cheap resource that will be used in innovative and disruptive ways. If you are not using cloud computing actively within your organisation soon you WILL be left behind whilst your competition streaks away. Ticking Clock Competitive market pressures are making this transformation occur so rapidly you have only a handful of years left to make this shift. Revolution Cloud computing is as much of a revolution as the Internet was to business in the 90s but will have occurred in less than half the time. Why? Because Cloud Computing enables not only the commoditisation of technology services but the democratisation of it as well. In the same way that cheap PCs enabled an information explosion and reformed the way we communicate, Cloud Computing changes the way technology is used by everyone. Large or SMALL. When the cloud computing revolution is complete there will be virtually NO distinction between the large and small business with regards to the scale and quality of the technology they can deploy to market. Zero The cost to deploy these technologies will be almost ZERO Time to market The time to be in market will be days and weeks not months or years. Infinite availability The flexibility and scalability of the services available will be virtually INFINITE. What can I do now? How can you start with Cloud Computing now? If you're a business get your CRM onto something like Salesforce, get your email to Office Live or Gmail. If you're a developer, get to grips with something like Google App Engine and deploy your next app there so you can build it faster. If you're about to launch a campaign, use some infrastructure services to support it from the outset using something like S3, EC2 Are you sitting on a pile of data? Make it available through a data API. Chances are if it's about products you'll start selling more of them. Here's some tips on how to sell cloud computing into your business. Cost focussed business If your business is cost focussed – and let's face it, most are at the moment – Cloud Services are Operating Expenditure rather than CAPEX. There's no depreciation, financing or generally up front costs. You pay for what you use and nothing more. Cloud services are generally cheaper than maintaining Infrastructure, Platforms and Software of your own. Providing Data as a Service might lead you to discover additional revenue streams or result in more sales of your core product. Process focussed business If you are a process oriented business then you need to look at starting with small, low risk trials and projects. Look at primarily Software services for a starting point. Make sure you do your homework around SLAs & legals. Most Cloud vendors realise there are issues and are attempting to fix them. You can also consider setting up your own private cloud. VMWare, Melbourne IT, GoGrid and Rackspace all do this and I'm sure would be very happy to help out. Innovation focused businesses If you are an innovation business the key thing to stress is that you can be in market faster by using Software Services or developing on Platform Clouds. Your focus needs to be on how you can innovate using these tools and how they stop you from having to replicate and go over ground that has been covered many times before. For innovation businesses you can trial things out with much less commitment. If the results are poor, switch off the service and the costs stop. If you have a hit you can scale up quickly to accommodate your new market. Innovation businesses will typically combine many kinds of services together in novel ways. Experience across all parts of the Cloud landscape will provide significant competitive advantage in market. Last Slide Hopefully this presentation has helped provide some insight into what Cloud Computing is, what it can do and what you need to be aware of before jumping in. Cloud computing IS a fundamental shift in the way business works. Cloud computing is not about a single technology or a single service. All of the elements come together differently for each and every business. Cloud Computing is primarily a shift in the way of thinking about IT and how IT can enable the business to radically transform the way it operates. Those businesses who embrace Cloud Computing will have a significant business advantage, limited only by their ideas and their willingness to execute on them. How are you going to Cloud Source your business. This article was cross posted to the [Citrus Agency Blog](http://citrusagency.blogspot.com/2009/10/presentation-web-directions-south-2009.html)","['business', 'cloud computing', 'conference', 'presentation']","['business', 'presentation', 'conference', 'cloud computing', 'web']","[0.605981113735297, 0.5803733992398715, 0.5757567821143675, 0.5727272511121114, 0.3362970874180066]",['web'],[],[],[],True,4
2009-10-11-the-only-reason-why-linux-isnt-ready-for-prime-time-desktop.md,One feature away from desktop Linux,"['desktop', 'linux', 'os', 'presentation']","One feature away from desktop Linux
Okay, so this title's probably a bit misleading as there are probably a few reasons but as far as I'm concerned there's only one thing stopping my final transition to desktop Linux for complete every day usage. Presenting In my job I do a lot of presenting. I give major milestone presentations on projects, I present to the business on things that are going on, I present in pitches where we are attempting to win new business and recently I've started presenting at conferences. I would not use my Linux desktop (and I have combinations of [Ubuntu](http://www.ubuntulinux.com/) and KUbuntu 9.04, CentOS) to present with at all - even if someone paid me. Before I say why I'll also lay out my Linux credentials. I use RHEL, Ubuntu and Centos EVERY day. All of my home computers are Linux based, I have a Linux PDA, I prefer my Ubuntu desktop for work and I administer numerous Linux (CentOS and RHEL) servers - via command line - all of the time. I've used it for over a decade and am more than happy with it and more than happy to hack on it to get stuff working. However, there comes a point where I am not going to entrust a complete presentation that our business or my reputation relies upon to Linux's extremely flaky graphics system. Yes, I know laptop Linux is problematic (but if the rest of the desktop is stable why not my second video out?) Yes, I know that graphics card support (particularly from ATI) is very closed so there's lots of reverse engineering going on (but again if I can have one video out working why not two?). I'm not sure why this is the case - I think it's a combination of X.org config and poor tools for configuring multiple screens with different resolutions but it definitely needs a lot of work to go ready for prime time. I was at a [conference this week](http://south.webdirections.org/) and I had built [my entire presentation](http://technologytreason.blogspot.com/2009/10/web-directions-south-2009-cloud.html) in my Gnome desktop using FLOSS tools like [Open Office Impress](http://www.openoffice.org/), had a great looking presentation and was legitimately keen on presenting using either my Ubuntu or Centos desktop. After hours of mucking around however I didn't feel supremely confident in just walking up to the podium, plugging in my laptop and ""It Just Works""TM. It's just too hit and miss. I don't generally experience this with Linux in general and Ubuntu specifically although I am aware of other people saying it. For me 99% of the time it does actually just work. So I defaulted back to my dual-boot Windows partition and presented from that instead. This was the partition that I had considered nuking because I hadn't used it in about 6 months. In this instance though I didn't have any other choice - and sure enough it did just plug in and go. I still presented from Open Office Impress though (which is a fantastic bit of software I might add!) and I think I was the only one at WDS09 that presented with it (and I'm sure no one could tell I wasn't using PowerPoint or Keynote). Desktop experience is exactly that - an experience and our experience, particularly when we are doing something social with a computer can affect our mental state quite substantially. If I'd have taken the decision to present using Ubuntu I would have felt worried about whether my laptop would work and I would have been nervous and probably would have delivered a terrible presentation. In contrast because I knew I wasn't going to have any support issues I felt confident, in control and delivered what I hope was a good presentation to the audience. Ubuntu are trying to address many of these issues with the [Paper Cuts project](https://launchpad.net/hundredpapercuts) but that's really aimed at business. Apple have addressed similar issues (hardware compatibility) by having a presenter's kit (which you buy) which provides all kinds of adapters to go from Mac to just about every video input type. Microsoft addressed this years ago from Windows 2000 with a great set of dual head tools that made it simple and a standardised way for vendors to incorporate them and it is extremely rare for it to fail. Business use is one of the areas that Linux (and especially Ubuntu) has got a real opportunity to shif users across as there are so many other business benefits but users want a single consistent desktop so they aren't going to build on one desktop and present on another - it's too inconsistent. For me this issue on presenting and graphics support isn't so much a paper cut as it is a gaping flesh wound and it really needs to be addressed.","['desktop', 'linux', 'os', 'presentation']","['os', 'linux', 'desktop', 'presentation', 'web']","[0.6140199460379999, 0.6055677787930666, 0.5930234436627005, 0.5905234269949958, 0.32889941732757966]",['web'],[],[],[],True,4
2009-11-09-admob-purchase-by-google-paves-way-for-interesting-developer-funding.md,AdMob purchase opens door to new funding models,"['business', 'google', 'media', 'mobile']","AdMob purchase opens door to new funding models
It's just been announced that [Google](http://www.google.com.au/) is set to buy [AdMob](http://www.admob.com/) for $750M in an all-stock deal. This is the third biggest purchase Google has ever made (the only two bigger are YouTube and DoubleClick). AdMob started in 2006 so they have capitalised very well for a 3 year old business. Indeed they've been cash positive for a while now so this is a great acquisition by Google. The full gory details of the deal [can be found here ](http://news.cnet.com/8301-30684_3-10393623-265.html?tag=mncol;txt) and a [press site by google here](http://www.google.com/press/admob/index.html) We know this is all aligned to Google's interest and in particular their big appetite presently for anything Mobile. However this also opens up some enormous opportunities for developers. This acquisition brings with it some great opportunities for in-application display advertising that is delivered contextually but also based on Google AdWords auctioning technology. Along side this I can then use the same advertising account to drive ads on my mobile website that compliments my application and then use standard ads on my main website that provides additional information / community support etc. All of a sudden a possible revenue opportunity opens up that was kind of there previously but wasn't very smart. Over the last 18 months in particular we've been watching the rise of free-ad-supported applications as well as paid-no-ad versions of the same application. I would expect to see a lot more of the ad-supported apps once this deal goes through. The reason for this is twofold: As a developer I can manage all of my advertising spaces with one vendor. I don't really want to have to deal with all these businesses I just want to get some beer money for my app that I'm spending my non-work hours producing. With contextual ad serving, I can make certain elements of data within the application available and use that to generate calls to the Ad Server - much the same way AdWords works with a web page or in Gmail. This means the ads that are served will be more relevant to the content which should lead to higher Click Through which then leads to potentially more revenue for me (see note above about beer money) This makes a lot of sense for an advertiser as well. Certain applications have huge amounts of uptake - [twitterific](http://iconfactory.com/software/twitterrific) on iPhone or [Twidroid](http://twidroid.com/) on Android for example. Imagine having contextual ads served based on the content of your twitter stream. Twitter might resist it but it could make some serious cash for the app developers. Overall I think this will really blow the top of mobile advertising. Advertisers who have been a little shy in the mobile space will be comforted by the fact it's Google doing it. App and mobile site developers stand to gain some good funding from it and it be relevant for their audiences and as the world goes increasingly smartphone mobile mad over the next 18 months this will be worth serious $Billions in the next 5 years or so. Cross posted to [Citrus Agency Blog](http://citrusagency.blogspot.com/2009/11/admob-purchase-by-google-paves-way-for.html)","['business', 'google', 'media', 'mobile']","['mobile', 'business', 'media', 'google', 'web']","[0.6454272996502394, 0.622987860887465, 0.620310026103419, 0.6137124555561858, 0.3376194949424932]",['web'],[],[],[],True,4
2009-11-13-spdy-could-gain-acceptence-very-quickly-with-some-product-innovation.md,SPDY could gain acceptence - with some innovation,"['google', 'internet', 'web']","SPDY could gain acceptence - with some innovation
Google have announced some early findings about their research into a faster protocol to reduce latency times due to good old fashioned HTTP. HTTP was designed as a really simple protocol to delivery (primarily) text content over the Internet and thus was born the Web. One of the problems with HTTP is that it only really allows a single request to be serviced at any one time. The reason this doesn't APPEAR to be the case is because modern browsers create multiple connection threads that connect independently to the server and it gives the appearance of things downloading in parallel. It's a neat hack and works because we have good network speeds and mast processors to manage all this multi-tasking. Go back to a Pentium II with Netscape 2 and you'll watch the glacial procession of elements loading in from the top and goes down the page. The [Google project page ](http://dev.chromium.org/spdy/spdy-whitepaper)talks a lot about why HTTP pipelining doesn't work and some of the technical architecture behind SPDY which I won't cover here other than to say that it's great we are seeing this type of innovation at the protocol level. What's most interesting for me however is how we get it in production. There is a lot of nay-saying going on around this suggesting that because of the size of the Web you'll never get people to shift to a new protocol HTTP:// won, let's all leave it at that because there are too many web servers and web browsers to convert. This is what I want to address in this post. Yes - there are fair too many legacy browsers to deal with to make this transition happen. Look how many IE 6 browsers are still in use, but we'd also have to shift all the Mozilla users, Chrome users (easy because of forced update) and Safari users as well. Not to mention all those pesky mobile devices that are springing up. Dealing with the web servers is a much more straightforward issue. There really aren't that many in the scheme of things. Indeed much of our existing infrastructure runs multiple servers, Apache alongside a lightweight server like nginx and this is increasingly common. As such there's nothing stopping me dropping in a SPDY server alongside my existing infrastructure for those users that can directly access it (Chrome 4, Firefox 5, Safari 6 and IE 10 for example). But let's not stop there. A network admin could create a software appliance at the Firewall or Internet Gateway level for the corporate network that took HTTP requests, turns them into SPDY requests and then proxies these back. Now I have doubly fast Internet connectivity without upgrading my connection. For the price of a box that is well worth it. For home users we could do the same thing. This protocol is software - it runs on TOP of TCP so because of that a Firmware upgrade of your average Netgear or Linksys home router could get you the same benefits as those above. ISPs could force this remotely on certain systems (Cable for example) or provide info on how to do it such as through a web, phone or personal service. So for all the nay-sayers out there - this is a MASSIVE opportunity to speed up the web and people need to think outside the browser sometimes. QoS was delivered at the router level based on intelligent packet analysis - that speeds up network traffic massively but it's a software change not a hardware one. I don't think it will be long until we see Netgear and Linsys start promoting this like they did with the WiFi standards and force adoption because it makes a great marketing case to do so. I'll be trying this out at the rawest state to see if we can make it work and if I can, watch how fast our servers and network gateway get upgraded before I embark on upgrading client machines.","['google', 'internet', 'web']","['web', 'internet', 'google', 'development', 'mobile']","[0.643091623245334, 0.6263625146245515, 0.5892216821328576, 0.32381641855020415, 0.3128834332775088]","['development', 'mobile']",[],[],[],True,3
2009-12-20-prediction-2010-will-be-the-year-apple-and-google-have-a-cage-fight.md,2010 will be the year Apple and Google have a cage fight,"['android', 'apple', 'business', 'google', 'internet', 'ios', 'mobile', 'predictions']","2010 will be the year Apple and Google have a cage fight
The pre-match slanging is pretty much over and the location of the fight has
been chosen. 2010 is going to be the year Apple and Google finally stop dancing
around and actually get in the ring. Unlike a nice clean refereed boxing match
(Apple V Microsoft) this is going to be a dirty underground cage fight complete
with barbed-wire wrapped gloves - expect to see a lot of blood on the floor -
and fanbois rucking in the concourses. ![Boxer laying on the canvas after fight](../../img/posts/cagefight.jpg)
*[Onslaught unleashed, image (cc) Chris](http://www.flickr.com/photos/icantcu/3447153416)* The ground is, of course, Mobile and the massive dominance both organisations
have taken in this space over the last 12 months. Mobile is still a fast
growing area of communications but smartphones is where it's at. There's no
question Apple ignited the world's imagination of what is possible in the
mobile space and capitalising on the fact that the fashionability of a phone
is important in a way that RIM and Microsoft just didn't get. Google have taken that to a whole different level with Android which just
""gets"" what it is to be a data capable and Internet connected phone. Couple
this with some fashionability and the stage is set for an almighty fight. Looking through the [AdMob](http://www.admob.com/) report for November, it's
astonishing to see how fast Android has grown in the last 2 months (doubled on
traffic requests through their network) but more importantly was the launch of
the Motorola Droid and the whole [Droid Does](http://droiddoes.com/)
campaign. <b>The Droid is one of the fastest selling phones of all time</b> almost
hitting iPhone 3Gs sales levels (which was working from an installed base
upgraded) and is now accounting for about a quarter of Android device share -
only behind the G1 which has been out for 18 months - expect to see that change
over December. Now Motorola have entered the fray and with Samsung and Sony Ericsson both
scheduling major launches into Q1 2010 the mobile landscape is going to get
increasingly messy as the iPhone isn't the only great phone out there. Indeed I
think Sony is going to do a Motorola with
the [Xperia X10](http://www.sonyericsson.com/cws/products/mobilephones/overview/xperiax10) as
it is simply stunning and is a big name in the mobile space - especially in Europe.
HTC have had a great lead but 2010 will see Motorola and Sony return to some
dominance here - and they can fight Apple in the Fashionability stakes. The biggest challenge for Apple is how to combat Google on the phone
itself. <b>Outside of iTunes, Apple has little in the way of first party apps</b> for
the iPhone and whilst it has a huge developer network it is definitely alienating
them through it's App Store management nightmares. Many developers are developing
for both iPhone and Android devices - especially those using Web technologies
for building and apps like [Phone Gap](http://www.phonegap.com/) to cross-package. A lot of what makes the iPhone really useful are Google applications (native
Gmail, Maps and most importantly Search!) - Apple has no way to combat this. Are
they going to deny Gmail or Search like they did with Google Voice? Apps that are available on both platforms and services that are available ""in
the cloud"" (eg Maps, Comparison Shopping etc) dilute Apple's position as it's
only point of differentiation becomes fashionability - and both Sony Ericsson
and Motorola have competed for over a decade against Nokia by building highly
fashionable phones. I'm not sure this fight will be a death match but all the signs are there for a
battle of epic proportions. Both are likely to be extremely battered by the
time they come out the other side and would be wise to hold a little bit in
reserve in case Nokia's Maemo platform takes off the way they are expecting it
to - at that point things could get really messy.","['android', 'apple', 'business', 'google', 'internet', 'ios', 'mobile', 'predictions']","['mobile', 'business', 'android', 'google', 'predictions']","[0.6725394930683614, 0.6242946488341666, 0.6167648590884298, 0.6157662794015376, 0.6156141197261144]",[],[],[],[],True,8
2009-12-22-why-im-interested-in-aws-spot-prices-for-ec2.md,Why I'm interested in AWS Spot Prices for EC2,"['cloud computing', 'development', 'devops']","Why I'm interested in AWS Spot Prices for EC2
There's been a lot of chatter going on around the intertubes over the last couple of weeks since [Amazon Web Services](http://aws.amazon.com) released their [Spot Instances](http://aws.amazon.com/ec2/spot-instances/) pricing model for EC2. In a nutshell - AWS have created a compute market. Instead of charging the same price to every person for the same product they have basically created a market where people can buy compute time at less than a price they are willing to spend based on the current demand. There's been some conversation about the fact everyone should just put the current demand price in as their maximum and this would game the system ([the comments here for example](http://gevaperry.typepad.com/main/2009/12/amazon-ec2-spot-instances.html)) however this misses the point slightly. The [Clouderati](http://twitter.com/#/list/ajfisher/clouderati) often talk about Utility Computing or Commodification as one aspect of Cloud Computing and what AWS have done is the logical conclusion of that - they have created a true market for the provision of computing time based on supply and demand. Now what's interesting with the ideas some commentators have come up with regarding gaming is it assumes everyone's working the interest of everyone else. That isn't the case. Yes I know I could get some resource cheaply if I keep my bid low and am willing to wait for a period of time however I have clients and they have deadlines. That big compute job crunching all the marketing data needs sorting out this afternoon - so I'm going to put a high bid in for 50 nodes NOW! The market will accommodate that and those with low bids will be knocked off. Thus the market constantly corrects to the requirements of demand. But it's the flipside of this which makes me really interested in EC2 Spot Instances. I can have a battery of servers doing work at little to no cost if I build my system correctly. The critical element to this is I need to address availability correctly - that is I need to ensure that my entire system doesn't go down because I've been priced out of the market. This is a really rough idea at this point but I'd love feedback around it - it's obviously based around some kind of online application that requires multiple nodes. I have an instance which is the master. All parts of the stack could be retreated back to this server if it's needed. I have Cloudwatch or some other monitoring system assessing the performance of my nodes so I can see when I have spare capacity or when I'm under utilised. The master server has a series of heuristics looking at the current work loads and the current costs that each server is incurring versus the work it is carrying out. Thus low utilisation and low cost is okay but low utilisation and high cost would cause alarms to go off. The heuristic set up makes reference to the demand pricing level and strives to always keep each instance below that price. As the spot prices go up and over the demand price I immediately terminate expensive spot instances and start replacing them with lower price demand ones. As the price comes back under then I can replace demand prices with spot prices The master server then creates instances as required to fulfill the work units that are required and link them into the system. Each node is able to be switched off mid unit so the entire network is self-healing So the only thing that would be required to get this up and running now is having a reliable system for creating nodes and getting them working into the network as quickly as possible and producing the heuristic system to monitor and create and destroy instances based on some rules that would create some intelligence around pricing. Not least the system would need to determine whether a mix of different types of instances would be appropriate if there are large distinctions between their current spot price for given work units. For example: If we were serving a bunch of web pages using some heavy duty memcached system then RAM is the most important commodity. Say I have an instance of 1.7GB RAM at 3C/hr and another instance of 7.5GB RAM at 15C/hour then my intelligence system needs to understand the component (Memcached) just needs buckets of RAM and that getting 5 instances at 3C/hour is better value than 1 at 15. Importantly it can then ramp up towards that number based on what is actually required rather than doing the whole lot and then under-utilising. So I think we're quite a way away from this type of system but my opinion is that this isn't out of the realms of possibility and importantly the market Amazon has created has allowed (I could almost say ""is going to force"") these types of architectural considerations to start being made. Interestingly all of a sudden decisions I am going to make around infrastructure is going to be much more value based. It's not about ROI - it's about value and am I getting the best value from my infrastructure. IT teams that get this are going to make an absolute killing with the type of services they can offer and the prices they'll be able to do it for. Am I off my rocker? I'd love to explore this idea further.","['cloud computing', 'development', 'devops']","['development', 'cloud computing', 'devops', 'web', 'internet']","[0.6311058318468327, 0.5905691183961944, 0.5807181242028582, 0.3327712157917601, 0.3080131063818196]","['internet', 'web']",[],[],[],True,3
2010-01-03-2010-the-year-the-netbook-turns-into-the-web-book.md,2010: The year the Netbook turns into the Web-book,"['consumer electronics', 'internet', 'mobile', 'predictions', 'tablet']","2010: The year the Netbook turns into the Web-book
2010 is set to be a bumper year for Consumer Electronics. With people spending less outside the home they are focusing more inside and as just about everyone now has some monstrous TV it's the little things that count. 2009 was arguably the year of the Netbook. After Asus launched with their eeePC in 2008 a land-rush occurred last year with virtually every Notebook manufacturer providing an offering. HP's Mini and Acer's Aspire One ranges both did very well as did Asus with their eeePC. At the end of 2009 however it became virtually impossible to get a Netbook that is truly still a Netbook. Acer, Dell, Asus and HP all fell back into their same tired old routine - bigger, faster, more capacity! And the Netbook experience suffered. I've made this point before but the power of the Netbook is in the Network - not in how big a hard drive it has. Why do I need a 160GB hard drive when I have Terabytes of NAS and Gigabytes of cloud storage? I don't need 5 USB ports and I certainly don't need Windows. Having said all of this the Netbook category has gone ballistic - having doubled from 16 to 33 Million units sold in 2009 - sales are worth about $USD11Bn globally ([Display Search research for 2009](http://www.displaysearch.com/cps/rde/xchg/displaysearch/hs.xsl/071309_mini_note_netbook_shipments_to_double_y_y_to_more_than_30m_units_in_2009.asp)) ![Prototype web book - from litle](../../img/posts/webbook.jpg)
*[litl
web book prototype design (image (c) litl)](http://www.flickr.com/photos/litl/4077444353/)* My money is on the next generation - so called Web Books, Slates or Tablets. These devices are being actively invested in by a number of investors and represent a merging of several types of computing behaviour. Architecturally, most are small form factor (10 inch or less), are either a tablet or have a folding range far outside the normal Notebook range (can be flipped over on itself entirely - so is just a screen), they are generally touch screen capable with many being multi-touch and the big one - most are not running windows (generally running flavours of Linux). Behaviourally, the Web Book is designed to be a piece of Consumer Electronics. It's not a desktop replacement, it's not an office machine. It's a device that is a general purpose computer but built to use in the home as such it plays on the following: It's relatively small and definitely light. The processor is powerful but not an energy guzzler (Intel Atom's do brilliantly here as do ARMs) The display is gorgeous and has high viewing angles so multiple people can see it It uses wifi and may not even have Ethernet connectivity Solid State disks are a must but are low capacity (you don't need more than 16GB in a machine that is connected to a network) thus saving on energy battery life is a must - the longer the better thus every component is energy efficient Ideally the screen is touch capable and ideally multi-touch (thus eliminating the need for a keyboard) The device is permanently connected to the network and thus the Internet. It's there to connect with people, view photos, play your tunes, watch movies and read web pages. <b>It's not there to write documents, do full scale design or programming</b> (though people will use it to do this in a limited, fast fashion). I've been excited about Internet tables, Slates, Web Books - call them as you will since Nokia released the N710 and with [Apple](http://gizmodo.com/5434566/the-exhaustive-guide-to-apple-tablet-rumors), [HTC (Google)](http://www.smarthouse.com.au/Home_Office/Notebooks_And_Tablets/C5J4K9R8), [Litl](http://litl.com/) and others all about to play in this space in a big way over the next few months, there will be a lot of people asking for a Web Book or Internet Slate in their Christmas Stocking next year. Expect to see masses of innovation in this space as companies that have not been too caught up in the Netbook scene enter the fray for the first time and start showing off some new ideas. Litl does this with their awesome Easel Frame style web book and both HTC and Apple will do some great stuff on the user experience end of things too. 2010 will definitely be the year that the Internet goes increasingly mobile both inside and outside the house but the experience of it literally becomes more tactile and less bound to the keyboard.","['consumer electronics', 'internet', 'mobile', 'predictions', 'tablet']","['mobile', 'internet', 'predictions', 'consumer electronics', 'tablet']","[0.6501884086110827, 0.619208815072141, 0.6011265129096575, 0.5895689485263117, 0.5829443392394895]",[],[],[],[],True,5
2010-01-28-ipad-almost-great.md,iPad - ALMOST great,"['apple', 'ios', 'media', 'mobile', 'os', 'tablet']","iPad - ALMOST great
There's been a lot of chatter about the [iPad](http://www.apple.com/ipad) today and to put it out there from the start I was expecting outstanding things from [Apple](http://www.apple.com) with their tablet. What I wasn't really expecting was the tablet to be a large version iPhone but in retrospect that isn't too surprising. The device itself looks absolutely stunning and 4:3 aspect ratio aside, watching video whether it's streaming H.264 or YouTube is going to be stunning whilst sitting on the sofa. And that brings me to the ALMOST great part. I've been talking heaps recently about context - how the device you are engaging with is used depending on your mind state and your location. For example using a mobile device on the move is different than using a laptop on a table in a cafe. For a tablet the killer context, in my opinion, is what I call ""lounge computing"" - the idea that you are using a computing device in a relaxed environment for non-serious computing. By non-serious I mean not hard core gaming (that's what your PS3 / Xbox360 is for) and not desktop computing (banging out an email but not answering 50 in your inbox). It's looking up a map, watching YouTube videos, using web sites etc. Lounge computing is all about generalised, casual computing where you don't need loads of power but need internet connectivity, a great sized screen and enough control over the environment you can customise it. Hardware wise I think Apple nailed it. There's been lots of chatter about ""why doesn't it have an SD card slot"",  "" how come it doesn't have a webcam"" but if you want (and need) all that stuff, go get a netbook. I've talked a  lot about the power of these devices being in the network. With cloud or network storage the space limitations aren't an issue, with a home media server you can stream your music or videos (or just use your iTunes account). What I would have love to see from Apple though is really crafting the experience around the lounge computing experience. Getting Flash on the device for starters would have been ideal but also things like a higher res screen. I'm also not so keen on the ""just put an app from iPhone on the iPad"" - the contexts and devices are very different so loses a lot of relevance. This platform will end up being absolutely fantastic but we might have to wait until the Gen 2 devices before there is enough iPad specific apps to really tap into the lounge computing experience but once that time comes and with the experience and feedback Apple will get in this market over the next 18 months, the Gen 2 release will really hit the mark with consumers.","['apple', 'ios', 'media', 'mobile', 'os', 'tablet']","['mobile', 'media', 'os', 'apple', 'ios']","[0.6451295218968743, 0.6232140427740955, 0.6001788034881193, 0.5916936784250737, 0.5869020103123118]",[],[],[],[],True,6
2010-03-23-an-open-internet-call-to-arms.md,An Open Internet call to arms,"['censorship', 'government', 'internet', 'media', 'rant']","An Open Internet call to arms
Having watched the trainwreck that is the Australian Internet Filter and Senator Conroy's single minded obsession to go down in history as the ""man who removed free speech from Australia"" I can't help but notice two things: There has to be support somewhere I canvassed people on twitter and email and I can't find anyone who knows of support for this scheme. Having said that, there's no way Conroy can go and do this by himself. Don't forget old Johnny Howard was touting this idea long before Stephen Conroy was. Antagonists are arguing an emotional issue on technical merits I've been as guilty of doing this as everyone else in the Open Internet / No Clean Feed camp and numerous industry stalwarts (Google, Yahoo & Microsoft included) have made [submissions to the government](http://www.dbcde.gov.au/online_safety_and_security/cybersafety_plan/transparency_measures/submissions) using exactly this tack ([SMH has a good summary](http://www.smh.com.au/technology/technology-news/conroys-internet-censorship-agenda-slammed-by-tech-giants-20100323-qt83.html?rand=1269318915365)). I've written to my MP, I've supported petitions and made the technical argument vociferously. Arguing that there are technical problems with implementation, that it will slow down connectivity etc is all technically correct but the pro-filter camp just say ""Think of the children"" and it's like some magical trump card that will negate any and all arguments. Where the argument is failing The problem as I see it is that the people who are supporting this aren't going out into the media and saying anything because they will be shot down by those that know more about technology. They are waging their war not through the media but through the back channels of conversation and the corridors of Canberra. The Open Internet / No Clean feed lobby whilst technically superior can't make a case that is being listened to and additionally we are out of step with the majority of voters who don't understand our concerns. Take this conversation as an example: Filter Lobbyist: ""We must protect the children from pornography and terrorism online"" Parent: ""Absolutely, I don't want my child exposed to that sort of content."" Filter Lobbyist: ""Well that's what this filter will stop. Your child and everyone's in Australia will be protected from the harmful parts of the Internet"" Parent: ""I completely agree"" Open Internet Lobbyist: ""Yes well that protection comes at a price. The government will choose what content is 'appropriate' and can censor anything it wants from the population with no accountability. The cost of implementing a filter and maintaining it could be better spent on education programmes or policing and technically every part of your Internet experience will be slower"" Parent: ""Oh"" Filter Lobbyist: ""Think of the children"" Parent: ""Yes I agree, we must protect our children from this type of content"" I've seen this exact argument play out at least twice now with friends and family. The problem we have is it's too easy for the Filter Lobby to recruit the average population into the fold and I suspect this is where Conroy's getting his base from. The only way to overturn this scheme is to get the average person involved, and to do that the technical arguments need to support but not dominate the conversation. The only way I see of getting out of this mess is to **SHOW** the average person what the extent of this scheme could do. A call to arms I want everyone who works at an ISP, a major content provider, or is a techie to do the following: On a day in April we choose to voluntarily censor the Australian Internet. ![Dark haired man with mouth taped shut](../../img/posts/taped_shut.png)
*[It's better this way (image (cc) Kevin)](http://www.flickr.com/photos/vtotter/3426290124/)* Let me say that again: We CHOOSE to censor our Internet within our borders. Doing this will show every Australian online what it will be like to live with this system in place. It's sounds like a challenge but it's not - here's what we need to do: If you are a search system like Google, Yahoo or Bing, you need to put an interstitial page on any link to something of questionable content (A standard blacklist would work) the same way Google does if you are about to visit a site where it knows there is malware. It won't stop you but we can take the opportunity to educate by forcing an additional click. If you are an ISP or you manage IT services for a business you can do this with DNS, send people to an interstitial page which then has a link to the content they are after (you could do this simply to well known RC sites such as YouTube) If you are a content provider run a black list over your forum or blog and get it to switch off content that may be inappropriate under this scheme. Again let them through but only after they've seen the message. This can be done, and importantly it can be done quickly. All it requires is will. If you know anyone that works in technology in any of these sorts of capacities, send them this page then get them to get in touch. If we can get some momentum we can use technical skill to make an emotional argument. We need the average person to understand what this means for them and to do that we need to show them. Volunteer to Censor the Australian Internet. Additionally - [support the EFA's fund raising activities](http://www.efa.org.au/)","['censorship', 'government', 'internet', 'media', 'rant']","['internet', 'media', 'rant', 'censorship', 'government']","[0.6288782541314979, 0.6267482024865048, 0.6174769705486941, 0.5877966737312499, 0.5834594858422895]",[],[],[],[],True,5
2010-04-13-adobe-narayens-kingdom-for-a-plan.md,Adobe - Narayen's kingdom for a plan...,"['adobe', 'apple', 'google', 'media', 'strategy', 'web']","Adobe - Narayen's kingdom for a plan...
Adobe's public fracas with Apple over lack of Flash on iThings and Google open sources V8 - it's been a tough couple of weeks for Adobe with no signs of getting better. Cries of ""My kingdom for a plan"" may just about to be heard from the corner offices... I've been through the cycle of love and hate with Flash. I have, at one time been employed to write games in flash, I appreciate it's usefulness in situations where HTML just doesn't cut it (3D animation for example) but I also loathe it with a passion otherwise reserved only for cucumbers - and have done for years. Flash, unfortunately, has gone from being a tool that enhances the web to one which degrades it. It is responsible for more performance woes and crashes in the browser than any other technology whilst at the same time the standard of design with flash has become almost powerpoint-esque in it's mundanity (fade transitions and slides really don't light me up the way they did in 1998). There was a time when Flash was just a tool for creating some interesting animations - then Macromedia made it a bit more programmer oriented, then a lot more programmer oriented but what Adobe didn't have the guts to do when they bought Macromedia was rip out all the designer oriented components and make it programmer focussed (that honour was left to the Open Source Flash Development team, with whom the last vestiges of Flash credibility now reside). ![A fortune cookie with the fortune 'meh'](../../img/posts/fortune_cookie.jpg)
*[meh(image (cc) Rick Harris)](http://www.flickr.com/photos/rickharris/430890004)* Adobe's lack of vision was the equivalent of a parent thinking it is okay to let toddlers play with machine guns - today's average designer is not capable of building anything non-trivial in flash that will not degrade or crash a browser. Apple and Google enter the fray The highly public fracas between Apple and Adobe about Flash being allowed on Apple iDevices has been matched by a slightly less vocal, but extremely important movement to get an open video format into HTML 5. With Google's [recent move to open source VP8](http://newteevee.com/2010/04/12/google-to-open-source-vp8-for-html5-video/) this now looks like a reality and Flash's dominance in web video looks certain to end soon - especially if YouTube convert their videos across as is predicted. Both Google and Apple both have self-interest in this move and both because of the shift to mobile computing. The second biggest search engine on the planet is YouTube and it is a media channel in it's own right - having their broadcast medium tied to a single proprietary format is potentially very bad news for Google (and has been because of the aforementioned issues around Flash-crashes). Apple have always taken a line on their hardware that borders on the fascist, but with generally good reason - user experience is maintained to high levels. Introducing flash and the current crop of flash designers to any iDevice will have it crawling to a crash in minutes. Adobe hero... to zero Today apparently Adobe are looking at giving Apple [a nice fat lawsuit](http://www.itworld.com/legal/104320/adobe-vs-apple-going-get-uglier) which I'm sure will actually make Steve Jobs laugh smugly as he drinks his coffee reading the news on his nicely performing iPad. What went wrong for a company that was at the forefront of innovation through the 90s and with it's purchase of Macromedia was the owner of just about every credible piece of tooling for creating the Web? My opinion is the acquisition of Macromedia went harder than anyone realised and Adobe are still choking the pieces down. Add to that the acquisition of Omniture  with some serious development needed to hold-off Google and this is a company that is trying to eat two elephants - at the same time; in one bite. Adobe's current rate of innovation is laughable and they continue to support and invest in products they should have killed off 5+ years ago. Both revenue and profit have taken a dive with profit almost falling off a cliff since 2007. ![Graph of Adobe's historical profit per year](../../img/posts/shares_adobe.png)
*Historical gross profit of Adobe corporation - Wolfram|Alpha* While I'm here it's worth pointing out that profit is equal to about $45K per employee (compared to $70K per employee at Oracle or nearly $250K per employee at Google!) Adobe - where to now? Whilst it's fun to give a major corporation a kicking, for what it's worth if I was working at Adobe here's what I'd be suggesting as a way to get out of the doldrums: Kill Flash The flash application as it stands now has got to go. Video has moved on and enhancements to the After Effects product line to support one-click publishing (thus streamlining work flow) and supporting the Open formats would reinvigorate this product and be at the heart of an Internet Video transition that has barely even started. Invest in developing an application that allows the easy animation of SVG which has languished as a standard because of lack of decent tooling. That developers are hand coding SVG and animating it via JavaScript and Canvas is ridiculous. There is great opportunity here and actually goes back to the heart of what flash was designed to do when it was Splash - vector animation. Revive Flash The only bastion of innovation in Flash these days is in 3D and Adobe are no where to be seen in this space. The native updates in Flash 10 to support 3D were okay but [PaperVision](http://www.papervision3d.org/) had already stolen the show. With 3D Augmented Reality using things like [FLAR](http://www.libspark.org/wiki/saqoosha/FLARToolKit/en) and the work already done by the PaperVision guys the reality of good 3D on the web may finally becoming a reality (I worked on [VRML](http://en.wikipedia.org/wiki/VRML) a long time ago which went nowhere). Focus back in on the core products Photoshop has always been Adobe's crown jewel. For a long time it was also one of the most innovative pieces of software being developed. The strategy behind the fragmentation of that product line into Elements and the web version probably went something like this: Someone at Adobe piped up and said that because of piracy they should offer a cut down piece of software at a much more consumer friendly price so if a million people were pirating the full Photoshop they might get 100,000 sales from Elements licenses. Adobe then went off and had to develop and support another piece of software that was then lower on magin and higher in support costs (lower skilled users). Platform fragmentation kills your business - that's why Software as a Service exists. [Photoshop.com](http://www.photoshop.com) is an attempt in this direction and may pay off but I'd kill Elements off with the vigour of an enraged samurai. Photoshop isn't supposed to compete against Picasa, F-spot and any number of simple photo editing pieces of software. Through taking the eye off the ball it's allowed Open Source projects like the[ GIMP ](http://www.gimp.org/)to gain market share and start to be known for innovation. The same diversions across the business are having effects elsewhere too, Illustrator having overlap with Fireworks for example has allowed products like [InkScape](http://www.inkscape.org/) to gain market share and again become known for innovation. So kill off the misbegotten child that is Fireworks and at same time get rid of Dreamweaver too (is there a serious web developer that uses this any more anyway? It was great when we built in tables but is now officially worse than useless) Cold Fusion should have been drowned at birth so let's finally put it out of it's misery. The product suite is fragmented and chaotic - get rid of the things that aren't needed and focus back on the things that made Adobe great and not worry about the things you've inherited. Leverage Omniture's experience Omniture was one of the first SaaS companies in existence - it was also quite profitable. Learn from this and how to deliver software over the web but at the same time look at it in the cold light of day and work out in an increasingly Google driven world how it is going to compete (and as an Omniture user UI / UX is a big area needing revision). Bring innovation front and centre There was a time when Adobe was one of the most innovative businesses on the planet. Now is not that time. The business needs to celebrate innovation not with patents but with releases - do great things and get them out. It can really learn from Omniture in this regard. Start listening to the market Listen to your customers, understand what they want and need then take the best things and make them better. Adobe doesn't listen any more - Apple, one of it's longest running partners gave it the warnings but no heed was paid. Adobe's head-in-sand attitude showed this week at the CS5 launch when they talked about packaging for iPhone / iPad which [Apple decreed last week could no longer be done](http://techcrunch.com/2010/04/08/adobe-flash-apple-sdk/). No business can be so arrogant as to ignore warnings about it's market. Adobe, zero... to hero? I don't know. We've seen a lot of businesses try and fail - Novell, Microsoft during Ballmer's reign, now Oracle to an extent. It takes an iron will to change a company's direction once it's set and has momentum. Adobe used to be synonymous with creativity and innovation, now it is synonymous with being average.","['adobe', 'apple', 'google', 'media', 'strategy', 'web']","['web', 'media', 'google', 'strategy', 'adobe']","[0.6287035996400898, 0.6280348232192552, 0.591025954521111, 0.5896915587469587, 0.5846167843037015]",[],[],[],[],True,6
2010-06-23-why-google-is-a-more-typical-business-than-you-think.md,"Why Google is a more ""typical"" business than you think","['business', 'cloud computing', 'desktop', 'google', 'linux', 'os', 'strategy', 'web']","Why Google is a more ""typical"" business than you think
There's been some interesting reportage over the last couple of weeks around whether Google's decision to remove Windows from internal use as a supported desktop has wider ramifications for the future of Windows in business. The Linux and Mac press have been crowing; suggesting that CIOs take Google's lead and kill off their dependence on the Microsoft OS. I'm not going to get into that discussion - especially given my Linux persuasions - but I was interested in the view expressed by [Matt Asay from Canonical over at CNET](http://news.cnet.com/8301-13505_3-20006539-16.html) where he suggests Google is an anomaly because they are a tech business that work heavily in Open Source and a lot of their staff needs can be met via cloud services. Whilst this is technically correct and being the technology leader at a technology company my view is probably tainted. Looking at my clients though, who comprise some of Australia's largest businesses, I actually don't think Google is as much of an anomaly as Matt suggests. Most enterprise job functions are split into three core technology requirements: Information Worker, Creator and Service (and yes I know this is simplistic and perhaps overly reductionist but it works in 90% of businesses where Desktop IT is an Enterprise function). An Information Worker typically spends their life in an Office program of some sort, a web browser and heavily uses email. Given the steady rise of Open Office, the large scale moves to Google Apps for Business and Microsoft's hosted Exchange solutions - <b>the needs of the Information Worker are being well and truly met with a Web Browser along with some cloud services</b>. The Information Worker could be on any browser on just about any device and it wouldn't matter what sort of OS they are running. Google have a lot of these types of workers and so to do many Enterprises (the majority of those who operate out of HQ). Service staff are typically interacting with customers whether on the ground selling or manning a phone line or service desk. The two main use cases for Service staff are CRM or POS type applications and clearly the move to cloud or web app CRM (eg Salesforce or SAP CRM) and the rise of web based POS will mean it doesn't matter what the underlying OS is because the needs are met with a browser. Add web based email into the mix and there's no need for anything more than a browser for these staff. The only group that aren't catered for are the Creators, and this is where choice of desktop actually becomes important. Each Creator will have their own specific requirements. Creator staff tend to be high margin resources so buying expensive software and hardware is generally an easy justification given their output and profitability. Google obviously has plenty of these people working for it but all companies that are in the business of making ""stuff"" will have this user group. The key then, is to move all non-creator staff (which in most Enterprises are a large proportion of the head count) to solutions that don't require a specific OS and then gain a very good understanding of what Creators need. There are also few needs for Creators that aren't well serviced by Mac or Linux (hence why Google can shift their baseline). So when you break down the user functions, Google isn't that atypical of many other businesses; <b>the direction Google is taking is something that IT leaders should be looking at</b> - especially given there is a large upgrade ahead of us to move from Win XP to Win 7 in business. The first step of this upgrade should be to move core applications to web apps (whether cloud or on-premise) and then look at potential alternatives that may break dependency on Windows which then frees up a discussion around OS. The bigger hurdles for IT lie in the perception issues of Information and Service workers who will need to retrain their core IT skills to cope with a different OS - but that is a social issue not a technical one.","['business', 'cloud computing', 'desktop', 'google', 'linux', 'os', 'strategy', 'web']","['web', 'business', 'os', 'google', 'strategy']","[0.630802531490236, 0.6191600219536684, 0.6087771136501204, 0.6007960521191926, 0.5992847539791941]",[],[],[],[],True,8
2010-06-27-a-telling-quarter-for-android.md,A telling quarter for Android,"['android', 'business', 'google', 'mobile', 'os']","A telling quarter for Android
Most people looking at the mobile and smart phone sector focus on unit sales as an indicator of performance - I suggest that one also needs to look at apps. The number of available apps is a metric that shows developer commitment to the ecosystem and also gives the manufacturer marketing leverage (see Apple 100k apps marketing). Apps gives a good long term view of the platform and is a key driver in purchasing behaviour. Steve Jobs understands this which is why he plays the ""most available apps of any platform"" card at every possible opportunity. Well, Android has been enjoying exponential growth in the number of apps in the market over the last two years since it launched. This is not uncommon for a new platform and iPhone OS did exactly the same thing when it launched. ![A graph of android market apps](../../img/posts/android-appstats.png)
*Number of apps in Android market - from androlib.com* Why this is an important quarter for android however is that the number of apps currently available for Android was the inflection point at which Apple's iPhone app growth stated to slow. As can be seen in the chart below iPhone apps have continued to grow but the pace has eased off. This is a sign that the developer community is saturating and is maturing. ![A graph of iTunes market apps](../../img/posts/iphone-stats-smaller.png)
*Number of iPhone apps in iTunes - from Wikipedia* I would suggest this also indicates that developers are becoming more considered about the types of apps they are building rather than doing quick, iterative development to just ""try things out"". Certain niches are now evident in the iPhone ecosystem that revolve around the capabilities of the device and the ways people use them. The overall quality of apps are increasing too (anecdotally and as should be expected as a platform matures). So we arrive at this point where a lot of the potential app space has been explored on a platform and development starts to plateau as developers get more serious about it, developing fewer, but better applications. For iPhone OS, the point this occurred was at about 75,000 apps in the App Store. After this, the growth started to ease off. At the end of June, the Android Market passed the 75,000 mark in number of published apps so this quarter will allow us to make some comparisons with the iPhone in a few key areas: Is 75K the magic number? Of all the potential insight this one interests me most as it's behaviour driven. If Android, like iPhone OS, starts to slow after reaching 75,000 apps it tells us that this is the minimum number required before a mobile platform can claim maturity and a vibrant developer community. This number tells us you need to have about this many goes at developing apps by your community before a sufficient amount of space has been covered to start arriving at niches and maximising them through quality updates and competition. This has enormous ramifications for markets being produced by Nokia, RIM (and potentially MS and HP). Anyone looking to contend in the smartphone market has to woo developers to get the market to this level as quickly as possible. Apple and Google have both done this extremely well through well designed developer programmes, lots of freebies and lots of conversation. Is the Android strategy of having multiple handsets paying off? One of the critiques around Android is that there are numerous vendors supplying hardware and lots of incompatible versions of the OS which is causing fragmentation. If the app growth remains strong, this could mean Android's fragmentation isn't as bad as everyone makes out as there are more potential niches to be had by developing apps that cater for different market segments around handset and OS version differences. Likewise the extremely rapid rate of development on the hardware side could be opening up new potential development opportunities and use cases that don't exist or didn't exist comparably during iPhone's growth. Arguably Augmented Reality (AR) is one of these areas; which saw explosive growth on the Android side and many of the market leaders then shifted to iPhone with well defined and highly polished products - killing off potential upstarts on iPhone before the niche was created. Did Apple's draconian app store policies stunt developer growth? This will be hard to understand totally until we see Android catch up to iPhone in terms of total numbers of applications however we know that many developers were getting frustrated with Apple with regards to submission handling and this started occurring around the time that iPhone apps started to plateau so there may be some cause and effect here. Certainly if Android grows heavily in this quarter then some questions need to be asked about whether hampering developer freedom was worth it from a long term strategic standpoint. Q3 big, Q4 bigger? At this point it's too early to tell. We know that Android is outselling iPhone heavily at the moment, even with the iPhone 4 release. Google announced at the Motorola Droid X launch recently that 160,000 handsets are being activated every day. Contrast this to about 95,000 from Apple (though this was pre iPhone 4 launch). Android sales also nearly doubled in as little as a month (100K units at I/O versus 160K at Droid X launch) so we can expect a number around 200K to some time in Q3 given this growth rate. If you are a developer, you should be looking at those sorts of numbers and heavily considering an Android development strategy if you don't have one already. The potential audience will be bigger long term and at this point there is opportunity to grab a niche - especially if you have an existing, polished iPhone app. My prediction, for what it's worth, is that we'll see a doubling over Q3 and then a reduction occur over Q4. This will take the market to about 175K apps going into 2011. The strong platform demand will draw in a lot of developers - and Java is a much more readily available skill than Objective C so I think there's still some legs in Android's growth. Given iPhone's current growth this would have the two platforms at similar levels of about 275,000 apps some time in the middle of 2011. Time will tell and I'll post an update at the end of Q3 as to the figures then.","['android', 'business', 'google', 'mobile', 'os']","['mobile', 'business', 'google', 'android', 'os']","[0.6517332714369605, 0.6259055192713476, 0.6210018944463408, 0.6182827646044888, 0.6031808806384064]",[],[],[],[],True,5
2010-07-20-thingstreams-the-future-of-brand-product-consumer-dialogue.md,Thingstreams - the future of product / consumer dialogue,"['essay', 'internet', 'media', 'mobile', 'predictions', 'web']","Thingstreams - the future of product / consumer dialogue
Times, they are a changing - for brands and consumers both. Gone are the days where a brand tells you what to think about them and as a consumer I duly do as I'm told because I've been brainwashed by hundreds of exposures to your brand and product message. Thingstreams and more broadly Thingspace will and are changing this behaviour - unfortunately many brands still haven't realised yet. The likes of [Erik Qualman](http://twitter.com/equalman) and [Charles Leadbeater](http://www.charlesleadbeater.net/home.aspx) have shown us how social technologies and behaviours are changing the way we look for information, how we make product choices based on other people's views because we respect their opinion rather than that of a marketer telling us their product is great. At the moment this information is widely scattered and can at times be difficult to find. Whilst there are niches of gold such as [Amazon's Customer Reviews](http://www.amazon.com) system on each product, and various review sites scattered around the Internet with their unique slants (eg [cnet for consumer electronics](http://reviews.cnet.com/)) there is nothing really binding these streams of content and opinion together. Recent research by Syncapse ([PDF](http://www.syncapse.com/media/syncapse-value-of-a-facebook-fan.pdf)) shows many people are more than happy to show their affiliation to a brand or product. The success of Amazon's rating system shows people are willing to spend time reviewing it. Without search though, how do I as a consumer find this information and start  deciding whether a product is right for me or not? How can I leverage all this behaviour and content that has been created? At the moment, outside of search I go to my peer network and ask for  referrals (has anyone used? Does anyone know of? What is a good?). This is a good start but I quickly come back to search to find more information or cast the net wider. I like customer opinion, even if I don't know the person, but finding it can be a struggle - especially if it's buried in a forum post somewhere. This is where ThingStreams will change the way we interact with product and brand related information. Opinion gets focussed The idea of a ThingStream is that a stream of content is created and is attached to a real, physical thing - in most cases some kind of product. At the moment this is done with a barcode because this is one of the only ways we have to uniquely identify a physical ""thing"". Once a stream of content is bound to a thing I have a ThingStream that I can engage with. The content doesn't need to be a rating or a text review, it could be pictures, video or any type of media, all attached in ThingSpace around a product that I can start consuming to better understand customer opinion or I can create and add to express my own. Brands be aware, every product you have will be subject to an anarchic wave of content that will be bound to your product forever, that doesn't require a customer to trawl the web looking for reviews and cruising support forums to see if there are issues. The Thing Stream will be activated through a UPC ([Universal Product Code](http://en.wikipedia.org/wiki/Universal_Product_Code)) lookup via a website or through a barcode scan off a mobile phone. If your product has issues your customers will document them; just like they do now - and those damning pieces of content will be bound to your product like a pair of lead boots, all in one place for future customers to look at and add to. However this is a conversation and brands can engage too, if there's an issue you can address it, maybe they need to update firmware - here's how to do it and links for further information. Brands can get on the front foot too, the first piece of content in the ThingStream could be more information about how the product is sourced ethically or is Carbon Neutral or just how it works in practice. This is an opportunity as a brand to create engagement beyond the price sticker whilst the customer is still in consideration mode. Brands that engage in ThingSpace and directly on their product ThingStreams get an opportunity to rally their advocates as well. We all know of products that people absolutely love, here's the place to harness all of that advocacy and focus it into one place where future customers will be looking. I'm just getting my Facebook policy sorted, I'll consider it for 2014 For many brands this is Yet Another Thing their marketing and PR teams need to think about but this isn't something that can be put to the back of the mind. Mobile apps right now such as[ Stickybits](http://stickybits.com) and increasingly [Shop Savvy](http://www.biggu.com/) are the nascent ThingSpace of 2010. Stickybits is closest to my view of what a ThingStream looks like though it only pulls information from within the StickyBits network itself. ShopSavvy is starting to pull in meta information from other sources in order to supplement it's core purpose of product comparison. Pepsi is already operating in this space with campaigns running across all it's major products (including Lays) which is being run through StickyBits. If you're a brand manager you need to be looking at ThingSpace and ThingStreams right now and start getting used to holding conversation there. If you're the brand manager of [Corona beer](http://www.corona.com) I'd suggest getting involved in the very active conversation that is already occurring in StickyBits right now relating to your product. The future of ThingSpace At the moment ThingStreams are very clunky - we are very much on the leading edge of this particular growth curve, but the foundations are in place for this to explode - customers like talking, customers want customer testimony and we are already actively engaged in these two behaviours right now. The only change is going to be the way we facilitate the conversation and the tools to do it. The mechanism for accessing ThingStreams will enhance over time. The work Google is doing with [Google Goggles](http://www.google.com/mobile/goggles/#text) for  example could use image recognition to determine what the ""thing"" is  you're looking at then associate it to a UPC and then display the stream -imagine walking into an electricals retailer pointing your phone at a fridge and it recognises the make and model then presents the ThingStream? Going even further apps  like Shazaam with it's music recognition feature could create a  ThingStream around music tracks showing listeners' thoughts, video clips  from the concert and commentary from the artist on their inspiration. Whenever we have the opportunity to recognise a ""thing"" via any means, we can tap into it's ThingStream and present that back to the customer. I have a vision of ThingStream content that goes beyond that offered by StickyBits now, a mechanism whereby current ThingStream content owners (Amazon, cnet and others) can use microformats or other means to syndicate the individual threads of conversation into the Stream (much like the work [Chris Messina](http://twitter.com/chrismessina) is doing with [Activity Streams](http://activitystrea.ms/)). This will be the subject of a subsequent post on how threads can be pulled into streams. Concept The idea of ThingStreams and ThingSpace has been informed heavily by the work of Charles Leadbeater and his thoughts around how ""I Think"" turns into ""We Think"" at critical mass, similarly being an active reviewer and consumer of reviews at Amazon and dabs has shown me the propensity of customers to contribute their thoughts on product, and further the work start up organisations like StickyBits are doing in this space - I'm not sure their goals or articulation of ThingStreams are in line with mine however they are well worth watching in this space as it's so new. This concept has been washing around in my mind for a while now and I   finally started to articulate it in a talk I gave at a Futures session   on Mobile Computing. I hope that this post provides further clarity   around the concept and starts some discussion around what I think will   be a brave new world for brands and customers.","['essay', 'internet', 'media', 'mobile', 'predictions', 'web']","['web', 'internet', 'media', 'mobile', 'essay']","[0.6346991560465916, 0.624367378193044, 0.6242994998866739, 0.6220398085864407, 0.5931390828452657]",[],[],[],[],True,6
2010-09-29-software-is-a-race-to-zero-how-do-you-create-revenue-then.md,"If software is a race to $Zero, how do you create revenue?","['business', 'development', 'essay', 'growth', 'strategy']","If software is a race to $Zero, how do you create revenue?
All software that has a market will inevitably and inexorably find itself in a race to the bottom with respect to price. To clarify, if you haven't heard this expression before - all commodities drop in price over time (as rarity disappears) to eventually hit a bottom price per unit. As the skills to write code are now very common and there is effectively no price per unit for production or distribution, the natural floor for any piece of software is basically nothing. Nothing other than time and inclination anyway. ![Picture of warehouse roofs that look like a downward line chart](../../img/posts/line_chart.jpg)
*[Linechart (image (cc) Andreas Levers)](http://www.flickr.com/photos/96dpi/4032198061)* Don't believe me? Think *your* bit of software is the exception? Let's look at some big names quickly: Windows Server -> Linux (various flavours) Windows Desktop -> Ubuntu (specifically) MS Office -> Open Office, Google Docs Oracle DB -> MySQL / PostgreSQL IIS -> Apache, nginx MS Visual Studio -> VSE / Eclipse There are many reasons for this but the one I want to focus on is the commoditisation of software and what the implications are if you build it. Why this is pertinent right now is one of my favourite start ups, XMarks is about to close down. Xmarks was the first cross browser app (to my knowledge) to allow users to synchronise their bookmarks between computers - a great feature for those of us with machines at home and at work. However in the face of all major browsers now having this feature out of the box and at least one operating system able to do it (Ubuntu) it appears as though they no longer have market position and indeed have no revenue current or likely to arrive in the future. Software and programming code is extremely malleable, it is often just a novel application of something existing already and even without seeing your code I can at least guess at how you did something in an attempt to implement it myself. This is a lot of the reason why software patents are ridiculous (though that is another post). So not a great day to be working at Xmarks. This happens all the time in the software world, so often in fact that we are accustomed to it and have habituated to it. Technology is based on the notion of better, faster, cheaper at every point. <b>The only way to survive is by innovation, brand or value added services, use one channel to fund another.</b> Having worked for and with businesses that have addressed this exact problem here are my top tips on how to end up at the bottom but still with a revenue stream: Innovation - be first every time People will pay for new, and they'll pay to have an edge if it gives them some sort of market benefit. The reason Adobe has been so successful is that they are very good at innovating, so are Oracle in some divisions. This is why PhotoShop in particular is still the jewel in Adobe's crown. As software goes it's hard to replicate and they have some of the brightest developers working on it constantly. Adobe are KNOWN for this piece of software few people think of going anywhere else. Contrast this with MS Office. <b>Productivity software is dead boring and the innovation has largely stopped</b> (unless you consider new slide transitions in PowerPoint innovative), this has opened the door for Open Office to catch up and become a viable alternative. Similarly Google Docs are now becoming commonplace due to the innovation they brought to the market (edit docs collaboratively from within a web browser). Being first every time is hard work, it takes a lot of investment but commands the highest returns and guarantees a revenue stream. If the innovation is slowing or worse, has stopped, it's time to reassess and start dropping price in order to keep your customers happy. Create a great brand - The Apple approach Anyone that knows me knows I'm not a big fan of Apple products but I am an admirer of the Apple business under Steve Jobs and their ability to create a technology brand so strong that it is almost unassailable. The Apple business over the last decade hasn't been the most innovative - they haven't needed to be, others made MP3 players, phones and laptops first, even tablets have been around long before Steve delivered them to us this year. What Apple did that no one else did was market the benefits not the features, they made people want their devices and they owned the space in their respective markets by sheer marketing and brand force. This is a very FMCG style approach that is at odds with most of tech but if you look at any part of FMCG you'll see space that has been crafted out of commodity goods by businesses positioning themselves as ""premium brands"". Microsoft did this in the 90s with it's Office suite. How often do you hear documents referred to as ""PowerPoints"", ""Word docs"" and ""Excel docs""? MS still push this brand heavily as it is worth millions of dollars and in light of little innovation is a good path to revenue in the future. Deliver service not software This isn't about going all Cloudy, though it could be part of it. This model embraces the idea that you aren't charging for your software you're charging for your expertise around it. Open Source businesses achieve this well most of the time. A good example is Red Hat who have eaten so heavily into Windows Server licences with their Linux distribution. Red Hat have a very profitable support division because they provide expert knowledge around Linux that isn't supplied elsewhere. Canonical are following a similar model now they are targeting enterprises. This is very akin to the Freemium model where your baseline offering is free but if you want additional, useful services in some instances then you pay for it. My advice is that any new software project starting out should adopt this model. Open Source your code but then be the experts to offer support and consultation around it (who's going to know it better than you? And if someone does, it's time to offer them a job!) Fake to the left, fund to the right I'm a data oriented guy and helped start up a business that succeeded at exactly this model. This is very focussed at Web based applications but can extend to mobile and desktop apps too. The notion here is that everytime your users do something with your software it creates data that is worth mining to create insight and can be sold to others (in specific or aggregate fashion). Google and Facebook are two clear examples of this. Google searches the Web but provides contextual ads, Facebook is the biggest repository of social connectedness and profile information on the planet - a marketers dream - which they'll pay for too. The critical things with this model are to try and work out beforehand what might be useful information to sell up front (whether through whitepapers, ad space etc) and constantly mine your data for anything new that comes up. These days it's easy to build, release and market software - there's no physical media or distribution channels to have to worry about so you can just post and go. <b>This raises many interesting challenges for the next generation of software entrepreneurs</b> and the traditional methods of revenue generation (license per seat) are simply not viable any more in most instances. All software is racing to the bottom in terms of price - the question is, have you planned for that and embraced it or are your fervently telling yourself not to worry, you'll find revenue somewhere.","['business', 'development', 'essay', 'growth', 'strategy']","['business', 'development', 'strategy', 'essay', 'growth']","[0.6059245078922744, 0.6044615851095231, 0.5990804345948559, 0.5888629815173492, 0.5775122648967697]",[],[],[],[],True,5
2010-10-07-i-like-where-i-think-sony-is-going.md,I like where I think Sony is going,"['android', 'consumer electronics', 'mobile', 'predictions']","I like where I think Sony is going
This is one of my speculation fueled posts so I'm admitting that a lot of it is based on rumour, hearsay, wild prognostication and adding up 2+2+2+2 to equal 63. With that in mind on with the rest... Right now I'm inclined to think that [Sony](http://www.sony.com) is on the cusp of a resurgence to being the most dominant player within the consumer electronics space in the world. This is a contentious point because Sony certainly represent well within every part of the CE market from computers, games consoles, TVs and phones through to DVD players and handhelds - it's not like they are at risk of disappearing any time soon. However if you look at Sony's position in these markets they are slowly slipping places, losing ground to Samsung (TVs & DVDs), Apple (Phones, Media Players), Microsoft (Consoles), Nintendo (Handhelds, Consoles) and others. However they have a huge opportunity and I think they've realised it but the rest of the world hasn't yet. The advantage Sony has over every other company I mentioned above is they are already present in every single part of the Consumer Electronics market. They also operate in channels the others don't touch - distribution and content creation. Whilst Apple might have iTunes, they still have to license the movie from Sony Pictures to distribute it. Whilst Samsung has the beautiful 50 inch LED display with a BlueRay player, they still have to get the Discs from Sony to play on it. Sony's amazing opportunity lies with their phones, and in particular their [Android](http://www.android.com/) phone platform - the [Xperia](http://www.sonyericsson.com/cws/products/mobilephones/overview/xperiax10) series. The X10 has been a big hit for Sony this year. A contact of mine from VHA says that the [X10 Mini](http://www.sonyericsson.com/cws/products/mobilephones/overview/xperiax10mini) has been selling really well even though it's a small phone with Android 1.5 - it has introduced a lot of new customers to Android and Sony phones. Couple to this Sony's [announced release of Crackle](http://latimesblogs.latimes.com/entertainmentnewsbuzz/2010/10/sonys-crackle-movie-and-tv-streaming-service-debuts-on-android.html) - their new content streaming service that will allow you to watch TVs and Movies on your phone and you can start to see their play. HTC showed in the middle of the year though that the future of the phone was one coupled to big displays. The [HTC Evo](http://www.htc.com/us/products/evo-sprint) can shoot high-def video and has a mini HDMI connector so you can throw your phone display onto the big screen - perfect for looking at pics, video or gaming. Coupled with a fast processor and a stunning display of it's own and you can see why it was one of the fastest selling phones in 2010. Many of the new top end Android phones are starting to follow suit so expect to see HDMI feature on Sony's next high-end Xperia and you'll be able to watch HD movies streamed via Crackle to your home system. With bandwidth detection it would be simple to be passing down 5 or 6.1 sound for your home theatre as well and HDMI will take care of the connections. Sony have dropped a few hints in public over the last few months about slates running Android and clearly they will be watching the [Galaxy S Tab](http://www.samsung.com/au/smartphone/galaxy-tab/) to see if they can outdo them. A mobile device that can play to BlueRay quality would be very cool and would outdo the iPad. Finally there's gaming - there have been some [persistent](http://www.engadget.com/2010/08/11/exclusive-sony-ericsson-to-introduce-android-3-0-gaming-platfor/) [rumours](http://www.google.com.au/images?hl=en&source=imghp&biw=1333&bih=626&q=psp+xperia&gbv=2&aq=f&aqi=&aql=&oq=&gs_rfai=) flying around that the next Xperia phone will be Sony's replacement for the PSP. I subscribe to this not because I love my PSP but because it's unlike Sony not to have shown us anything new for so long. The PSP Go last year wasn't a roaring success but it gave Sony experience working out how to distribute games digitally and assess the state of the market. With no hardware upgrade and no new games there wasn't really a compelling reason to upgrade. PSP is now at the end of it's life cycle. The other reason I subscribe to this is that by the time we get to the next iteration of the Xperia it should be possible to drop an emulation chip onto it to play PSP games natively without significantly affecting battery life or hardware size (Sony have a long history of this by putting in hardware emulation for PSOne and PS2 platforms to maintain backwards compatibility on old games). I've seen a few offers over the last couple of months where ""free"" PSPs have been offered to customers buying an X10. I don't think this is because sales are poor, it's an incentive to finish off the stock of PSPs and get people used to PSP games ahead of a move to getting them via your phone. With the current crop of graphics chips being designed for mobile devices and the speed improvements on CPUs (most new Android phones are running at least a 1GHz [Snapdragon core](http://en.wikipedia.org/wiki/Snapdragon_(processor))), gaming is becoming a first class citizen on mobile devices and many now far outstrip a humble PSP or Nintendo DS and are even challenging a Wii or XBox in terms of power. Combined with a couple of wireless controllers (Bluetooth naturally the same as a Wiimote) and you've got a gaming platform you can throw on the TV and take with you on the move. Pretty compelling for casual and hardcore gamers alike. I stated at the outset of this post that there's a lot of wild speculation in here but it's mixed with a lot of hope too - this is EXACTLY the way I want my home to run - my phone should be the most useful and flexible device available, being able to syndicate services to other devices to enhance it (display, processing, storage, control etc), it needs to be the hub that everything else hangs off. I don't think there are many other businesses that can do this. Samsung could have a go but they haven't got the gaming heritage nor the content to pull off a total vertical play (though partnerships could be had), Apple clearly don't have the games or the TV technology to do this (Apple TV is a dead end in my view anyway and is just a pretty Tivo - Sony could render this irrelevant). Nintendo simply don't have the interest. If Sony aren't doing this then I'll be very disappointed. If they are then I can't wait until CES 2011 as we have to be right on the cusp of some announcements around this. My prediction - the Christmas of 2012 will have a lot of Sony boxes as consumers re-envision the way their home entertainment works and finally unify all of these devices using the humble mobile phone as it's core.","['android', 'consumer electronics', 'mobile', 'predictions']","['mobile', 'android', 'predictions', 'consumer electronics', 'internet']","[0.6622445190058373, 0.6135164675735042, 0.607917765511124, 0.5885393093758067, 0.329914378142358]",['internet'],[],[],[],True,4
2010-10-18-how-to-avoid-the-audiencepresenter-disconnect.md,How to avoid the Audience : Presenter Disconnect,"['essay', 'presentation']","How to avoid the Audience : Presenter Disconnect
I've just finished two fantastic days at [Web Directions South](http://south10.webdirections.org/), a conference that has great organisers, great participants and largely informative and inspirational presentations from experts in their respective Web disciplines from around the world. There's a full wrap up coming shortly with my views on where we're going and the biggest topics of the conference but that's not what this post is about. Most conferences these days have a twitter backchannel usually revolving around the hashtag of the presentation or the conference. For Web Directions this was [#wdx](http://twitter.com/#!/search/%23wdx). This means the conferees can focus their messages and you end up with conversation and often with a [semi-live transcript](http://wthashtag.com/transcript.php?page_id=19429&start_date=2010-10-13&end_date=2010-10-16&export_type=HTML) of the presentations with insights that people not attending the conference can view at the same time. Over the course of WDX the backchannel was largely positive with nearly 3000 tweets in two days from over 500 contributors. This highly engaged audience is much more ""tweet-happy"" than any other conference I attend over the course of the year. At two points during the conference though, the mood turned bad - the closing keynotes of both days. The backchannel created a feedback loop of negativity that created a unruly mob. This isn't unique to WDX, I've seen it have a few times now - a real time back channel can significantly amplify the point where a speaker loses their audience and this is what I call the Audience:Presenter Disconnect - the moment where the two occupy the same space and time but two entirely different activities are occurring. At this point I'm going to point out that I am a speaker, I've presented at [Web Directions previously](http://www.webdirections.org/resources/andrew-fisher-cloud-computing/) and some other conferences large and small. The thought that an audience could turn on me like this makes me feel sick thinking about it but hopefully this gives me a perspective that can explain the behaviour and provide thoughts on how to combat it as a speaker. Why the back channel turns feral: The backchannels can turn feral for a variety of reasons, but here are some of the main ones I've seen. Idleness I've seen this happen in numerous presentations and is simple ""Idle hands doing the devil's work"". This sounds like a ridiculous explanation but I think it counts for a lot. Conferees come expecting to mostly be informed - entertainment is a bonus but mostly it's about information delivery. I sat through one of the most awful presentations of my life at the CIO summit earlier this year and no one turned on the speaker because as bad as his presentation was, his information was brand new and clearly understood by the audience. If you are providing a solid stream of information, your audience won't have time to do anything other than process the data and concentrating on shaping your messages into 140 character bursts of insight and throwing them to the wind. A great example of this was [Simon Pascal Klein's](http://twitter.com/#!/klepas) presentation on [Web Typography](http://south10.webdirections.org/program/design#setting-standards-friendly-web-type). His presentation wasn't the most entertaining but it was one of the most information dense of the conference but was paced well. The volume of messages flying out was consistently high during the whole session. The overall sentiment was of extreme positivity and he will get a lot of deck downloads afterwards. [Dan Rubin](http://twitter.com/danrubin), [Dmitry Baranovskiy](http://twitter.com/dmitrybaranovsk) and[ Matt Balara](http://twitter.com/MattBalara) were other positive highlights because of the amounts of information packed into their presentations. If your presentation lags in terms of its information density people start thinking ""why am I here?"" and start saying as much. Misjudging the audience At any technical conference, be it Web, engineering, medicine or otherwise a speaker should never underestimate the knowledge of their audience. A conference is a place for people of similar interest and skill level to swap information and learn from others so the whole group improves over time. The biggest danger a speaker has is pitching low - better to go high and force some of the audience to ""step up"" their knowledge afterwards rather than go low and appear patronising. Dmitry Baranovskiy and [Steve Souders](http://twitter.com/souders) both did excellent jobs of this - loads of people walked out of their sessions saying ""wow - that will take me a while to digest"" but no one walked out saying ""I knew all of that, what a waste of my time"". As a speaker at a technical conference you are either there to inspire generally such as Scott Thomas did with his Designing Obama opening keynote or more likely you are there delivering knowledge as a ""First amongst equals"" like Dmitry, Steve Souders and [Daniel Davis](http://twitter.com/ourmaninjapan) did. The best presenters I've seen do this (and all these three did it) and take the attitude of, ""I found something you might think is interesting, check this out"". I spoke to Steve Souders after his talk about some of the content and his results. Even one-on-one I found him to be extremely humble and willing to listen to some ideas that might help him from some random guy even though he's written the books on site performance. Everyone is a specialist at something but in the development and design of the web we're all technical peers and behaving like one gains a lot of positive sentiment. The feedback loop The twitter backchannel moves quickly, if you are sitting in the audience with a laptop or iPad (that is, any device where you can consume and contribute very quickly - phones are a lot slower in this regard) the conversation is reacting in as close to realtime as possible with only seconds passing from a speaker making a point or displaying a slide and feedback appearing upon it. Again, where the speaker is informative or entertaining you see a feedback loop of positivity - someone tweets quickly and a slew of people retweet the original or add further comment. [Ben Schwarz](http://twitter.com/benschwarz)' presentation on Thursday had a lot of this - he was making some fairly controversial statements about the W3C and as it was delivered well he received an immense amount of ""yes I agree"" style responses. The audience was onside and he turned that into action by illustrating how he stopped bitching and started doing - launching the [HTML 5 spec for Web Authors](http://dev.w3.org/html5/spec-author-view/) during his presentation, possibly the most highly shared piece of content of the conference. We had to follow his actions with our own. Contrast this with the closing keynotes. Once people started making negative comments, more people retweeted or chimed in on the ""I agree"" bandwagon. One of the presenters got a lot more pointed criticism at his presentation because the audience was mis-sold. The session was ""Where are we going?"" but spent 30 minutes on ""What has influenced where we are going?"". The audience got grumpy. To [Josh's](https://twitter.com/JW) credit his last 10 minutes were inspirational and gave us a future vision of location services - the audience rallied around him and he managed to largely turn them back onto his side by the end. The backlash backlash The feedback loop is a fickle thing and it can turn positive or negative very quickly. An interesting side effect is the ""backlash backlash"". This is the equivalent of a [Cnut](http://en.wikipedia.org/wiki/Cnut_the_Great) moment where several people start trying to stop the negative loop by saying ""hey it's really hard being a speaker give the person a chance"" or ""I don't see you standing up there - put up or shut up"". Unfortunately this typically fans the flames and it was interesting to note that neither Maxine or John from Web Directions waded in during the presentations or afterwards which is a great approach for the following reasons. As a speaker if I screw up I'd like to know about it afterwards. A tweet transcript is a great way to get feedback about a presentation. I can review it over time compared to my deck and see what was a problem. Likewise, I have the right of reply. If someone's said something you can bet I'm going to answer them later. Because of it's immediacy, even with the dangers of the feedback loop, twitter is a very good release valve. On stage you can feel the audience's attitude, whether they are engaged and watching you or whether they are talking amongst themselves. [Scott Berkun](http://twitter.com/berkun) in his book [""Confessions of a Public Speaker""](http://www.amazon.com/gp/product/0596801998) talks about this a lot. This creates its own feedback loop as positive audiences provide energy to the speaker but negative ones sap it. In my view Twitter provides a valve that stops negative feedback washing onto the presenter and causing them to do worse. This means that at a high point the speaker can still turn the audience onto their side and get the positive effect rather than going flat. Josh Williams' presentation showed he had ""some left in the tank"" towards the end and finished very well because of it. What can you do as a speaker? As if standing in front of several hundred people wasn't harrowing enough (I even get physically sick from nerves), as a speaker you now have the backchannel to worry about and whether or not you'll be eviscerated on twitter. Below I've got some thoughts about what can you do to stop the Audience:Presenter Disconnect and create positive feedback in the back channel. Focus on speaking not the back channel One of things I love about Web Directions is that it doesn't display the twitter stream during sessions. This stops the feedback loop going out of control and influencing non-tweeters in the audience and allows the speaker to focus on delivering their presentation not splitting their attention between the two. If you are presenting, find out whether the feedback loop will be shown and if you aren't comfortable that you can zone it out of your awareness insist it's turned off. Say to the audience you have a really low attention span and you'll watch it instead of delivering your presentation - they won't care as they can still see it via their clients anyway. Engage the back channel before the session [Craig Mod](http://twitter.com/craigmod) gave an excellent presentation on how Digital affects books & publishing. One of his most interesting ideas was this notion of the ""Immutable Artifact"" - in his case a book. I would suggest a presentation is an Immutable Artifact; it's almost impossible to change once you've started delivering as it's scripted and tied to a deck. However, Craig talks about how the lines of the immutable artifact can be blurred by getting contributions before it's creation. This can be done through various channels beforehand asking what people want to know about before you construct your presentation. Afterwards it's about taking feedback and commentary and working it back in whether by adding appended notes when you upload it to Slideshare or by reworking parts for your next presentation. Conversing with your audience before hand connects them to you more closely and gives you humanity through prior engagement - it's harder to lay into someone you ""know"". Deliver information first, entertainment second I made the point earlier that I've seen some horrific presentations but they were so information packed and thus valuable. Any presentation that is remotely information led, imparting knowledge from your brain to your audience's with some nuggets of insight should put the information delivery first and worry about the entertainment second. Some presenters are witty and full of energy, bouncing around on stage and can talk without notes. At WDX, [James Bridle](http://twitter.com/stml) did this, so can John Allsopp. If you can't present like this, don't even try. I am so nervous during a talk that even if I had a perfectly scripted joke it would come off flat and fail dismally. Steve Souders' presentation was information dense, it wasn't comical or witty but it was an outstanding presentation and his is well worth watching and learning from in terms of style. Contrast this with one which has very little information density and is trying to be entertaining by showing videos and funny pictures or cracking jokes. It comes off poorly for being vacuous and the audience feel ripped off for having sat through it. At a conference the audience is paying for the speaker to inform them. Entertainment is a nice surprise when it happens. If I want to be entertained by people on stage I'll go to a concert, the theatre or see some stand up comedy. Conferences are a different context and one that all technical presenters should consider when creating content. Delivery of information will stop the ""Just get on with it"" or ""Tell me something interesting"" type chatter in the back channel. If you create a steady stream of points people will be so absorbed taking notes and passing on your insights they won't care if your slide is out of alignment, you fumble some words or haven't told a joke. Consider points that can be tweeted I hate this idea as it's a sign of our waning attention spans but it's a fact of life so you either roll with it or stick your head in the sand. Our communications are turning into microbursts of activity. When you take notes at a conference you note the points not the words, when an audience member tweets, they compress and express the insight, not all the details. If you are taking a long time to get through a point or have made the same point ten times the audience is going to start getting frustrated as they have stopped annotating your talk. This is complex because sometimes you have to build a story to illustrate a point. The challenge is to get there quickly and avoid the ""I wonder where this is going?"" style comments. Something I've started doing recently as a result of observing my own behaviour at conferences is reviewing every slide I'm presenting and expressing it as a tweet or short annotation. If I can't, or it takes me a paragraph to express then it's a problem and I can try and fix it. If your presentation has gone more than about 3-4 slides (about 2-3 minutes) without something tweetable or notable then you're on the limit of the audience's attention span wavering. Unfortunately, Tim Harrison suffered from this heavily - in 50 minutes I tweeted only a few points he'd offered and didn't write any notes. Contrast this to Simon Pascal Klein's presentation where I sent 20 tweets AND wrote 3 pages of notes! Craig Mod similarly scored 15 or so tweets and a few pages of notes as well. We live in an age of soundbites and 140 character points - make it easy for your audience to rebroadcast your message and they will. Don't go silent This is a strange one that I've just realised due to seeing a series of videos used in a talk. Video is a powerful medium if it's used well and I've come to the conclusion that the only time you can use it is if you are providing a commentary or it is extremely short (I'm guessing less than 20 seconds). Steve Souders and James Bridle did excellent presentations incorporating video - not least because they were showing things that were relevant to the presentation but they were annotating the moving image with their own insight. Scott Berkun writes about the moment when hundreds of people channel their energy directly at the speaker - which can then be harnessed into your presentation. Directing that at a 3 minute video when you're not speaking squanders that energy and turns your presentation into a cinema experience. Challenge the common view and provide more than Google One of the most common tweets to start a negative backchannel looks like this - ""You need to consider X when you do Y - yep we've all got it lets move on"". This often happens when a speaker dumbs down for their audience who consequently get bored of a point that was made in 30 seconds but is taking another 5 minutes to deliver. Assume that over half the audience know close to as much as you do in your topic area. You're the specialist but only by a small amount. Also assume that the other half are more than capable of understanding what you're talking about and will be inspired enough to go and find out more because of the information you've delivered. If you follow these two assumptions then you won't belabour a point or regurgiate information that can be found with a google search. Ben Schwarz' presentation on HTML 5 showed this beautifully as the information he delivered in the second half of his talk was almost impossible to find. In 20 minutes he aggregated months of work into simple points everyone could take away and research further. Dan Rubin and Steve Souders did the same thing - is it any wonder their resource links on their last slides were some of the most shared pieces of content of WDX. A great way to avoid this is to test your presentation on other people. Steve Souders' presentation showed this - it was honed so there was nothing superfluous. User testing is always a worthwhile thing to do. Don't disrespect the audience This goes without saying but it's a minefield. Disrespect can come out in a lot of different ways, lack of preparation, appearing bored or not giving your audience enough credit. Again, testing your subject matter and the way you're going to deliver is well worth it here. I've pulled slides numerous times because of feedback that it was pitched too low. Conclusion There are plenty of much better speakers and presenters than I am or ever will be - I work with at least two and I am in constant awe of people that can deliver amazing presentations effortlessly to any sized group. Conversely, I don't think I'm the worst speaker or presenter ever - mostly because I am so nervous that I don't lack for preparation - I literally have backups of backups of backups to account for things going wrong. I don't know whether the things I've written about here are right, or if they are right for you. They work for me, it's how I approach a presentation and if they help you out too that's great. I think I have a unique perspective because I present and also a vocal and active member of the backchannel at any conference - it's what I do. I think the backchannel is a great method for freeing information and catapaulting it outside of the conference hall, promoting the work of the presenter to others that couldn't be there who can in turn pick it up and amplify it. An audience doesn't come to watch a presenter fail. They come to be informed, to hopefully be entertained but mostly to go away feeling as though the presentation was worth the money it cost and the time they invested to view it. Twitter can be a powerful amplifier of your message if you can get the backchannel working for you - unfortunately it can also go negative but at least now you know the reasons why and how to prevent the Audience:Presenter Disconnect from happening before you've even stepped onto stage.","['essay', 'presentation']","['essay', 'presentation', 'web', 'media', 'internet']","[0.5953049591261219, 0.592365959312976, 0.3383759181537529, 0.3306282614128011, 0.326368506022433]","['internet', 'media', 'web']",[],[],[],True,2
2011-01-10-computing-is-finally-becoming-personal.md,Computers are finally becoming personal,"['android', 'apple', 'consumer electronics', 'internet', 'media', 'mobile']","Computers are finally becoming personal
After going back to work, it dawned on me that I hadn't used a computer for nearly two weeks - evident in the fact that I spent my first day back getting helplessly finger-twisted using a keyboard. Two weeks away from a computer for me probably hasn't occurred since 1990 when I went away camping and surfing for a month. So what occurred this Christmas? For those two weeks I [searched](http://www.google.com), I [tweeted](http://twitter.com/ajfisher), I read marketing emails from [Amazon](http://www.amazon.com), I read books on my [kindle](http://www.amazon.com/kindle), I watched videos on [YouTube](http://www.youtube.com), I got the [dismal cricket scores](http://www.guardian.co.uk/sport/ashes) via an app on my phone, I took photos and read blogs and all the while I maintained my connection to the Internet but not once did I fire up a computer and do something with it. This random change in behaviour was a result of several factors. First I wasn't working and wasn't on call, second I didn't do any programming or other origination of content, everything I did online via my mobile phone. For two weeks straddling 2010 and 2011 I had adopted a [Jobsian](http://en.wiktionary.org/wiki/Jobsian) approach to the use of my technology - one that was totally integrated into my daily life. <b>My computing had become first and foremost consumption driven but it required no ""computer"".</b> My dad got a [Galaxy S Tab](http://www.samsung.com/au/smartphone/galaxy-tab/) for Christmas - something he said that I laughed off at the time has since been nagging me. His question? ""What can I **DO** with this thing?"" My reply at the time was a flippant, ""nothing, it's a consumption device"". The full meaning of this only came home after watching [manufacturer after manufacturer](http://www.engadget.com/features/tablets-at-ces-2011/) parade a seemingly infinite number of tablet computing devices, most of which were running [Android](http://www.android.com/) - as much a consumption oriented operating system as [Apple's iOS](http://www.apple.com/ipad/). ![First era personal computer terminal](../../img/posts/zenith.jpg) With increasing speed, the computing landscape is moving towards one of consumption driven devices not general purpose computational devices. Tablets (including the iPad and others) are [expected](http://news.yahoo.com/s/afp/20110105/ts_afp/usitelectronicstelecomcomputerinternetces) to shift 30 million units of sales in 2011 and the Kindle is likely to shift another 20 million units just by itself. 70% of all computers sold are now laptops, netbooks or tablet devices - the humble desktop now almost only exists in a business context. Whilst we've had tablets and laptops for a very long time, I suggest that almost ubiquitous wireless networks coupled with the launch of the [eeePC](http://en.wikipedia.org/wiki/Asus_Eee_PC) was the starting point of this trend showing low cost, highly portable, consumption oriented computing had a viable market. Apple honed this with their usual precision and flair with the iPad which proved the viability of the consumption market once and for all - especially when paired with a content delivery channel. The rest is history and we had nearly 100 ""me too"" devices flood the market at CES last week ready to cash in on the trend. As I was mulling these thoughts over, I explained to my astonished 6 year old that when I was his age <b>we had one computer for a large family and were the only people for streets around to have one.</b> It was a shared resource not only for our family but for our neighbours as well. Contrast that to his childhood where there are more computers than people in our house. Consumer computing has been subjected to the same forces that have provided us with cloud computing and [virtualisation](http://en.wikipedia.org/wiki/Virtualization) - where we now have so much computing power available to us that we can use it in frivolous consumption oriented activities. Whereas in the past, computers were designed to primarily produce and by their general purpose nature be able to consume as well, we are now adopting a mode where most devices are oriented for consumption. In a world where 1% of the computer users are creators, 9% are [prosumers](http://en.wikipedia.org/wiki/Prosumer) and 90% are consumers, the creator becomes the niche market. This transition doesn't come without its challenges, the closed nature of most modern computing is of concern to those of us who believe in the [freedom](https://www.eff.org/about) to do what you want with software and hardware. Whilst I'm not a fan of closed systems (and express this with my wallet and my advocacy of open alternatives) I am similarly heartened by the idea that with ubiquitous access to computing technology we will see an exponential rise in connectedness and the humanity that stems from that. As we make this shift, we will finally realise the idea of the Personal Computer - no longer an aspirational IBM marketing slogan that has eluded us for nearly 30 years. At the start of a new decade, computing has finally hit a point such that each person can have a personal computing device and experience tailored to their needs as a Creator, Prosumer or Consumer that goes way beyond the changing of a desktop wallpaper and a superficial choice of Operating System. _Update 9/Feb/2011: [Latest sales figures](http://unplugged.rcrwireless.com/index.php/20110208/news/6928/smartphone-sales-top-pc-sales-for-the-first-time/) show smart phones outselling PCs for the first quarter ever in 4Q10 - surely a sign that consumption oriented computing is becoming a mainstream phenomena._","['android', 'apple', 'consumer electronics', 'internet', 'media', 'mobile']","['mobile', 'internet', 'media', 'android', 'consumer electronics']","[0.651255605773788, 0.6262483106050173, 0.6233644676404662, 0.6009084833796329, 0.589733376619641]",[],[],[],[],True,6
2011-01-18-android-fragmentation-really-not-a-big-deal.md,Android fragmentation: really not a big deal,"['android', 'development', 'google', 'internet', 'media', 'mobile', 'rant']","Android fragmentation: really not a big deal
This is a post I've been mulling over for a while and it now seems the right
time to put my thoughts down around the issue of
[Android](http://www.android.com) Fragmentation. There has
[been](http://arstechnica.com/open-source/news/2010/06/ars-explains-android-fragmentation.ars)
[a lot](http://news.cnet.com/8301-30685_3-20023199-264.html) [of
talk](http://blog.appboy.com/2011/01/android-fragmentation-in-cold-hard-numbers/)
amongst the community about this and whilst some was fuelled by [Steve
Jobs](http://techcrunch.com/2010/10/18/steve-jobs-android-audio/) (though they
are remaining remarkably quiet currently) it seems like the fragmentation
""issue"" now has a life of it's own amongst devs. The start of the whole fragmentation debate goes back approximately a year to
the end of 2009 / start of 2010. At this time Android version shares looked
something like this: Cupcake (v1.5): ~ 30% Donut (v1.6): ~ 50% Eclair (v2.1): ~ 20% By the end of 2009, we had seen 3 major upgrades to the Android OS in 6 months
(1.5 in April, 1.6 in September and 2.1 in October). What has been forgotten is
these shares coincided with releases of new handsets (which at the time were
very few). Indeed the incredible rise of Eclair in less than 3 months to 50% of
global market share of Android users was largely due to the success of the
[Motorola
Droid](http://www.motorola.com/Consumers/US-EN/Consumer-Product-and-Services/Mobile-Phones/Motorola-DROID-US-EN)
which had significant uptake. It also illustrates that the total population of
Android devices was still relatively small at this point so could be easily
swamped by a new device and new OS this is less the case now as can be seen by
low levels of Gingerbread (v2.3) penetration. The reality is that prior to even Froyo (v 2.2 released in May 2010), Android
was an operating system in pretty small total numbers (especially compared to
iOS, Symbian and Blackberry) and was still rather niche with respect to it's
end user (firmly aimed at knowledgeable techies who wanted a hackable
smartphone) - it was also very BETA software. At this point the Android team
could afford to push a large number of OS upgrades, allowing for
experimentation and feedback very quickly - they also gave themselves the
opportunity to prove momentum of the operating system and to go to market with
new stories, showing big improvements each time. Recall the almost slow hand
clap that Apple received once it finally released Copy and Paste actions -
something they could have pushed earlier were it not for their annual release
cycle. In 2010, after the release of Froyo, we see a significant slow down in version
releases now the software has matured but the Android team is also bowing to
pressure to do fewer releases over time because of slow carrier uptake on
upgrades. This is often caused by carriers making customisations with the
manufacturers and they get[ charged for doing
updates](http://ausdroid.net/2011/01/17/samsung-insider-tells-the-world-how-android-updates-through-carriers-work/)
as has become recently apparent. The biggest problem the Android team had was at the point where Cupcake, Donut
and Eclair were all more or less evenly split in share and there was some
significant differences in the underlying APIs which could cause breakages.
There were features that just weren't available in older versions of the API
and it's from this root that the fragmentation issue stemmed. Fragmentation isn't just an issue for Android developers though. As a Web
Developer I've had significant fragmentation issues with browsers over the
years (if you're old enough - remember going from 800x600 displays to
1024x768?). Adobe (previously Macromedia) Flash also caused significant issues
when everyone wanted to use a feature of a new version (eg Video) which wasn't
available in portions of the installed base and let's not even talk about the
legacy of IE6. It's not often talked about, but even iOS has fragmentation issues - most of
our clients want support back to the iPhone 3G (a widely used phone due to the
2 year contracts we have in Australia) - and there were such fundamental
hardware changes between versions that it still causes us issues if we need to
use something like the camera (in image processing for example there's no auto
focus). Almost every version of iOS requires different sizes of things like
icons and this is particularly noticeable when you have to produce assets for
the iPhone 4. Likewise as you move to the iPad there's a different set of
capabilities (no camera for example, a lot bigger display) and I'm sure as we
move to the iPad 2 there'll be a considerable number of inequalities across
versions. [These
numbers](http://www.quora.com/What-proportion-of-all-iPhone-owners-use-iOS4-*-today)
from the guys at Bump indicate that 10% of the population are still on iOS 3
which is not insignificant - and a lot more than 10% are using iPhone 3G and
3Gs' so there's hardware concerns as well as software ones to consider. Just about every developer with some degree of experience has to deal with a
fragmentation issue at some point. If you want to see **real** fragmentation in
action, become a PC game developer for 18 months - just about every component
can be changed in a PC and cause the computer to have very different
capabilities and developer headaches. We're just starting to see Android tablets (and probably phones too) with Dual
Core chips in them and it's widely rumoured the A5 (the chip powering the
iPad2) will be Dual Core too. What's that going to do for your fragmentation
once all your code needs to be multi-threaded? Here are some methods to deal with fragmentation: Stop Whinging It's not going to change any time soon and nor do I want it to. Having a rich
ecosystem of device manufacturers creates innovation that benefits consumers
and creates new opportunities for developers. Do you remember what phones were
like in 2006 when Nokia was the only company ""innovating"" due to their massive
global market share? Perhaps you would prefer to go back to your Blackberry
from 2007? Stop whining about how hard your life is to support all these
devices - not everyone can afford your high end Galaxy S from Samsung or
upgrade to the new iPhone every time Apple release one. Accept diversity and
accept that not every device will be pixel perfect and move on. Understand your market and where it's heading The Android team have [this
page](http://developer.android.com/resources/dashboard/platform-versions.html)
on their site for a reason - it's to help you understand right now and
historically what sort of devices are available in the wild right now - I'd
love to see Apple do the same thing to help make it easier for developers to
understand the devices in the wild. Once you know your numbers you can
extrapolate trends and work from there. For example we're working on a project that might have some issues with Cupcake
(~5% market share now) - we aren't supporting it for the same reasons we aren't
supporting IE6. In order for us to try and achieve compatibility it would cost
too much and we know Cupcake is on the way out. It's largely on phones nearly 2
years old so as people upgrade over the next 6 months it will disappear nearly
altogether. Do you really need that API feature? I'm a developer, I know what it's like when you get new features - it's like
being an 8 year old in a candy shop with $10 in your pocket. If you know your
numbers you can assess whether you absolutely need something or whether you
just want it because it's shiny. Structure your code properly We have an architecture called [Model View Controller
(MVC)](http://en.wikipedia.org/wiki/Model%E2%80%93View%E2%80%93Controller) -
you're using it right? If you don't know what it is may I suggest some further
reading before embarking on phone development. MVC gives us the tools to
decouple the different concers of our code (data and logic from UI and
interaction). If you design your application the right way, you might need to
do some UI tweaks to deal with a device with a larger screen than others - but
guess what? That's all you'll change. Also your users will love you for it
because the app works perfectly on their device. Progressive enhancement This has been a big part of web development for some time now and in turn came
from game developers. If a basic interface will do for older devices then use
it then enhance the elements you want to when you know that the device has more
capabilities. An example of this is GPS. On the original iPhone, GPS wasn't
available - but that doesn't mean you can't do location based on cell tower
triangulation or using WiFi locations to give you an estimate of where someone
is. It won't tell you what street number they are standing at but it will give
you suburb resolution. Build for this and then if you can get the GPS
coordinates then great - you get better resolution as devices get better
(especially over time). Do you really need an app? This is still a [big area of
debate](http://www.google.com.au/search?sourceid=chrome&ie=UTF-8&q=mobile+web+vs+native+app)
but if you answer ""no"" to the above question, fragmentation issues within and
across Operating Systems largely disappear. If you can implement what you want
as a mobile website then not only will it be easier to build, it will be easier
to maintain and you can support more devices in one go rather than building
lots of different apps over at least two operating systems. Similarly, a further question is ""Do you need a totally native app?"" Using
something like [Appcelerator](http://www.appcelerator.com/) or the Open Source
[PhoneGap](http://www.phonegap.com/) gives you a lot of cross-platform
consistency and allows you to be a lot more efficient in app development -
especially if it's something that could be created as a web app. Listen to your customers Release early and release a lot of updates - with all the best testing
available you're never going to simulate the mix of capabilities, OS and
installed apps on someone's device. Be clear about the status of your app and
allow them to feedback - thank people for their support and taking the time to
file a bug report - every bug seen is a step along the way to having a
fantastic, well honed product. Be specific about your support Pick up any computer game and it has minimum requirements. Even Nintendo do it
with different versions of the GameBoy or with requirements for Wii Motion Plus
controllers. If you're doing it for a reason have some cajones and stand up for
your rationale. ""Sorry, this won't work on these devices because the chip isn't
fast enough to play the game"" works well. If you're not going to support HTC Magics (MyTouch) - tell people. There's no
point beating around the bush and then getting a bunch of bug reports you won't
fix and annoy your customers which will turn into hate mail. Tell them upfront
and they'll thank you for it - if they see it more often it might even spur
them to upgrade to a new phone in all it's Gingerbread or Honeycomb glory.
Likewise use your platform targeting in the build process so some of those
Cupcake and Donut devices just don't even see your app in the Market. Fragmentation can be an issue if you let it become one. Embrace the diversity
and the challenge - remember that the apps you're building could be creating a
whole new experience for someone that will change how they communicate or go
about their daily life and that's an exciting place to be working - better than
maintaining a 30 year old banking system huh?","['android', 'development', 'google', 'internet', 'media', 'mobile', 'rant']","['mobile', 'media', 'internet', 'android', 'development']","[0.6450772840786345, 0.6164627517041379, 0.60837645750715, 0.6013997585510167, 0.6013830442956625]",[],[],[],[],True,7
2011-02-12-microsoft-buys-nokia-for-0b-what-this-means-for-mobile.md,Microsoft “buys” Nokia for $0B - what this means for mobile.,"['business', 'mobile', 'nokia', 'strategy']","Microsoft “buys” Nokia for $0B - what this means for mobile.
Windows Mobile 7 is the latest incarnation of the Microsoft mobile platform
that started in the late 90s as Windows CE. It has always had relatively good
penetration in the mobile business sector and has been the foundation of HTC
and Samsung's smartphone strategies. For the latter part of the decade though,
Windows Mobile has been languishing, and the release last year of WinMo 7 was
received by the industry with a cursory “I think Microsoft just updated
something to do with mobile” before switching their attention back to what is
happening on the iPhone, Android and Blackberry platforms. To be fair to Nokia, they have been fighting a rearward action for a long time.
Whilst their presence in all markets outside of the US has been and still is
strong, the global landscape is shifting towards the US as a leader in mobile
technology and their position is being slowly eroded. With the launch of the
iPhone and subsequent launch of Android, Nokia and many of the “old”
manufacturers have been finding it tough. Nokia had to partner with someone to make their handsets relevant to the market
again. It transpired last week through conversation coming out of Mobile World
Congress in Barcelona that both Android and WinMo were considered as options
for the new platform. WinMo won out largely because Microsoft has agreed to
spend a lot of money marketing the platform at consumers and developers alike. The latter should not be underestimated in it's impact on a platform. iPhone
and Android have very large shares of mind with developers. Nokia attempted and
failed at doing this in the mid 2000s. Apple and Google have excellent
developer relationship programs (including Google bribing developers with brand
new handsets) and excellent App Store systems. For Apple to have 250,000+ apps
in iTunes there's probably over a million developers who have played with the
development kit and probably similar numbers involved for Android. That's a lot
of “reach out” being done by two companies but between Nokia and Microsoft they
can do this (not least because Microsoft has this function already embedded in
the business). Nokia has said that WinMo phones will be shipping in 12 months – personally I
think they need a handset ready for US Thanksgiving and rest of the world
Christmas as this is a known hot period for sales. Assuming this is the case
who do they target? Well Nokia shifts a lot of phones to people who don't care
what it's running and the fact it's Windows Mobile won't matter at all. Nokia
will continue to sell many tens of millions of handsets to this group just by
virtue of being cheap and able to make calls and send texts. Then there are the “feature phone graduates” - those consumers who will be
looking for their first smartphones. For Nokia and Microsoft these are critical
customers. Give them a positive smartphone experience and they won't shift to
iPhone or some Android device – they won't risk it. Give them a terrible one
and they'll disappear over the horizon when their 2 year contract winds up.
This is the fastest growing group of users and largely responsible for
Android's boom in 2010. However, unless Nokia can produce an extremely slick high end device capable of
competing against an iPhone, Galaxy S or Evo then Nokia will lose the top end
forever. This is very risky ground for Nokia and Microsoft right now. The
reason brands like BMW and Mercedes compete in Formula 1 Racing is to drive
technology that eventually trickles into consumer products but to also create
branding that is aligned with high end technology (which trickles down into
consumer consciousness). Part of Nokia's current woes are that it isn't viewed
as pushing the boundaries like it once was (the Nokia 7710 is the conceptual
grandfather of the iPhone but it's been nearly 10 years since the company was
capable of producing devices like this). The risk for Microsoft in all of this however is that long-term Microsoft
partners, HTC and Samsung may feel alienated by their tight partnership with
Nokia and decide to abandon their Windows Mobile devices completely. WinMo has
already taken a backseat to Android for these manufacturers (and has led to
fantastic growth for HTC and positioned Samsung as now competing against Apple)
so they probably won't be too worried. Microsoft should be though because there
could be 6 month period where there are no Windows Mobile devices launching
into the market. So what does the marketplace look like in 2 years time once Nokia / Microsoft
have had 12 months to shift product? I predict we'll see Android retaining it's number one operating system spot at
somewhere around the 30-35% market share point. After this will come iOS at
approximately 25-30% (especially given Apple's likely iPhone Nano launch at
some point) and then we'll be seeing significant fighting going on between RIM
(Blackberry) and Windows Mobile / Nokia for about 25-30% between them. Symbian
will probably still exist as devices are slowly transitioned to newer hardware. Nokia and Microsoft's first hurdle will be to overtake RIM quickly – within 6-9
months. If the platform doesn't launch with significant momentum (possible
given Nokia's distribution reach) then both companies may as well give up. As a marketer what does this mean? Well you'll still need to market to all of those 100 Million Symbian devices
that were sold last year and the couple of hundred million in circulation that
are connected to the Internet right now. iOS and Android should be your
flagship platforms with degraded support for Symbian, Windows Mobile and
Blackberry. This will give you future proofing as well as picking up the people
actually in the market now without worrying too much about who they might be in
two years time. Of course this flux lends itself to ensuring a flexible mobile strategy – not
going down the path of complex, expensive Native Apps when a mobile website
will be sufficient and more cost effective. The current history playing out in front of us is showing very clearly that
Mobile is the single most important battleground right now and that even
industry Goliath's are not immune to the disruption occurring. Update: dead links removed","['business', 'mobile', 'nokia', 'strategy']","['mobile', 'business', 'strategy', 'nokia', 'android']","[0.6662525649687892, 0.633092731911529, 0.5955361766407105, 0.5840762450026126, 0.32393808371415866]",['android'],[],[],[],True,4
2011-08-08-the-web-of-intent.md,The web of intent,"['essay', 'internet', 'media', 'predictions', 'web']","The web of intent
Web Intents, Web Activities, Web Actions - call them what you will, I'm going to call them the future of the web app. The idea isn't new - for example the humble mailto: ""protocol intent"" has been around since about web 0.1 as a means of telling the browser to do something other than render a web page (in this case, fire up an email client and send a ""mail to"" whoever's email address it was). Various application makers have hooked into this over time to give you more functionality direct from the browser eg Skype transforming all the tel: links to clickable phone numbers so you can [Skype](http://www.skype.com) to directly (as well as doing some regex parsing to trying and find phone numbers in text too). Likewise there have been a [few](http://www.webintents.org/) [thoughts](http://tantek.com/2011/220/b1/web-actions-a-new-building-block) [over](http://web-send.org/introducer/) [the](http://mozillalabs.com/blog/2011/07/web-apps-update-experiments-in-web-activities-app-discovery/) last 6 months or so attempting to develop out this idea with varying levels of success. For the purposes of this post, I'm going to use the term Web Intent. I know it has android specific loading as well as infers an underpinning API binding but I'm going to assume here they are all interchangeable. What makes web intents different than a protocol link is that they are fundamentally bound to the services we play with on the web. I look at the applications I have installed on my computer these days and other than the stock things I use to develop code, just about everything I use day to do day is a web app - twitter, gmail, gtalk, flickr, github etc. Installing applications on my computer is becoming a thing of the past, but I haven't replaced this behaviour by installing loads of plugins / extensions for my browser. Instead; in the tabbed browser world, I simply have tabs up one end of my browser window that are permanently there. I also have a couple of extensions that operate at a meta-level on the whole page I'm viewing - notably bit.ly, evernote and chrome2phone. ![Chalkboard with the phrase 'will you (blank) me?'](../../img/posts/will_you.jpg)
*[image (cc) Poppy Thomas-Hill](http://www.flickr.com/photos/pinkpoppyimages/)* But all of this is back to front - and this is the beauty of the web intent - I want to bring my existing services to the attention of the page so it can interact with what I'm looking at right now without that web page needing to know anything specific about the Intent directly (eg what protocol or services it also has available). It's at this point that a demonstration is probably useful. This is the Mozilla labs view of Web Activities which is a similar concept. It's a little contrived because nothing exists yet except the flickr plugin but it explains the idea. Go ahead, watch the video, this will wait. So now you get the idea - as a user I can ""install"" personally useful web apps that do certain things and when I want to use them I can push the content to the app which then interacts with it in some fashion. That's all well and good but I can imagine my ""app tray"" beginning to look something like my twitter favourites or my browser bookmarks so will get out of control pretty quickly. Likewise, as a developer I struggle with this issue all the time. Just tonight I was updating the share plugin for word press and there are over 50 places I can share a link to - if I was to list them all the share system would be bigger than this blog post. That's insane! I get into trouble about this all the time with clients - yes I know you still think everyone's using mySpace but seriously no one's sharing there - least of all from your professional services oriented blog post. As a user I probably use two (either facebook or twitter as well as email), possibly three (add a bookmarking service of some sort) and rarely use four (say chrome to phone). I'm a power user - my mum just shares it to facebook - my wife just copies the link into an email. So now I'm going to talk about real intents as I see this developing. I see this broadly aligned to the way Android Intents work, which as a developer was one of the strongest features of the early platform. It allowed developers to build upon others' work without needing to worry about the specifics of the programming library (which is how you usually build on programming code) or the API (which is how you usually interact with other web services). Real intents are exactly that, they capture the ""idea"" of what you're trying to do and take action upon it. The best one I always think about is sharing. Say I have a page, a snippet of content or a photo and I want to share it. What do I do? If it was a URL I could bit.ly it, I could send it to my phone, I could email it, tweet it, facebook send it, facebook like it, digg it, ever note it, reddit it or all sorts of things. The reality is I'd probably just tweet it, I may email it and if I want it later it'd evernote it. This is where intents come in. As the page author (or web application author) <b>all I need to do is declare the intent ""Share URL"" and the browser will query my services that match that intent</b> and provide them to me. Only the web apps that can service that intent will appear and there'll be extra points for a browser that tracks how often I use each one and surface them to the top of the list. I could also have ""Share image"" which will render a different set of intents - including local and remote printing services for example. ""Save for later"" could sync it to my reader, send it to my kindle or phone, create a diary entry for me to read it later or just book mark it. And so the realm of intents gets created and we come full circle with the web - the idea that there is an interconnection of information and services that are all interrelated and can interact with each other. To me this starts looking like the real semantic web - no top down taxonomies, no RDF, no microformats and no standards bodies arguing for 5 years on the best way to construct a ""share protocol"". This is classic survival of the fittest. The same way links between sites and web apps themselves work - a democratic, user oriented, grass roots approach to self-organisation of services. Within the Android community, certain ""intent patterns"" quickly emerged - sharing, video watching and photo manipulation being the most common. No one architected how these worked, <b>no governing body decreed that to share a URL ""one must call this method""</b>. The beauty of this is that as an app developer I can choose which intents I'm going to ""service"" as well as which ones I'm going to ""call"". ""But how are you going to keep track of all these intents?"" I hear the cry going. It doesn't matter, you'll learn pretty quickly what's important and we'll coalesce around the main ones pretty quickly (by virtue of them being smart, logical and useful - like web sites and apps themselves). What will make this beautiful for the end user is if the application calls for an intent that isn't installed and it goes off and searches the web for intents that match - giving the user the opportunity to install one. We're a little way off this nirvana in my view, but not as far as you'd think. With the clearing of some of the old browsers we're pretty much on an ever more rapid upgrade path that will see more users with this technology in their hands more quickly. It will only take some early adopters on the web publishing side to start using it to gain traction very quickly. Imagine a day in 2013 when you can view a blog post or a news article and when you get to the bottom, instead of being assaulted by 20 share icons that look like a designer vomited on the page, you get one elegant button just saying ""Share this""...","['essay', 'internet', 'media', 'predictions', 'web']","['web', 'internet', 'media', 'essay', 'predictions']","[0.6521941467763492, 0.640511361367382, 0.6188122526167543, 0.5911200753015904, 0.5891491464833902]",[],[],[],[],True,5
2011-09-15-device-api-applications-of-devicemotion-and-deviceorientation.md,Device API - Applications of DeviceMotion & DeviceOrientation,"['android', 'arduino', 'development', 'hardware', 'internet', 'media', 'mobile', 'open source', 'python', 'web']","Device API - Applications of DeviceMotion & DeviceOrientation
I've always loved the fact that in every smartphone there are a range of sensors attached to it. At the moment this is limited to GPS (position on the earth), orientation (how the device is tilting) and direction (how is it moving / accelerating) but we'll get others such as temperature, light etc at some point too. While we've had access to these for some time at the native app level, exposing access to these sensors has been slow to filter through to the web browser. We've had GPS for a while using the GeoLocation API which is great but it's a little too macro for playing with. ![A large gyroscope photographed while spinning](../../img/posts/gyro.jpg)
*[Gyroscope et rotations - image (cc) by Mathieu Marquer](http://www.flickr.com/photos/slasher-fun/3039970101/)* With the iPhone 4 and Gingerbread Android devices we're starting to see this data become available. Mobile Chrome is lagging but Mobile Safari, Firefox for Android and Opera Mobile in developer mode are all providing access to the gyroscope and accelerometer data even though [the spec is still in draft mode](http://dev.w3.org/geo/api/spec-source-orientation.html). (Note: Having just got a Honeycomb tablet today, it appears mobile chrome for Android now supports these features so we should see it available in handsets from Ice Cream Sandwich) If you want to see what sort of data you can get access to take a [look at the demo here](http://ajfisher.me/code/deviceapi-normaliser/examples/data.html) if you have one of the browsers above. _Why would you even want this - a web browser is for browsing the web isn't it?_ It is, but increasingly it's a tool for interaction as well. I started exploring this space not so much for the applications that you could create within the browser (eg games) but more out of interest in how you could use the web browser to facillitate interaction with the physical world. I work with a lot of clients who use apps to create engagement and I know there's a lot of download / install drop off. Even <b>as a hardened mobile user, accustomed to installing many apps a day, I get frustrated if I have to install something just to interact with a billboard</b> or in store display (especially if it isn't multi-platform). If I'm standing in your store or in front of a piece of your media why are you asking me to download something? With that in mind, I feel mobile web can come to the rescue. Why not use the web browser as a means of controlling a web app remotely. Could the web browser become a game controller in its own right, for you to be able to interact with media and with other people? Have a look at the presentation I gave on this at [Web Directions South, What do you know Melbourne in August](http://whatdoyouknow.webdirections.org/) this year. There's slideshare and youtube available. The YouTube screencast in particular shows how quickly people could jump on and start playing and interacting with a system that was literally only up for 90 seconds. Watching the smiles as people played this from where I was standing on the stage was gold. Tank tag demo starts at 4:30. How does it work? Tank Tag is actually pretty simple. Using the device API events, DeviceMotion and DeviceOrientation, I'm pulling the sensor data from the phone and streaming it to a server over [web sockets](http://en.wikipedia.org/wiki/WebSocket). The web server manages all the data and then provides it back to another browser (again using web sockets) that simply provides the view into the game using canvas (and actually handles all the game play). I'm using [Django Socket IO](https://github.com/stephenmcd/django-socketio) for the server but any [Socket IO](http://socket.io/) based server would work and you could do this just as readily using node.js for example. At the moment this is a proof of concept and a bit rough around the edges and the big caveat is that because the sensors generate so much data (literally as fast as the phone can produce it) that you have to limit the web socket stream. For my demo I ran this using a portable wifi hotspot and at an event / media location you could do the same thing. Trying it out over 3G was very laggy though some optimisation may help there but 3G isn't really designed for realtime data streaming hundreds of times per second. Applications As described above, and in my presentation there's plenty of applications within the browser itself. The [Is this an Earthquake site](http://isthisanearthquake.com/) is a cute application of the technology but is limited to one user. I've seen a few labyrinth and bouncing ball demos as well but they are all limited to the individual's context. The big areas I see as opportunities for this technology are media interaction (individual or multiplayer) and physical interaction. Media Interaction As can be seen by the tank tag demo, using just a web stack it was possible to gain a large amount of multi-user interaction very quickly through a simple interface with an intuitive control method using the device as a controller. The opportunity for transforming media spaces (eg museums / installations) is huge - all that's needed is a small server (A mac Mini would be sufficient) a wifi access point and a display or projector a combination that would cost less than a thousand dollars + display. Advertising media spaces could utilise this technology too, say on train platforms where you have a lot of people standing around for up to 10-15 minutes not doing anything (and largely having their phones out already). <b>What better way to drive brand engagement that providing a bit of fun or distraction?</b> Physical Interaction This was actually my first thought in this space as for WDYK Melbourne I was planning on having a mobile phone controlled puppet on stage people could interact with. The idea was a bit cumbersome to work with in the 5 minute format but the technology works. An early stage example of this can be seen in the photos below where I'm using the web browser orientation values across each of the three axes to [control the RGB channels on an LED](http://maker.ajfisher.me/2011/09/rgb-led-controlled-by-mobile-phone-browser/) thus creating an interactive light sculpture that merely requires a web browser and some motion to interact with. Besides being a Django / Python guy, this was the main reason I chose Django Socket IO as the server - being in Python gave me access to USB devices so I could control the light (or servos) using the incoming data. I couldn't do this easily (if at all) with Node. Where to from here? I'd love to see what people can do with this. I've [released a library](https://github.com/ajfisher/deviceapi-normaliser) that is in early stages of cleaning up some of the differences between implementations of the DeviceOrientation and DeviceMotion events and the data they produce. Feel free to use, play with, test and fork that. If you're interested in Tank Tag and the arduino interaction stuff then that's[ available as a repo on github](https://github.com/ajfisher/django-arduino-socketio). It's a little rough at the moment but will be cleaned up over the next week as I stabilise it a bit more.","['android', 'arduino', 'development', 'hardware', 'internet', 'media', 'mobile', 'open source', 'python', 'web']","['web', 'mobile', 'development', 'internet', 'media']","[0.6650185183423354, 0.6500761189993703, 0.6492588946543397, 0.636903655591012, 0.6126553307764405]",[],[],[],[],True,10
2011-10-04-on-a-post-flash-world-and-adobes-place-within-it.md,On a post-flash world and Adobe's place within it,"['adobe', 'business', 'media', 'mobile', 'predictions', 'web']","On a post-flash world and Adobe's place within it
A [while back I criticised Adobe's lack of web oriented strategy](http://ajfisher.me/2010/04/13/adobe-narayens-kingdom-for-a-plan/) and in particular it's bloody minded resistance to dropping flash. This was written during Adobe's public spat with Apple as a result of iOS not supporting Flash and with no intent to do so. As we've seen over the last 12 months, mobile devices are beginning to shape the web. At some point in the not very distant future mobile devices will be the dominant platform for the web - not high end desktop machines packing a lot of memory and quad core processors. As an android user who has flash available on both phone and tablet I concur with Mr Jobs, Flash on mobile devices is a terrible experience. Flash kills battery life and it causes a significant number of crashes. Even on the desktop Flash is responsible for just about every browser crash I experience on a daily basis. Poorly executed flash ads built by junior designer / developers with no review seem to be the worst culprit. It has been widely speculated that once Flash penetration drops below about 90-95% it will be untenable to continue supporting it within the development community and we are fast approaching that number. Many flash developers I know are looking at cross skilling. Quietly I've noticed the trend of brainstorms and solution sessions being less about ""can we do this in the browser using HTML and Javascript?"" and more about how far can the HTML 5 and related technologies be pushed. Websockets & JSON are the tools of the real-time; canvas is increasingly the tool of animation and give WebGL another 12-18 months to get some penetration and we'll have 3D in the browser as well. No need for that crashy plugin any more. Today Adobe have announced to the world not just that they've acquired [Nitobi](http://www.nitobi.com/) and [Typekit](http://typekit.com/) but that they are also considering a future devoid of flash or at least one where it is no longer relevant to the mainstay of their product line. These acquisitions highlight the future of the web that Adobe is betting on, in much the same way they bet on the Web a decade ago by purchasing Macromedia. Nitobi's experience with phonegap brings some serious mobile credentials into the business, especially where the native blurs with the web in a cross-platform manner. Phonegap didn't win the Mobile Web vs Native App war but it won some significant battles and showed manufacturers and developers alike that the web platform was the most viable for cross platform development in most cases - even on the native side. Adobe's purchase of Nitobi should translate into tooling that will help designers and developers build higher quality mobile web and native apps and provide a good, solid revenue stream - it might finally reinvigorate the aging Dreamweaver product line too. Typekit's purchase is slightly different and marks Adobe's understanding that the web, and in particular HTML and CSS, is the future of digital design. Typekit have done an amazing job in a small space of time, again almost single-handedly proving to the web community that we can have amazing typography online - at a time when web typography had been in the doldrums for nearly a decade. Given Adobe's heritage in this space, this is a wise decision. On the surface this may not look like a huge revenue opportunity however I wouldn't put it past Adobe to wrap typekit up in some tooling down the line as well as making a play at the agency end of town for one stop font management across domains. There's some opportunity here I think Typekit have touched on but not had the resources to bring to bear. Adobe already has a lot of the design agency relationships and that's a lot of potential revenue opportunities. Also consider that even a $15 a year subscription from 10 million bloggers is a tidy revenue stream. These acquisitions are a great thing for Adobe. The purchases of Macromedia and Ominture have gone less well than anticipated as behomouth pieces of software were digested by the business. These smaller, more nimble, web oriented businesses will inject some creativity back into Adobe and hopefully some of their culture will rub off on the software giant. ![Adobe logo on the floor](../../img/posts/adobe.jpg)
*[Image: (cc) Marcin Wichary](http://www.flickr.com/photos/mwichary/2198354027/)* A lot of people will lament the swallowing up of two extremely savvy web organisations that have shaped a big chunk of the digital landscape over the last 2 years. Maybe, but I'm quite excited by the potential this brings. With Adobe's resources focussed in these areas, there's a lot more to come from both Nitobi and Typekit and that will only bring benefits to the web - like flash did over a decade ago to bring interaction to the web but whose time is now past.","['adobe', 'business', 'media', 'mobile', 'predictions', 'web']","['web', 'mobile', 'media', 'business', 'predictions']","[0.6509782737100321, 0.6458200629775019, 0.6375869251170002, 0.6145237183925542, 0.5899457415525327]",[],[],[],[],True,6
2011-10-17-neo-futurism-in-the-information-age.md,Neo-Futurism in the Information Age,"['conference', 'development', 'internet', 'media', 'mobile', 'web']","Neo-Futurism in the Information Age
Post-WWII. After the dust had settled and old maps had been redrawn, we entered a period of utopian future-gazing. This period, predominately lasting through the 1950s and mostly found in the American and Soviet superpowers of the time, was characterised by our view that as humans we would triumph over any adversity. We held the view that all of nature was our to command - for we had just mastered the atom, the jet age had begun and we were on the cusp of sending humans into space. The dream of protein pills and personal jetpacks didn't eventuate, however the thinking ushered in a new period that would last for another couple of decades - a period where considering big, idealistic futures was considered the norm and that one should get out and try and make them happen. For me, [Web Directions South 11](http://south11.webdirections.org) held much of the same passion and fervour. Finally, at least in Australia it seems, the shadow of the GFC is lifting and <b>we are at the dawn of a period where a third of all humans are connected and we are starting to see the future that mastering the connected bit can achieve</b>. Whereas in 2010 it was about the potential technologies like HTML5 and mobile technologies would bring us, in 2011 it is about our application of these technologies into new ways of working, new styles of design and the creation of a future for everyone. Much of the conference theme was about just getting out and doing stuff, providing echoes of the 1950s sentiment that we live in a time where it is the makers' world, that we are architects of the future and our place within it. Indeed, WDS11 showcased a future where the web transcends the boundaries of mere browsers, where it is now the platform for our mobile worlds but increasingly our physical ones as well. As designers the call was put out that we will be designing physical objects, as developers that we will be creating means for greater utility of the web in these future environs. Web Directions this year was a showcase in diversity in thinking and technology, like an atomic age World Fair. We had sessions on [Augmented Reality](http://www.slideshare.net/robman/web-standards-based-augmented-reality) merged with the [Web of Animals ](http://www.slideshare.net/annegalloway/a-21st-century-bestiary-9723431)merging with[ classical architectural design applied to the web](http://south11.webdirections.org/program/big-picture#interaction-design-bauhaus) merged with [Physical](http://south11.webdirections.org/program/big-picture#using-the-world-as-a-canvas) and [Ubiquitous (PDF)](http://www.orangecone.com/webdirections_2011_presentation_0.1.pdf) [computing](http://www.slideshare.net/andrewjfisher/how-the-web-is-going-physical). We had visions of our future mixed with an [appraisal of our current state of being](http://south11.webdirections.org/program/big-picture#the-dao-of-web-design-revisited). <b>Alongside the whimsical we had the [practical](http://www.distractable.net/media/talks/html5-api-soup/index.html) too</b>, conveying the knowledge of our craft that will raise the bar yet again next year to greater levels. And we had [calls to arms in the style of presidential challenges past](http://south11.webdirections.org/program/big-picture#how-to-be-a-web-sorcerer). A few weeks ago [I read a piece](http://www.worldpolicy.org/journal/fall2011/innovation-starvation) by [Neal Stephenson](http://twitter.com/#!/nealstephenson) on how Science Fiction writers had lost their talent for dreaming big ideas and articulating futures that would inspire scientists and others to attempt to fulfil them - a sentiment I totally agreed with. What I've since realised is that scratch the surface of the web community and there are big ideas being dreamed. Whether it's a future where all [data is interlinked seamlessly](http://south11.webdirections.org/program/big-picture#culture-citizens-digital-heritage) so we can [create better stories about our past](http://www.slideshare.net/davidseth/bringing-history-alive-telling-stories-with-linked-data-and-open-source-tools) or one where we begin to [interact with render-ghosts](http://south11.webdirections.org/program/keynotes#the-robot-readable-world), those half real avatars of the robot world through the medium of the web there are futures being envisioned and articulated - and they are being made real. Many people I talked to - both presenters and delegates kept saying over and over that this Web Directions was making them think bigger, that it wasn't all just about skill transferral, that they were inspired to do more. I think we exist now at a point of change, where the web has hit some unintended critical mass. <b>The web is now permeating the fabric of humanity on a nearly global scale</b> and Web Directions managed to tap into the web's subconscious - highlighting the patterns that will develop over the next couple of years and take shape around the mainstream. Regardless of whether I get my personal jetpack or not, this neo-futurism wave that seems to have swept the web community (and the maker community more generally) will at least help shake off the shadows of a post-GFC world, and sometimes a bit of unbridled futurist optimism can't be a bad thing.","['conference', 'development', 'internet', 'media', 'mobile', 'web']","['web', 'mobile', 'media', 'development', 'internet']","[0.6541203324962367, 0.6412557498392457, 0.6335840935505275, 0.6274298815487394, 0.6220820814156569]",[],[],[],[],True,6
2011-11-03-we-are-the-champions-of-the-web.md,We are the champions... of the web,"['conference', 'internet', 'media', 'mobile', 'standards', 'web']","We are the champions... of the web
Recently, at [Web Directions](http://south11.webdirections.org) this year [John Allsopp](http://twitter.com/johnallsopp) revisted a classic piece of web writing, ""[A Dao of web design](http://www.alistapart.com/articles/dao/)"", 11 years since writing it. The presentation stood out as a passionate defence of the things that made the web great including it's universality and openess. One point he made was a rebuttal to a comment that the ""problem"" with the web was one of control. This was becoming the defence for why the mobile app model was the future but it's been raised before - that the failings of the web were its lack of control, its slow speed of evolution and its difficulty. _Full disclosure: I'm a web guy. I come down on this argument the same way as John. The web has been 95% of my career thus far, has allowed me to travel the world, speak, write and have a stack of ""firsts"" that I am very proud of working on. _ Having seen the news that Internet Explorer has [dropped below 50% browser share](http://arstechnica.com/microsoft/news/2011/11/the-end-of-an-era-internet-explorer-drops-below-50-percent-of-web-usage.ars) for the first time in over a decade I am insanely happy because it proves the point. The web doesn't need curators or controllers, it needs champions. Internet explorer - and specifically IE6 has been the dominant controller of the web for nearly a decade. We've had control - and we reaped it's benefits - stable (though quirky) APIs and Web Standards implementations. For all it's ills IE6 gave us okay CSS, good Javascript and a DOM that was largely workable and we really had only one platform to consider for a long time. But we don't need control, we need champions. Mozilla and Web Kit and Opera were our champions; but so too was the entire web community. By galvanising around web standards we made the case that control wasn't sufficient for innovation or even good implementation. ![An illuminated fist punching through a circular light](../../img/posts/champion_fist.jpg) As the desktop browser champions matured, those of us in the community endorsed the browsers as being ""mainstream friendly enough"" so we installed firefox or chrome on every machine we could possibly ""infect"" with a decent, modern, secure browser. That's assuming we didn't just tell the person in question to go buy a Mac (so we could minimise the family and friends tech support calls). So momentum built... When Nokia originally chose Opera and Mozilla as the core of their mobile web browser and Apple and Android chose webkit they endorsed the open mobile web - with all the consistency issues and difficulty that meant - yet the web browser is still the most used ""app"" on a mobile phone (outside of the phone and sms functions) and is the fuel of most of the web's current growth. So momentum built... When the big web properties said ""no more IE6"" and meant it, license was given to every web developer and designer on the planet to say to their clients they weren't going to support it any more - because just about every client uses at least one of Facebook, Twitter or Google at some point. So momentum built... Now Microsoft - who famously ""embraced and extended"" the web and produced IE5 & 6, can't even keep up with the innovation occurring due to the multitude of champions simply pushing the web further, day by day and month by month. With IE10 they will have just about caught up to the bar that has been set by Mozilla and Web Kit - after a decade of almost no innovation - controlling the web by fiat. And so the champions have prevailed - in an unruly, largely disorganised, bickering, chattering, tweeting mass - but still they have prevailed. In the same way that science, when exposed to the transparency of the scientific method consistently brings new discoveries and innovation. The position we have attained over the last 18 months and have hit now with this milestone is really a restarting of the process begun in the 90s. <b>Again we see rampant innovation throughout the web</b> - which has been languishing for a long period of time. This is why developers and designers are excited about their craft again after years of just about going nowhere. But the new front in this war is the Mobile App - with its fallacy of control - and it should hopefully be merely a speedbump in our history, like the ubiquitous onmouseover=""rollover()"" of 2000. The web doesn't need curators nor control; all it needs are champions who are prepared to make a statement, choose a path, have their views supported or revised and continue to evolve this amazing platform.","['conference', 'internet', 'media', 'mobile', 'standards', 'web']","['web', 'mobile', 'media', 'internet', 'conference']","[0.6538762690340428, 0.6458191542612671, 0.6312786321964268, 0.6252824228701414, 0.5867014247138457]",[],[],[],[],True,6
2011-11-07-app-stores-are-delivery-channels-not-search-engines.md,App stores are delivery channels not search engines,"['android', 'apple', 'google', 'internet', 'ios', 'mobile', 'os', 'web']","App stores are delivery channels not search engines
I saw the tweet above from [Tim O'Reilly](http://twitter.com/#!/timoreilly/) the other evening, and duly read [the post attached](http://www.xconomy.com/national/2011/11/04/mobile-app-search-is-so-bad-altavista-could-have-done-it-chomp-is-biting-off-the-problem/?single_page=true). The premise is that search in the Android Market and in iTunes is fundamentally broken - so badly busted in fact that [AltaVista](http://www.altavista.com/) could have produced a better search engine. Enter into the mix, [Chomp](http://chomp.com/) who profess to solve the app search problems by doing things like indexing comments about the app, links to it from blog posts etc in order to give it a more ""google-style"" ranking. Whilst I technically applaud what Chomp have managed to do, they have almost no revenue to speak of and a dismally small audience for such a service. My sense is that the reality of app store search is that almost no one actually uses it to search for apps in a general sense - they use it for recognised brand terms or keywords which lead them, without fail, to exactly the application the user is after. ![Google Android plushie doll attempting to eat a MacBook computer](../../img/posts/chomp.jpg)
*[""Androids
eat apples"" - image (cc) ryanne lai](http://www.flickr.com/photos/laihiu/4407979507)* No one I know (and I talk to a LOT of people about mobile device usage) have ever said to me that they couldn't find the app they were looking for. When was the last time someone you know lamented the fact they couldn't discover an app based on broad criteria? I'm tipping never. If you're a mobile maven or a serious app hipster then yes search is broken for this context (yes, I fall into this camp too). For the other 200 million (and rising) users around the world they actually don't care about the latest, most niche app in the market all they care about is that they can find the specific app they are after. And how do they find what app they are after? Marketing. Pure, simple, traditional, marketing. The app store is not the web and because it's not the web it doesn't get the web's benefits (relatively easy to search, standards based, hyperlinked content). <b>Apps are actually a lot like, wait for it, applications</b> - and if you've ever had anything to do with real application development then you'll know there are huge marketing teams (the same size or bigger than the dev teams) who exist purely to market the bejusus out of the product that's been created. When you play this game it's all about awareness and conversion - typical  marketing activities and those that are doing really well in the app stores understand this model very well. The application is promoted as a product, it's highlighted on the website, there are emails sent out raising awareness with a download link and it's promoted on TV and all the other channels one advertises products. Let's face it, no one goes to iTunes and searches for ""app to see what my friends and family are up to"" - they type in Facebook. Similarly no one searches for ""restaurant review guides"" - they type in Yelp, or Urbanspoon or whatever other brand they related to out on the web. And I can almost guarantee you that no one has ever searched for ""kill pigs with irate avian projectiles using a catapult game"". ![Angry Birds sculptures from plastecine](../../img/posts/angry_birds.jpg)
*[""Angry
Birds Live"" - image cc Yaniv Golan](http://www.flickr.com/photos/yghelloworld/4966726746/)* Apps, like any other product are also subject to referral. People write about them - how many blog posts are entitled ""[The 10 best [CATEGORY] apps for [PLATFORM] ever](http://www.google.com.au/search?hl=en&safe=off&q=The+10+best+*+apps+for+*+ever&oq=The+10+best+*+apps+for+*+ever&aq=f&aqi=&aql=1&gs_sm=e&gs_upl=1186469l1195562l0l1196345l31l28l1l2l0l1l412l4534l2-11.4.1l16l0)""? If you like something you tell someone about it and if you really like something you install it for them on their device. I'm not sure either of my parents have ever even seen an app store but they have plenty of applications installed on their phones and tablets courtesy of us kids. One of the most telling aspects of the recent Android 4.0 launch was that they demoed in passing how using NFC you can share any arbitrary piecs of content by touching phones together. Applications was one of the demos of this and clearly the Android team has seen some data to indicate that personal referral is a major way that apps are shared. Which leads me back to the start - that apparently search is broken in the app store. Mobile devices are one of the most highly monetised and increasingly optimised sales channels currently in operation. Every search, application view, download and uninstall can be measured by person, by location and probably a heap of demographic inference by virtue of the rest of your account with Apple and Google. In my view it is inconceivable that if there were even a reasonable number of searches occurring within the app stores that didn't convert into a download that search wouldn't be fixed. This is Google's core business - <b>they have the means to fix it - if something was broken</b>. And you can be sure Apple would either buy or build something that worked as well. If even 1% of searches were resulting in a lack of discovery, that would translate to potentially hundreds of thousands of dollars, if not millions over time. That's revenue that would be just left on the floor. Revenue like that tends to get picked up by data-centric businesses pretty quickly. The other factor in all of this is that over the last 15 years we have been trained to believe that the web has the answers. Google is always there in a web browser, only a few seconds away, regardless of mobile device or desktop. A couple of little app stores that we only use once every couple of weeks isn't going to become our first point of reference compared to the entity that answers our questions multiple times a day, every day. ![Search results prompts for 'best apps' on google](../../img/posts/google_apps.png)
*Search prompts for ""best apps""* Ultimately there's nothing new about this at all - how do I choose what bit of video editing software to install on my Ubuntu laptop? I go to the web, I read reviews then I download and install the ones I want to check out; eventually selecting one that meets my needs. Synaptic doesn't do this for me and it's one of the best (and longest lived) app stores in existence. So I don't believe that the app store search is broken and I think there is definitely a place for more editorially driven referral. Looking at what nvidia is doing with the Tegra Zone on android is a good indicator of how this could work (magazine content to promote android games designed for the tegra graphics chip). Ultimately I'm not convinced that apps are our long term future on mobile any more than they were on the desktop and we will start to see a rationalisation whereby the best survive and the others just fade away into nothing or at least transition into web apps, just like a lot of desktop software did over the last 10 years. At the end of this process though we'll end up with smaller app stores, more editorially controlled, with higher quality, more relevant applications and at that point this whole search debate is meaningless. <b>When was the last time you required search to find some ""office productivity software""</b> in Dick Smith or Best Buy or PC World? While you ponder that I'm off to use an app that ""displays short, character limited messages from people all around the world"" on my phone.","['android', 'apple', 'google', 'internet', 'ios', 'mobile', 'os', 'web']","['mobile', 'web', 'internet', 'android', 'google']","[0.6424143298018029, 0.6391804082065429, 0.6262398880824057, 0.6046812244350868, 0.6025549291587947]",[],[],[],[],True,8
2011-12-20-towards-a-sensor-commons.md,Towards a sensor commons,"['essay', 'internet', 'iot', 'open source', 'physical computing', 'ubicomp']","Towards a sensor commons
The [Internet of Things,](http://en.wikipedia.org/wiki/Internet_of_Things) a term being bandied to the point of almost meaninglessness now it's hit the mainstream of the [NYT](http://www.nytimes.com/2011/12/18/sunday-review/the-internet-gets-physical.html?_r=1&pagewanted=all) and the [BBC.](http://www.bbc.co.uk/news/business-13632206) Yet, while the mainstay of the media struggles to describe how and why smart sensor arrays are going to mean you spend less time in traffic, ultimately pay more for your electricity but make sure your fruit is always fresh, there is a quiet revolution taking place. ![Different types of electronic resistors](../../img/posts/resistors.jpg)
*[""Resistors"" -image (cc) Windell Oskay](http://www.flickr.com/photos/oskay/437342078)* The action taking place is the creation of what I call the Sensor Commons. Why is this a revolution? Because as a population we are deciding that governments and civic planners no longer have the ability to provide meaningful information at a local level. Two posts summarise this activity and its implications beautifully for me. The first, by [Ed Bordern](http://twitter.com/#!/edborden) from [Pachube](http://pachube.com), is on the creation of a [community driven Air Quality Sensor Network](http://blog.pachube.com/2011/12/you-can-help-build-open-air-quality.html). His passionate call to arms highlights that we have no realtime system for measuring air quality. Further, what data does exist and has been released by governments is transient due to the sampling method (ie that the sensor is moved from location to location over time). Summarising a workshop on the topic, he discusses how a community oriented sensor network can be created, funded and deployed. The implications of this quiet revolution are discussed by [Jauvan Moradi](http://twitter.com/#!/javaun) in his post on [how open sensor networks will affect journalism](http://javaunmoradi.com/blog/2011/12/16/what-do-open-sensor-networks-mean-for-journalism/). Jauvan discusses how citizen data will re-establish the localised roots of journalism by reporting on issues that matter locally and with accurate, real time data to help drive the story. Obviously Jauvan has an interest in media so he's taking that slant yet this is but one of the many implications of the Sensor Commons. We don't know what we're going to get when we arrive at a point where there is hyperlocalised data available on any conceivable measure - sound levels, temperature, rain levels, water quality, air quality, the number of cars passing a location in real time. The needs are going to be driven purely by local communities - by bottom-up interest groups that have access to cheap technologies to enable the sensor creation as well as a local need or concern that drives action. I gave a talk at [Web Directions](http://www.webdirections.org) in October this year on the [Web of Things](http://www.slideshare.net/andrewjfisher/how-the-web-is-going-physical). The last third touched on the notion of community created and led data - citing the nascent [Don't Flush Me project in New York](http://dontflush.me/) and the spontaneous self-organisation of radiation data in the wake of the Fukushima Disaster. ![Grafitti on a wall suggesting a radiation leak](../../img/posts/radiation.jpg)
*[image cc Julian Stallabrass](http://www.flickr.com/photos/slowkodachrome/11817407183/)* Through observation of many of these projects, as they mature one of the issues I have is that many of these endeavours require deeply technical knowledge in order to be effective. For the true Sensor Commons, as I see it, we need to have deep engagement with the population as a whole, regardless of technical ability or knowledge. What is the Sensor Commons? Before I get into the fundamental requirements of a Sensor Commons project it's worth defining what I mean by the term. For me the Sensor Commons is a future state whereby we have data available to us, in real time, from a multitude of sensors that are relatively similar in design and method of data acquisition and that data is freely available whether as a data set or by API to use in whatever fashion they like. My definition is not just about ""lots of data from lots of sensors"" - there is a subtlety to it implied by the ""relatively similar in design and method of data acquisition"" statement. In order to be useful, we need to ensure we can compare data relatively faithfully across multiple sensors. This doesn't need to be perfect, nor do they all need to be calibrated together, we simply need to ensure that they are ""more or less"" recording the same thing with similar levels of precision and consistency. Ultimately <b>in a lot of instances we care more about trended data rather than individual points</b> so this isn't a big problem so long as an individual sensor is relatively consistent and there isn't ridiculous variation between sensors if they were put in the same conditions. In my definition of the Sensor Commons, geography doesn't matter. You can be as hyper localised as measuring the sewage level of a borough - as in the case of Don't Flush Me - or measuring radiation on a global scale. The scale upon which you operate is dictated by the type of thing you're measuring. For example measuring water quality in two unlinked water courses makes almost no sense, in two different oceans it makes even less with regards to comparability. The 5 requirements of the Sensor Commons. We're at a very early stage of the Sensor Commons and attempting to define it may be foolish, however by observing many different types of projects around the world I believe there are five critical requirements for getting a Sensor Commons project off the ground and making it a viable endeavour. A Sensor Commons project must: Gain trust Become dispersible Be highly visible Be entirely open Be upgradeable Each of these will be dealt with in the sections below. A project that has these characteristics will generate a momentum that will exist beyond a core group of technical evangelists and will find a home within the mainstream community. Gaining trust Many sensor commons projects shine the light on our human behaviour. Ostensibly the goals are noble - to try and understand our environs such that we can make them better and change our behaviour - yet we must stay on the side of data and fact and not move towards blame; others can carry that torch. For example the project that seeks to close down the local smoke stack due to its impact on air quality will have a hard time fostering trust due to their agenda. We all want to have clean air but my kids go to school with the kids whose parents work in said smoke stack - how will I look at them when they lose their jobs? In the section on dispersal I'll talk about using existing community assets and infrastructure and trust plays a part in this. If you are piggy-backing the local library's WiFi so you can get a network connection down in your stream bed <b>it is imperative you don't abuse their network by sending or requesting too much data</b> - or harvest anything you shouldn't do. Trust is provided by having stated project objectives, clear policies around what data you're going to capture, where it will go and how it will be used and available. Someone responsible for dealing with these issues and being the ""go to person"" for any issues or questions that arise will provide credibility as well as probably opening up some opportunities for partnership as well. Note how trust requires no technology, merely an understanding of it. This is a perfect role to engage non-technical team members in, especially those who can articulate why the project is important to the community. As an example the Don't Flush Me team have done an excellent job of this, they have built trust with the authorities who are granting them access to the sewerage system - there's no blame being cast, they are simply trying another way to help a community known problem. Similarly they are building trust with the community by creating a valuable resource for people who care about their local environment. Become dispersible One of the biggest issues facing Sensor Commons projects is that of dispersion. Projects that seem like such a good idea fall at the hurdle of widespread adoption. Understanding how you can disperse your sensors properly means that like a dandelion seed on the wind you'll find plenty of places to put down and ensure success. ![Dandelions illuminated by a low sun](../../img/posts/commons_grass.jpg)
*[Image(cc) sciencesque](http://www.flickr.com/photos/apoptotic/2597478489/)* There are many factors that contribute to this which are discussed below: Price This is pretty obvious but can go overlooked. What is the total cost of the sensor? Don't forget that as well as the material cost of components you need to factor in someones time to build the sensor (especially if it's short run and will be hand built by the project team). You also need to factor in ongoing cost - for example if you have a remote sensor that uses the 3G network you'll need a data plan that is paid for month by month. Similarly if it breaks down can it be fixed (if so for how much) or is it a straight replacement? Price is a big factor in dispersal. Taking Dont Flush Me as an example, the cost of the sensor and the data plan make the project unwieldy without donations. While I'm sure this will work in the end, this isn't the path towards quick dispersal. Contrast this with say the radiation data gathered by individuals globally - while the sensors themselves were relatively expensive, the network cost was negligible and thus led to higher uptake. Tapping into local assets If you can gain trust with the community then you get the opportunity to try and use community assets to help with dispersal. If you can use things like WiFi on your project why not talk people locally and see if they would be willing to ""host"" one of your sensors on their network so long as you don't do anything silly. I used to belong to a kitesurfing group in the UK and we wanted to get a networked wind meter at our local beach so we could see if it was windy enough to go kitesurfing. As we all drank in the local pub on the beach anyway, the owner allowed us to mount a weather station on his roof and use his Internet connection so we could publish the data so we could all see it. Do you have a local library that is on a main road? Might make a good location for an air quality sensor that uses their WiFi to stream the data back up. Libraries, schools, local council buildings are all community infrastructure - it's worth a conversation to see if you can use it for your project. ![Image of the Giesel Library](../../img/posts/geisel_library.jpg)
*[""The Geisel Library"" - image (cc) O Palsson](http://www.flickr.com/photos/opalsson/13535412304/)* In Melbourne you can walk along some of the suburban creeks that run into our bay and never be out of range of a WiFi connection for its entire length. Surely some of the people who live along that river would have an interest in the quality of the water and would share their WiFi with you? If you're a local organisation you probably know some of them or know someone that knows some of them already. Utilising local assets can dramatically drop the cost of a project, meaning more units, greater dispersal and better community engagement too. Units should be self contained The sensors themselves should be as simple and self contained as feasibly possible. Utilising batteries or solar power makes sense and if you can use WiFi then it's even better. WiFi modules for things like Arduino use are becoming pretty cheap now so won't blow your budget too much. It's still cheaper to run cable if you can however this is another barrier to dispersal. It's one thing to ask someone if you can put the sensor in the creek next to their house and send the data through their WiFi, it's another entirely to ask them to route a cable across their yard, in a window and across a room to plug it into their router. Don't underestimate the cable factor - I've had my wonderful and generally relaxed wife draw a line at visible cables taped to the decking so I could get data from the back yard into the house. What level of technical knowledge is required to deploy? To gain higher levels of dispersal, drop the technical knowledge required to deploy. There's a reason why Linksys and Netgear own the home router market - because anyone with some very basic instructions could deploy a box and get their home Internet up and running reliably. If you have a difficult package to deploy it means your technical members of your project will need to do it. This may not be a problem if you're doing small scale projects but if you have say hundreds of nodes this becomes an issue. An API makes your data dispersible too Once you have your data wrap it in an API so it becomes dispersible too. This doesn't need to be a grand piece of software engineering, either let me have all of it and document what you've got or else provide me a method of querying your data over a period (from X to Y) for the entire node array or individual nodes in the array. Make it lightweight and expressive, such as JSON and you'll provide a data set that can be readily used, integrated into other systems or mashed up with other data sources easily. Adopt permissive licensing Permissive licensing for your hardware, software and data allows it to be used and improved upon by others. You probably haven't considered all of the uses people will come up with for your project so let others help you. Be highly visible There are two aspects of visibility that should be considered; first the visibility of the device itself and second, the visibility of the data created. With respect to the sensor itself if it is in a public place then you should endeavour to make it visible and also provide information about what it is there for. Occasionally you're going to get vandals trash your stuff - there's not much you can do about it. However if you take the opportunity to explain what it is and what the project is about then <b>it becomes harder for someone to vandalise a community project than something put there ""by the man"".</b> Once you have the data then look for ways not just to make it public but also ways to make it visible. The [Neighbourhood Scoreboards project](http://neighbourhoodscoreboards.com/) by [Martin Tomisch](http://twitter.com/#!/martintom) and team from the [Sydney University Design Lab](http://sydney.edu.au/architecture/research/research_deslab.shtml) showed how visibility of data at a community level could affect behaviour. Imagine engaging with a local council that has a display on the side of their building showing what the overall air quality score was in real time for the borough? These sorts of Civic Displays could become quite common place as different projects feed data into them. There's probably an opportunity for civic art to incorporate data from these types of projects and display it in interesting ways to the local population. ![Terrace house with blackboard showing energy consumption and ranking](../../img/posts/neighbourhood_scoreboards.jpg)
*[Neighbourhoodscoreboards project](http://neighbourhoodscoreboards.com/)* By creating visibility of the data we can raise awareness or affect behaviour which is often the goal for many of these projects. Data should be visible online as well - not simply by making the data sets available but also highlighting some meaning as well. What I found most interesting about the self-assembly of the radiation data on pachube in the wake of the Fukushima incident was that it wasn't ""real"" until it was on a [google map](http://japan.failedrobot.com/). Prior to that point there were dozens of data streams but it was too hard to interpret the data. Making your data visible in this instance means making it approachable for people to gain understanding from it. Be entirely open Openness in this day and age is almost expected but it's worth pointing out that the projects that open source all of their code, schematics and data will do better than those that don't. The other part of openness however is about the wider project context. This type of openness is about the transparency of the project objectives and the findings, documenting any assumptions about your data such as it's likely error rate and whether you're doing any manipulation of the raw data to derive a metric. Government data sets and sensor networks are steadfastly closed but there is a lot of weight paid to them because they have an implied lack of error and high precision. Ostensibly this is because they are supposed to be ""well engineered"", rigorously tested and highly calibrated devices - why else would one sensor cost $50,000? With radiation data on pachube as an example, there was much made in April about how reliable it was given that it wasn't calibrated, the sensors were probably sitting on peoples' windows and that they were only consumer grade. <b>Precision was never the intent for those deploying the sensors however so the argument was moot</b> - ultimately the point was to assess trends. If my sensor has an accuracy level of ∓ 20%  then it's always going to be out - probably by a similar amount. However if it goes up consistently over time, even though it's out by 20% the trend is still going up - and I wouldn't have known about that unless I was using a more deployable sensor because the government one is probably 200km away. Having a culture of openness and transparency makes up for the error and lack of precision in the data. By ""showing your workings"" it opens up your data and method for critique and from there allows room for improvement. It also provides a method by which you can agree or disagree with the assumptions if you want to use the data and make an informed decision underpinning the data set. Be upgradeable The final requirement is to be upgradeable. One of the benefits of [Moore's Law](http://en.wikipedia.org/wiki/Moore's_law) is that not only do we get more computing power for the same price over time but that we get the same computing power for less dollars over time. Consider a humble arduino - something that is more powerful for about $40 than a multi-thousand dollar 286 PC back in the late 80s. Being able to upgrade your sensor network allows you to take advantage of all the developments happening in this space. Adequately modularising your components so they can be switched out (eg switching to WiFi from cabled Ethernet) as well as abstracting your code (not doing heavy processing on your sensor, offloading it to the acquirer then processing it) make upgrading easy over time. This means your project gets better over time rather than stagnating. The Sensor Commons Future Smart Cities are all well and good and [IBM](http://www.ibm.com/smarterplanet/au/en/), [Cisco](http://www.cisco.com/) and others are more than welcome to their ideas and products to make our urban infrastructure more clever - we need it more than ever now. For me this vision is narrow in that the top-down view made from a very tall tower provides an architecture that doesn't seem to solve problems at a local level. Humans, by our nature are highly localised beings - whilst we may have to travel long distances to work we only travel a few kilometres from where we live and work once we're there. As such we develop profound connections to our local environments - this is why we see ""friends of"" groups spring up for local parks, creeks or other reserves and why communities lobby so heavily for protection of these spaces. This type of technology enables us to interact with our environments differently. If you think this is all naive data-driven techno-utopia think again. Governments are starting to look at ways they can push their data into platforms like Pachube to make it accessible. Germany is in the process of doing this with its radiation data. Individuals and project groups are already using tools like Pachube, [Thingspeak](https://www.thingspeak.com/) and [Open Sense](http://open.sen.se/) to aggregate data from their local environment (eg:[ C02 levels](https://pachube.com/feeds?tag=co2)). It's becoming almost trivially easy to create the sensors and the web tools are there to hold the data and start the process of understanding it. The access we are getting to cheap, reliable, malleable technologies such as Arduino and Xbee coupled with ubiquitous networks whether WiFi or Cellular is creating an opportunity for us to be able to understand our local environments better. <b>Going are the days where we needed to petition councillors to do some water testing</b> in our creeks and waterways or measure the quality of the air that we are breathing. The deployment of these community oriented technologies will create the Sensor Commons; providing us with data that becomes available and accessible to anyone with an interest. Policy creation and stewardship will pass back to the local communities - as it should be - who will have the data to back up their decisions and create strong actions as a result. If you have a project that is creating a Sensor Commons I'd love to hear about it.","['essay', 'internet', 'iot', 'open source', 'physical computing', 'ubicomp']","['internet', 'iot', 'open source', 'essay', 'physical computing']","[0.6415244106515298, 0.6095702714614946, 0.6051552389718259, 0.5949529884343177, 0.5881571349549896]",[],[],[],[],True,6
2012-02-24-humanising-the-internet-of-things.md,Humanising the Internet of Things,"['arduino', 'internet', 'iot', 'media', 'mobile', 'open source', 'predictions', 'presentation']","Humanising the Internet of Things
This is a transcript of my speaker notes from a presentation given at the [Churchill Club](http://www.churchillclub.org.au/) in Melbourne on Thursday, 23 February 2012. The overall topic was a [technology briefing on IoT](http://www.churchillclub.org.au/index.php?option=com_jevents&task=icalrepeat.detail&evid=2655&Itemid=1&year=2012&month=02&day=23&title=the-internet-of-things) technologies and business opportunities and had other speakers talk on the specific technologies involved and the networking needs of these technologies. My view (presented below) was to take a less technical stance and present examples and opportunities to provoke thought on the topic. Due to the format that was used this wasn't the actual talk though it was used as the basis of my discussion points and my opening overview. Introduction Let me ask a question. How many of you here tonight have got primary school aged kids? Put your hands up. So right now, with just a box of [Lego Mindstorms](http://mindstorms.lego.com/en-us/Default.aspx) and a [couple of hacks](http://dexterindustries.com/manual/wifi/) - all readily findable on Google and YouTube - your average ten year old now has the ability to conceive, design, build and deploy an Internet Connected Thing in their bedroom. When I was ten Lego was mostly fire trucks and spaceships - with some Technic if you were really lucky. As a young teen getting into electronics I was almost always disappointed. The pay off given the amount of effort required was too low. So the lure of programming - with it's fast iteration and almost infinite malleability was too strong and thus it became my career. So if kids are capable of playing with this stuff in their living rooms then you can be sure there's applications we haven't thought of yet. Tonight I want to talk about the how the Internet of Things technologies are being used by humans not just by machines, like how the Sensor Commons is starting to drive social change, how our physical health and well being are being enhanced by technology and how web-facilitated products are redefining our interaction with physical objects and our sense of where the physical-digital boundary lies. Some Context First of all some context for what is happening and why the changes we're seeing are happening so quickly now. Over the last five years or so it would appear that the other half of [Moore's Law](http://en.wikipedia.org/wiki/Moore's_law) - the bit showing that any given processor will get exponentially cheaper over time has finally caught up with mine and many other people's teenage aspirations. The Internet of Things is being driven by both sides of the Moore's Law coin - on the one hand we have access to vast amounts of high performance computation available to us whether though PC or Cloud based architecture and on the other we finally have access to enough computing power to put inside physical devices at a price that is so cheap it is almost disposable. However high performance and inexpensive computation are not sufficient to drive the technological changes we're currently seeing. Along side this we need cheap, ubiquitous communications, and in many places around the world we now have this type of access in both WiFi and digital cellular networks. So what happens when you have cheap computational power in a physical object coupled with cheap and almost infinite processing power available via cloud services which are facilitated by ubiquitous networks both wired and wireless? What happens to the world when the price of physical computation and networking drop to the point where it can be given away for free in a McDonalds Happy Meal toy? Well, we're almost there now and I have some examples to share. The sensor commons Let's start with the most obvious Internet of Things use case - sensor networks and telemetry. But instead of how networks of sensors are creating smart homes, smart cities and everything in between I'm going to focus on how sensors coupled with the web are driving social changes through a mechanism I call the [Sensor Commons](http://ajfisher.me/2011/12/20/towards-a-sensor-commons/). Deriving from [Open Source](http://en.wikipedia.org/wiki/Open_source), [Creative Common](http://creativecommons.org/)s and [Open Data](http://en.wikipedia.org/wiki/Open_data) movements, the Sensor Commons are being built by grass roots organisations in order to solve the problems they are seeing in their communities. By sharing designs, code and the data they collect, they are providing a means for creating understanding at a local level that are not being achieved by centralised direction. At the heart of these projects are data aggregators and brokerages such as [Open Sense](http://open.sen.se/), [ThingSpeak](https://www.thingspeak.com/) and [Pachube](http://pachube.com) - who, via web based APIs are providing the ability to push and pull bits into the platform via whatever arrangement of atoms you would like to use. Whenever you hear about a tweeting pot plant, chances are it's using one of these systems to do it via their web APIs. Much like the rest of the Internet however, for every hundred [tweeting pot plants](https://twitter.com/#!/ajfisherbot), there's a project much more worthy and they don't always start in an architected fashion. Last year after the Japanese earthquake for example, [some hackers decided to put together an open sourced radiation sensor](http://translate.google.com/translate?js=n&prev=_t&hl=en&ie=UTF-8&layout=2&eotf=1&sl=auto&tl=en&u=http%3A%2F%2Fwww.yapan.org%2Fmain%2F2011%2F03%2Fmeasure_radiation_dose.html&act=url) in order to monitor the amount of radiation in the wake of the Fukushima incident. Notably they were doing this due to the unreliability and non-public nature of official sources. Very quickly, many sensors sprang up around Japan and the Pacific to monitor the radiation levels. Commercial and scientific sensors also had their data pushed to Pachube to aggregate it too. So within only a couple of weeks, pachube became one of the most definitive sources of public radiation data in the world that was good enough to see trends. Other developers used the data and mashed it up to create mobile apps and more importantly used Google Maps to visualise what the levels of radiation were in real time in general understandable terms. This made it easy for people to start understanding whether 50 micro seiverts was high, low or otherwise - whether it was normal or whether it could make you sick. This availability of cheap physical devices coupled with ubiquitous networks facilitated by web technologies allowed this to happen in both a time period and geographic scale that few governments would have been capable of achieving. Even five or six years ago, trying to do this would have been almost impossible to achieve. And now there are many such projects doing similar things - from [Don't Flush Me](http://dontflush.me/) in New York attempting to change people's awareness and understanding of storm water flooding in the sewage network to the [Air Quality Egg](http://airqualityegg.wikispaces.com/) project being undertaken in Europe and US which seeks to provide inexpensive air monitoring devices in numerous homes in order to assess air quality that is typically only being measured in one location in most cities with sensors that cost tens of thousands of dollars apiece. This humanisation of sensor data through mechanisms like Sensor Commons shows how we will begin to interact with and understand our environments better. From systems that show how much energy a given building is using in real time to visualisations projected into civic spaces that show the levels of satisfaction of residents with local government services. The mashing up of data like this will prove very interesting. Meta-Products If networked sensors are the beginning point of many Internet of Things discussions, [Meta-Products](http://metaproducts.nl/) are it's natural evolution. These are products and services that are built from scratch to take advantage of this new computational and communications architecture and without a significant web component to their design would be be able to exist. They generally create so much value that they totally change the way we behave as a result. Health and well being The classic example is [Nike+](http://nikeplus.nike.com/plus/). What's interesting is that the mechanics of the sensor in the shoe existed previously yet the wrapping up of the Nike+ web services that sat on top of it was what drove it into the mainstream. That ability to track your own performance as well as compare and compete with others was the killer feature. And with that, they created a new product category that is changing the way we view exercise, health and well being. From the [FitBit](http://www.fitbit.com/) which monitors your activity levels and can monitor your sleep through the [WiThings](http://www.withings.com/) scales that track your weight by simply stepping onto it. We're even starting to see heart rate and blood pressure monitors for the very serious bio data geeks out there. What I'm most surprised about is that there aren't similar devices yet for pets even though we're quite used by now to the whole idea of the [Internet of Cows](http://www.designculturelab.org/2011/07/20/an-internet-of-cows-and-sheeps/) - livestock tagged with RFID chips being moved around networked farms and other parts of the supply chain for traceability reasons. Health and well being is a huge market that is still in it's exploratory phase but there is plenty of space for well thought out products and services. [Just this week](http://www.smartertechnology.com/c/a/Optimized-Systems/Wireless-Implant-Meters-Drug-Doses/) approval has been given for a team to move to production of medical implants that receive signals wirelessly from the GP at the appropriate time for a drug to be administered - in order to help patients on serious medication regimens so they don't need to do so many injections and to help with compliance. Welcome to the future of how we'll be administered drugs in our old age. Web facilitated physical objects. Meta-products can also use the web to orchestrate better physical efficiency than existed before. Take flexicar or Go Get as an example. Has anyone here subscribed to their services? The beauty of [Flexicar](http://www.flexicar.com.au/) and the services like it is it's simplicity - which is in turn driven by web thinking about a physical world problem. This is what happens when physical objects become discrete, track-able data points that can be interacted with via the web. The clue to the thinking here is that each vehicle has a unique name - proving it's individuality. This shifts the conversation from being about a car in a fleet to the car that's around the corner from me now. Not only has the model changed the way we hire cars; it's also changing the way we view car ownership. Many urbanites are choosing to not own vehicles as they are expensive and see a low frequency of use. Given a means of efficiently managing all the different people who want the car at different points in a day, this model becomes extremely viable. The number of Flexicars springing up around suburbs such as Prahran and St Kilda are testament to how desirable this method of ownership is becoming. This type of meta product is shifting our behaviour from ownership to access - driven by smart networked objects intermediated by clever web services. There are huge opportunities in this space for urban environments where people are just drowning in redundant clutter - tools such as lawn mowers and other large, expensive tools would be an obvious place to start on this front but we're starting to see similar behaviour in fashion as well. Digital Shadows and the physical / virtual boundary One final example I wanted to share is in the realm of kids toys - which is always an interesting space to see technology opportunities in the future. The idea I think was sound, but it was probably a little ahead of it's time and was a commercial failure but it's worth mentioning regardless. Disney built a product called Clickables, which was physical jewellery and other objects that you bought. The product was marketed at Tween girls and was derived from the insight that these girls generally behave in a gift culture - that is, respect and social standing are raised by gifting each other - typically through helping others out and making and giving things to their significant friends. The physical jewellery could be paired with a friends by clicking them together and that would create a friend relationship in a virtual world played online. Here girls could exchange virtual goods and go on adventures together. Obviously the product outcome was that additional physical artefacts could be bought and gifted to another person in the real world and that would unlock achievements, special goods and activities within the virtual one. As I say, the product itself was a flop and was probably indicative of Disney's lack of network thinking as a Web veteran would put it.This was because the value of the virtual environment was dependent on the number of physical devices in the real world. For any given circle of friends, in order for the virtual world to be useful they all had to have a clickables product linked together - a classic network effect issue. Someone taking another crack at this now would probably have a better run, given the drop in development costs associated with doing this type of work now that would see greater ubiquity of devices. Conclusion And so this that brings me full circle to the question I asked at the start; what happens when web connected, physical devices are so cheap that the hardware is disposable. What happens when a smart device can be handed out for free with a Happy Meal or as part of conference schwag? As yet we don't quite know where this will go, but those who have web thinking in their core DNA and who can also become skilled in designing and building physical things will architect new products and services. This will redefine whole product segments across toys, wellness, and health care all the way down to changing our relationships with ownership and the way we understand our physical environment. The web of things for me is about the humanisation of the web, bringing it into our physical spaces and things; in order to enhance them both. This trend is just in it's beginning, but the effects it will have on our physical world and the way we interact with it will be profound.","['arduino', 'internet', 'iot', 'media', 'mobile', 'open source', 'predictions', 'presentation']","['internet', 'mobile', 'iot', 'media', 'open source']","[0.6350896887882449, 0.609676025687368, 0.6091629557956741, 0.6087437939089424, 0.6053896734454391]",[],[],[],[],True,8
2012-06-10-is-this-the-end-of-windows-server.md,Is this the end of Windows Server?,"['cloud computing', 'development', 'internet', 'linux', 'open source', 'os', 'predictions']","Is this the end of Windows Server?
Well, probably not quite yet - just look at how long it's taken Unix to die in the data centre. However I can't but feel that Microsoft's [announcement this week](http://www.zdnet.com/blog/microsoft/windows-azures-spring-fling-linux-comes-to-microsofts-cloud/12869), that they will now be supporting Linux under Azure, represents a fundamental shift in the balance of power of server operating systems. Microsoft haven't been competitive on the web server and database side of things since the [middle of the decade](http://news.netcraft.com/archives/category/web-server-survey/) with steady decline since then. Yet, they've held up more strongly in the traditional data centre side of things and the conventional wisdom is that historically Linux has gained at the expense of Unix - ie workloads were being migrated to Linux when they came under review. More recently we've [seen that wisdom be questioned]((http://www.linuxfoundation.org/publications/linux-foundation/linux-adoption-trends-end-user-report-2012) and importantly the role of Open Source within the enterprise has[ hit its tipping point](http://blogs.hbr.org/cs/2011/03/open_source_software_hits_a_st.html) and is now becoming entrenched as a respected method of providing software. All of this started before we seriously began moving workloads to cloud environments though. Revenues from Azure are hard to come across but are tipped to be about $200-400M, compare this with [AWS](http://aws.amazon.com) however which has just broken $1.2B this year. Azure strategists would be looking at those numbers and wondering why they weren't getting anywhere near given their marketable base (and dominance in paid server revenues) and asking serious questions about the validity of Windows Server and SQL Server within a cloud environment. End of days? While this post stems from an action by Azure, it's really about Windows Server and the end of an era. The reality is that Windows Server and SQL server in a cloud environment just plain suck. I know, I've tried it - indeed for some workloads I have to use it. It's terrible for multiple reasons. Obviously there's price, it's going to cost you a lot more, even with PAYG licensing than any other OS. But more fundamentally, the Microsoft stack is too monolithic for most cloud applications to be really useful. If I want a constellation of dedicated machines undertaking different tasks that I can scale independently, I'm saddled with Microsoft's stack all the way down. Okay sure, I don't HAVE to use IIS, I don't HAVE to use SQL Server and I don't HAVE to use .NET. But if I don't have to use any of these things, <b>why the hell would I chose to run any of the alternatives on Windows?</b> All I'm doing then is opening my application up to more stability, management and development problems and I become a second class citizen as a result. Only an idiot actively chooses to be a second class citizen in any instance. Here's why that has happened. Over the last 5-6 years, largely BECAUSE of the shift to commodity infrastructure services like AWS and [RackSpace Cloud](http://www.rackspace.com/cloud/) etc, what we've seen is a refocussing of the efforts of hundreds and thousands of developers on tooling to support the differences in this architecture. No longer was the system design about expensive hardware that had to have maximal utilisation and so required a monolithic approach to your workloads - architecture moved towards a more modular approach (not N-teir or even service based) and take advantage of being able to run different workloads on differently instanced machines (eg high memory or high CPU or both etc) that are dedicated to the task at hand. So now most applications and services designed to take advantage of cloud based architecture are using Linux as the core with layers on top of it to achieve this. For the web there's not just [Nginx](http://www.nginx.org), but a host of application servers such as [Gunicorn](http://gunicorn.org) and [Node](http://nodejs.org) that are designed to work with it for specific tasks. You've got [Varnish](http://varnish-cache.org) to do content caching, [memcached](http://memcached.org) to do data caching. And this is just the web based stuff, before we start talking about things like [RabbitMQ](http://rabbitmq.com) for messaging and the multitude of NoSQL data stores (eg [Riak](http://www.rackspace.com/cloud/), [Redis](http://redis.io), [Hadoop](http://hadoop.apache.org) etc). If you're building a serious new application, regardless of whether it's a web app, and certainly regardless of whether it needs to be ""web scale"" or not, you're quite simply not going to find the breadth of tooling available to you anywhere other than Linux. Yes, out of those applications I mentioned above, some can be run on or interfaced with Windows Server. Why would I want to be a second class citizen in my own application though? If I'm going to build a new application for our business, why would I put it on anything less than the best of foundations? No one in their right mind would run something like Gunicorn on a Windows server in production! Back in the day, many of these applications would be ported back to Windows due to developer demand (eg Apache, PHP, MySQL etc). Now, the fact <b>that few are bothering is a sure indicator of how irrelevant Windows Server is</b> to new projects leading the direction of technology for this next decade. In an evolutionary sense, Linux has provided a better host for rapid development of new projects that simply couldn't or wasn't possible under Windows. As a result, Windows Server has become an evolutionary dead end and will slowly become extinct. Given this scenario, if I was the product manager for Windows Server, I'd be seriously polishing my CV - and probably giving [Canonical](http://www.canonical.com) a call, or at least applying to the Mobile or Gaming divisions where Microsoft are doing some valid and good work. The news that Azure is going to support Linux has probably got some old school MS employees chewing bricks but it's a smart play in the cloud space. Azure's two most serious competitors are Amazon and RackSpace, both of whom have excellent Linux support AND both support Windows. This move by the Azure team cements them into a position where they can compete effectively and if they have to jettison some old party lines about product support then so be it. Now they can get on with the job of being a credible ""Top 3"" cloud infrastructure provider. On balance this is a good thing for Azure, a great stamp of approval for Linux, and I think, the beginnings of the end of Windows server. I'm sure Windows Server will continue for many years and versions yet but I'd like to hope we don't get to see windows server 2020.","['cloud computing', 'development', 'internet', 'linux', 'open source', 'os', 'predictions']","['development', 'internet', 'os', 'linux', 'cloud computing']","[0.624729283482606, 0.6171005809937413, 0.5982212855325574, 0.5964526552744152, 0.5895427004125667]",[],[],[],[],True,7
2012-07-25-web-facilitated-play-in-the-real-world.md,Web Facilitated Play in the Real World,"['arduino', 'development', 'gaming', 'hardware', 'internet', 'iot', 'mobile', 'open source', 'presentation', 'web']","Web Facilitated Play in the Real World
I got the invitation to attend and present at the [Sketching in Hardware conference](http://sketching-in-hardware.com) this year on some of the work I had been doing around integrating real time web communication with physical devices. This aligned well with the overall theme of ""Clouds and Atoms"". My presentation was called ""Web facilitated play in the real world"" and expressed a summation of the work I have been doing over the last 18 months to bring together mobile and network aware physical devices utilising the real time web. My slides are below and the transcript of my talk is underneath. You can find the transcript of the talk below. Transcript Hi. My name's Andrew Fisher and my background is as an interaction developer and today I want to talk to about web facilitated play in the real world. Play is fundamental to our lives - from our earliest childhood through to being an adult, play is a core part of what defines our humanity. Technology and play are highly symbiotic with each one helping to drive the other forward and evolve. Now, I was on a train the other day going to work and saw someone that looked like this; headphones in, iPhone out, totally immersed in what was obviously a multiplayer game. This has become a familiar view of play in the modern world - at times I am this person. The technologist in me loves the fact we have the technical capability for someone to play a multi-player game from their phone in Melbourne with others in Madrid and Moscow all at the same time. This is brilliant! However the sociologist in me can't help but feel we've had to give something up as a result - and that is, we tune out the world around us almost completely. I think our shared spaces are causing some of this as well. How often do you stand on a train station platform and see advertising 2 months or in some cases 2 years out of date. Not that anyone's noticed because they are all looking at little black rectangles of glass. Our civic environment hasn't kept pace with technology and is becoming ever more boring just as our phones become ever more compelling - is it any wonder we tune out? We have hit an interesting time though. With approaching a billion smart phones in people's pockets and a billion more expected over the next decade. With physical computing devices increasing in their capability and increasingly being networked with all the benefits that confers. And all of this coupled with the web! But now we have the technologies at our disposal to reshape play again, or at least methods of interaction, in our shared spaces using digital tooling. What could this do for play as a result? Today I want to show you how this can work. I'll give a brief introduction to web sockets, then show you the technical architecture for doing this and then round up with some examples and a demo at the end. Websockets So the technology that enables real world play is called web sockets. Web sockets is part of the suite of tech that makes up HTML 5. Thought it's not actually anything to do with HTML directly. Web sockets is an upgrade to the standard HTTP connection - getting rid of the traditional request / response model. Instead it opens a long lived, bi-directional, network connection that data can be passed along. This lends itself well to scenarios where you are passing small packets of data very frequently over connections open for long periods like minutes or hours. There's a fair amount of overhead in opening this connection, but once you do it's much more efficient. The most common messaging arrangement is called [""Pub/Sub""](http://en.wikipedia.org/wiki/Publish%E2%80%93subscribe_pattern) or Publisher / Subscriber. We have a publisher that produces a message and sends it to the web sockets server which acts as a broker and it passes that on to subscribers who consume the message and do something with it. Now in web sockets world most messages are passed around using JSON because it's lightweight, many libraries exist, it's expressive and flexible. So this architecture scales well and you can have many publishers and subscribers just producing and consuming messages. Many topologies exist for different needs but this is one of the most common. Now you understand a bit about web sockets let's talk about how we can use it to connect objects in the real world. Websocketing Things What's interesting about web sockets is that it's a protocol and as such anything that can talk it can become a publisher or a subscriber and work with messages. For example, we could have an arduino with a temperature sensor on it that broadcasts temperature readings every 100 milliseconds to the broker. The subscribers could be a real time logging database for later processing and a web client for real time graphing of the data. Now scale the arduino out and have 10 sensor nodes, 100, 1000 all producing data in real time that could be used by a dozen subscribers all doing different things with the data. As interesting as that facet is, I came here to talk about play. For play, then, we can turn all of this on it's head. So here's a view of the stack I use to do this. At the top we have web browsers across phone, tablet or desktop with interfaces that create messages. These get sent to the web sockets server for processing. I use [Django Socket IO](https://github.com/stephenmcd/django-socketio) as I'm a python guy but there's things like [Node.JS](http://nodejs.org/) which are conceptually similar. The broker then forwards on messages to the subscribers which in this case is an arduino running a mod of [Kevin Rohling's excellent WebSockets](https://github.com/krohling/ArduinoWebsocketClient) library and it then turns that data into some type of physical control. There's a lot of benefits to using this stack which you can see here, however the main one I want to call out is that as the system is web based and messages are JSON it means I can prototype and simulate EVERYTHING in the browser. This means I can get the web interaction rock solid and the networking totally debugged BEFORE going to hardware which then becomes a decoupled and more straightforward implementation on the physical side. Now you understand how the architecture works I have three examples I want to share, including one I've brought with me that you can play with. Examples My first iteration of this was purely digital in order to assess the viability of the stack under real world conditions. [Tank Tag](https://github.com/ajfisher/tank-tag) uses the tilt sensor in a phone to drive a tank around on a screen; and the touch screen to fire, so you can tag other players. The key is that the phone is now the controller and everyone plays together on a shared space on a screen or via a projector. The largest scale I've had about 100 people playing this on a 40ft projected screen at once. I tried for bigger once and got nearly 150 before the network seized up for volumes of data being shifted. For my next iteration, I wanted to incorporate something much more physical but also create a sense of team work and focus in the space amongst the players. The tug of war concept was used for this and again players interact with their mobile phones. After hitting a web page the players are divided into a red and green team with their own goals to pull a magnet towards. This time the accelerometer is used for input and players have to shake their phones as hard as possible. The team that is collectively pulling the hardest at any time will pull the magnet towards their goal and eventually light it up. This was a lot of fun and really starts to create a sense of shared use in the space given the focus and requirements for team work and it's all facilitated by web enabled devices that people already have in their pockets. The third example I've actually brought with me from Australia. It's quite simple so it was travel proof but hopefully it will serve to illustrate to you the direction this can all go. If you want to play with this then point a web browser on any device to [ajf.io/sketch12](http://ajf.io/sketch12) - this won't work in Internet Explorer however so use something else - not that I expect that to be a problem here. Click on the circles and away you go. As you all can have different colours they should mix somewhat if you hit the same lights at once. As you can see the interaction is near instant and again there's almost no barrier to someone interacting with this. Applications If you consider my original points about creating interactive spaces by bringing mobile, physical computing and the web together this is how we can do it. Imagine something like this scaled up to say 10 metres across and hung on the side of a building and all you'd need is a phone with a web browser in order to interact with it. This stack will work in any context where we want to create interaction on a semi mass scale but where physical proximity is important. So it could be used for interactive advertising for shared user experiences, general civic space upgrades or for spaces like museums to create points of interaction with exhibits via smartphones without having to worry about downloaded apps. In summary, I've walked you through a tech stack that gives you the ability to harness the real time web and allow it to interact with the real world. I've got some resources here which I'll send around as a link and all the code is in my [git hub](https://github.com/ajfisher/sketching-conf-demo) for the demos I've shown today. Obviously come and talk to me about this if you're interested and I can show you code etc if you want to see it. I hope this gives a slightly different view on how we can bring together mobile with physical devices and use the web to facilitate play in the real world.","['arduino', 'development', 'gaming', 'hardware', 'internet', 'iot', 'mobile', 'open source', 'presentation', 'web']","['web', 'development', 'internet', 'mobile', 'open source']","[0.6481930522111269, 0.641042296769471, 0.6337974902018871, 0.6315268716952603, 0.6092570320222502]",[],[],[],[],True,10
2012-10-19-datatium-a-material-to-create-responsive-experiences.md,Datatium - a material to create responsive experiences,"['conference', 'context', 'data science', 'media', 'mobile', 'responsive design', 'ux', 'web']","Datatium - a material to create responsive experiences
I had an opportunity to speak at Web Directions South again this year though was a bit daunted by the prospect of being asked to speak in the Design track for the very first time in my career. However, this was a great opportunity to distill a lot of the thinking I've been doing around responsive experiences for the last two years, thinking that dates back all the way to the work I did with [Paul Thurlow](http://twitter.com/jptcovers) at [peoplesound.com](http://wayback.archive.org/web/*/http://www.peoplesound.com) over a decade ago as well as more recent work at [JBA](http://jbadigital.com) as a result of my data work. I've included the slide deck here as well as the document which lead to this presentation. This is just a small piece of a wider body of work I've been amassing on this topic for the last year and my first attempt to codify the mechanisms of responsive experience. I will be looking to extend this over the next several months with some additional ideas I have on this and probably build a site to support it. Transcript Today I'm going to talk about how we use Datatium to make responsive user experiences for the next 45 minutes. I must admit I was a bit daunted at first at the thought of speaking in the design track at web directions because I'm not a designer, I'm a programmer with a fascination about human behaviour. So I thought, I'm not going to be able to speak about design, but I can speak about where I think the web is lacking, some things I think can help from a technology point of view and talk about what I want it to become. The web as it stands has got remarkably prettier over the last few years, and we're seeing some interesting effects as the web is joining together nearly two billion people and that's all great. But the web is still not truly responsive to me as a person, it responds to my device and reflows nicely but not to my behaviour. We're not evolving to respond to our users the same way we're responding to technology choices. [Amazon](http://www.amazon.com), for all it's early innovation on this front in personalisation is becoming less adept not more so. Every day that goes buy transforms Amazon into the digital equivalent of the local $2 store but one that just happens to move some things that might be relevant to the front of it when it sees me coming down the street. That's not the type of web I signed up for when I started as a developer far too many years ago and this is why I'm getting grumpy - I was sold a personal jetpack and what I've been given is a Honda Civic. In my future I want all my data made securely available to any service I give access to and I want those services to shape themselves around me all the time. I want applications that change their nature based on how I behave not just as a result of what device I'm on but how I use the service. I want all the features of the web - search, social, location, information, service layered around me all the time with relevant pieces popping into existence when I'm likely to need them, seamlessly integrated into my day. I want the alarm in my phone able to access my diary, the weather, the traffic and the public transport system and decide whether to wake me 10 minutes earlier because it's going to take me that much longer to get to work. I want github to recommend that I check out three other projects after I commit some code because it looks like I might be doing something similar and I might be better placed contributing there rather than making a fourth project. I want the moon on a stick, I want a pony, and I want it now. Is that too much to ask? Responsive Design is an important aspect of the next evolution of the web. People are starting to become unbound not only from desktops towards mobile devices but our notion of what is a web browser is beginning to change due to the fragmentation of the web across so many devices and services. The web is the only thing that can possibly keep these things glued together but responsive experiences are what allows the adaptivity between them. And data is the fuel of truly responsive experiences and allows them to function and this is the notion of what I call Datatium. My aim here today isn't to turn you into data scientists, though if I do make you decide to become one then that's awesome. Rather I want to start injecting some data science thinking into your approach to design and hopefully make you interested enough to pick up some of the tools and techniques I'm going to talk about today and start using them. The third decade of the web is going to be led by those that understand data both from the insight it can give in shaping the user experience and by those who can get to grips with the mountains of data we're generating and design totally new data products from it. The next age of the web will become increasingly elastic and fluid that will react to the way we want to experience it. And today I'm going to show you how using a little bit of datatium can really start to shift the types of experiences we can create. So to do this we're going to concentrate on three key areas: We'll start with looking at direct feedback experiences. We'll then look at how we can use behaviour to shape a response. And finally we'll look at the effect of context on experience. So let's get started. Conditionally responsive experiences Conditional experiences are the simplest type of responsive experience. They take explicit pieces of information and shape the experience based on what you tell them. I call these conditionally responsive experiences because they are pretty much like big programming “if” statements: IF I do this thing or provide this information THEN the application does something in response.. This stuff is pretty simple as it's entirely driven by explicitly given data points and a lot of these things we can ask for and we can usually trust the data once we have it. For example if someone picks “tall” from a gender selection list we can start doing something with that information because we're going to be fairly happy that the information is correct and we ignore people that are lying and treat them as though they were telling the truth. I can get a long way by designing this type of experience because it all comes back to what the user has told me they want. Conditionally responsive experiences should be the baseline for most web experiences by now, but sadly they aren't or are often ignored - how many of you get annoyed when you set some kind of preference about how you want to interact with a service and then it's blatantly ignored? So let's look at how we get the data to do this, the types of experiences we can create with it and then how we weave it into the design process. Getting data What sort of data do we want to get when we're designing conditionally responsive experiences. Well the main thing here is to make it as clean as possible and also to use what you ask for. Start by just keeping it simple. Ask questions and ask for corrections from the users. The obvious things are items like demographic and preference information and wherever possible provide a pick list. Sometimes you can't do this however so you need to take a guess and roll with it or suggest an alternative to the user. A really good example of this is [Google's](http://google.com/?q=sheos) “Confused User” mode where it says “Showing results for shoes” because you can't spell ""shoes"" Andrew. Also consider best guessing and providing the results to the user showing what assumptions you've put in place - for example [Wolfram Alpha](http://wolframalpha.com) when you type Ruby gives it a go and then asks for further clarification. So don't underestimate asking and validating with your users in order to get clean data that you can use. Types of conditionally responsive experiences So we've worked out how to get the data so what can we do with it now we've got it. One thing to point out here is that if you've gone to effort of getting it, make a bit of effort to show the user how you're making their experience better as a result. If you've got it, flaunt it. Efficient experiences So the first and most obvious use of all this data is to simply make things more frictionless throughout the experience. These don't need to be massive mods, they can be little tweaks to help make the person's process a little more frictionless. Like one of my pet hates is when I buy something online and I have an account because I've shopped there before and yet things like the contact form doesn't populate my details with name and email address. Why do I need to be asked again? You already know who I am, I've already provided that info... Another way you can do this is by leading questions that might ask for something which helps a later decision. If we put the postcode field first in our address field set then we can pre-populate state and country with information derived from it. Now as an engineer I KNOW you need to do a real look up on postcodes to determine state because we have some wacky exceptions but a user is a little forgiving. You don't have to be perfect in every instance. If you can get 99% with about 10 lines of javascript why wouldn't you? Don't underestimate the value of tiny removals of friction, especially in things like checkout processes. The way I think about this is like a slide right. Remember when you were a kid and they made a slide out of some sort of metal that you just didn't seem to slide on so you had to wiggle your way down. Pretty soon you got bored and went and set fire to things or did something more interesting. ![A sandwich shop with people queuing to buy food](../../img/posts/tss.jpg)
*The Sandwich Shop, Surry Hills, Sydney - image (cc) ajfisher* One of my favourite examples of this frictionless interaction is actually from a sandwich shop over in Surry Hills. When you place your order you have to give your name. If you pay with a card though they use your name off the card and just confirm it with you “You're Andrew right?”. Beautiful! We can do this so much more often than we do. Leading incremental experiences We can also use conditional response to lead a user through a process to supply more data or gain experience. This works by constantly shifting the goal slightly so you always have another destination but in doing so you build up your skill with the service. [Linkedin](http://linkedin.com) leads people through the process of getting their profile built up and it doesn't feel like an interrogation. They need to get a full profile on everyone so they lead the user and stretch them with goals to supply more incrementally which helps the user as well because they aren't overwhelmed in the initial sign up process. How many of you have played a game like Zelda Ocarina of Time, or Twighlight princess or some other Nintendo, SquareEnix or EA RPG of some sort? Okay most of you. Notice how when you start playing one of these games you start off with a really limited palette of actions. You move around, maybe jump and maybe fire. So you have this purposefully limited set of actions while you develop familiarity and then more and more complex actions are given to you over time. Eventually you end up with these control systems where you're clicking buttons like mad and it feels quite natural but if you tried to put that in front of someone in their first 30 seconds of a game it would be almost impossible to play with. This is a responsive experience in action - the game helps you along the way but until you master the ability to do something you don't move on to higher degrees of complexity. So we can use the data that surrounds our user to open up the experience around them as they are capable. As complexity arises in modern web applications, this keeps them engaged, doesn't overwhelm them and gives you more data to work with to create even more responsive experiences down the line. We could do this much more than we do now. Design process How do you approach this in the design process? One of the ways I incorporate this is by calling it out explicitly during the wireframing and prototyping phases.  I draw little stick men asking what do I know about the user to this point and what should I be asking them now which will help me give them something more later? I constantly look at forms and attempt to pare things back to only that which is required. You know when you go through that process of marking fields as required or optional? get rid of the optional ones! If they are optional create another process to fill them in later as part of “profile completion” tasks. Every time you put a field down question what you are going to use it and what does the user get out of it by supplying the information. Look at whether there's a better arrangement of requests for data that allow you to make the experience have less friction. Keep asking this over and over and work with your dev team to see if they have any additional sources they can pull in to help this as well - for example address validators or importers. We've looked at the most straightforward type of responsive experience, the one that lends itself towards obvious user personalisation. We've looked at how we get data from the users and how that creates certain types of experiences and we've looked at how we can weave this into the design process. Now we'll take a look at the next type of responsive experience, where we don't just consider what a user says but we'll look at what they do as well. Behaviourally responsive experiences Behaviourally responsive experiences are a little harder to create because we will look at what a user does as well as what they say - actions speak a lot louder than words. A thing that we also need to be aware of is that behaviourally responsive experiences can start get a bit murky as well because the user isn't always aware of what is causing the application's behaviour so we need to consider transparency. So we're going to talk about what data is useful for these types of experiences, the types of experiences we can create with them and how we factor this into the design process as well. Getting the right data So how do we get the data we need to make responsive experiences from people's behaviour? This data is largely implicit in nature. Now, implicit data is generally the stuff we derive from other sources - like familiarity with our system is a function of clicks to finish a task or time spent on a particular page or interaction with particular content. It's less reliable and we can't say things definitively though we can start to infer things from this behaviour. I just want to mention Web Analytics for a moment here. Even though I work with this every single day, I don't consider it real behavioural data. It's marketing spend justification data. So it's not that useful for us when designing experiences. No, what we're interested in is in getting data that is actionable - that helps us form opinions about how design should unfold or about giving us direction for iteration. So that helps us; but we're also interested in data that shapes the experience for the user. It's about them too remember? So we look at why is a user doing or not doing what you've set out to build for them? Are they getting stuck? How do we even know if they are getting stuck? We can ask questions about a user's intent. What are they after? Are they exhibiting any sorts of behaviour where we can start predicting what they are ultimately wanting to do? Are they using our system in a particular way that allows us to tune the experience for that. Often to make this type of data work you need to start working with a developer or a data scientist in order to start making sense of it, but it's worth considering these questions up front as it allows you to craft experiences around the answers. Types of experiences we can create So once we have some behavioural data what can we do with it? Using behavioural data doesn't need to be ridiculously clever to be extremely effective. Recommendations Recommendations of what other things to look at is an obvious first step but one that's ignored many times. In my experience, a machine with a reasonable model will beat a human on recommendations just about every time. Amazon are the obvious example here and have got consumers used to the idea of affinity matching - this model is also dead simple to implement too but it can work on other types of content too like this recommended stories panel from the New York Times site. So recommendations is a great way to help the user and increase discoverability and you use the data from thousands or millions of users to create the correct associations. When you've got a product catalogue that literally has hundreds of thousands or millions of items in it then you need to be able to do this. Repetitive behaviour: What can you do in order to get people to the things they really want to be able to see as fast as they can. One of the things I've been toying around with is to consider the thing someone does most frequently and consider having a slot for it in your main nav or homepage. For example if I have a pay as you go mobile phone and I recharge it online, chances are most of my visits to the website are probably going to follow a pretty well defined path. Home page, account login, select recharge, put in the recharge details, complete, exit. Why not make this a link that surfaces when I start exhibiting this behaviour. Sure it makes it a little harder to design for but if we just make the slot available for responsive experience customisation and define constraints around it then it makes it much more useful for the user. ![Screen shot of the home page of Amazon.com](../../img/posts/amazon_shop.jpg) Taking Amazon back as an example the thing I do more than anything on the Amazon site is check my Gift Card balance because I read so many ebooks on my kindle. Creating a responsive experience for me would be taking that piece of data and then exposing it on the site AND exposing it through the API that is available to the kindle. That's the sort of stuff that starts empowering users and making them feel as though the application is reacting to their behaviour. So behaviourally responsive experiences start becoming a lot more elastic in terms of design. Design process Now the problem with behaviour is it's inherently chaotic. It's messy and it's now reliant on users who could be doing all sorts of different things and behavioural data can be contradictory as well. Argh - how can you design for it without it looking like 20 random things have just been vomited up onto your home page. Start small and build upwards. Consider using behavioural rules like we do media queries to show behaviours once a threshold is reached. Some thresholds will be low - for example product recommendation based on the product you're looking at. Others will take time to develop say surfacing content that is based on previous interactions with the service over long periods. Design for slots / modules as high up as your primary page structure where you can dynamically allocate them as the user's experience evolves. And make sure you do this early on as this helps constrain the chaos a little bit can stop data vomit later on. Allowing for failure Now, we need to consider designing in methods to allow people to correct a mistake. If you embrace the chaos of behaviourally responsive design you ARE going to make mistakes in what you put to the user but they are good opportunities to learn. So in your design process you need to do two things. The first is to make it transparent to the user about WHY they are being provided with the information you're providing them. Sometimes this can be hard to articulate easily so you might need to work at it. [Amazon](http://amazon.com) recommendations work quite well here because it tells you what you purchased or looked at in order to get the recommendation. The second is allowing the user to correct things. Facebook ads are a good example of this as they let you fix a problem and in fact they look at it as an opportunity to collect some additional data about WHY it was no good for you which helps them with their targeting ongoing. Passing data back that's useful Correcting failure starts the process of closing the loop on behaviour, however, we can extend this and provide the data back to the user in some other form to start using for themselves to give them feedback on their own behaviour. The saying goes that if you're not buying the product then you are the product and I think many users realise this now. But that doesn't mean you have to just brutally harvest them for their data and sell it off to the highest bidder through targeted advertising. A nice obvious example of that is say [Last FM](http://www.last.fm/user/andrewjfisher/charts) which shows succinctly what I've been listening to over different time periods, by tracks, albums and artists. Linkedin gives you stats about how your profile has performed over the last week or month to show how effective your profile is in search and visits. In fact they built an entire data product around this for “vanity users” who want to see all the details of how many people are looking at them. So behaviourally responsive experiences take a bit more work but they completely change the nature of the experience from one of linear progressions down a decision tree to something that is a bit more fluid. It sits on the edge of chaos from a design and system perspective a lot of the time but if you embrace it you will end up with a bunch of unexpected consequences as a result which you can turn to even greater experiences for your users. Now we understand how conditionally and behaviourally responsive experiences work we're going to talk about how we really start to change the nature of experience and look at contextually responsive experiences. Contextually responsive experiences These experiences are ones that constantly evolve, they are highly chaotic and require you to think more about intent than about anything else. They are shaped by external factors to the user as well as to the explicit and implicit data they have generated for you. To give you an example of how seamless this looks when you see it in action here's a clip from the Avengers movie. Notice here how the HUD changes from a general display on what's going on to full threat tactical display in a heartbeat. Stark doesn't activate it at all and it becomes perfectly tuned to the tactical situation around him, responding contextually to the threats nearby. Now clearly this HUD doesn't exist in anything other than a fictional sense but this completely sums up how I want the web to behave every day - and I'll settle for this without the flying suit of armour and pulse cannons in my hand. A contextually responsive experience is really easy in theory but super difficult in practice. How many of you are using media queries to create responsive pages for mobile, tablet and desktop web experiences? Great - just about all of you. So you're already familiar with the basics of contextually responsive experiences. Now I'm sure many of you have come across this problem where you have a nice desktop site and you use media queries to reformat it to work on mobile but it doesn't feel right or worse it feels terrible? It ends up as a big long scrolly page, the navigational system doesn't work very well and you end up with something that whilst it's reflowed nicely doesn't really elicit the feel or the usability you were striving for. Has this happened to anyone? Right so the issue here is that whilst the mechanics have worked properly using a different device has created a totally different context from one interaction type to another. This is the hardest type of  responsive experience to create because we haven't been trained to consider it, we don't have a lot of tools to make it work and it's really difficult to get the data for it. But this is where the web transforms into something else - something that's entirely and seamlessly linked into our every day. So we'll look at how we get some data to work with, what we can do with it once we get it and then look at how we factor it into the design process. Getting the data Getting the data to use for contextual responsiveness can be a bit hit and miss. The key here is to experiment, to use all sorts of data sources and blend them together. The obvious starting point is devices but that just lets you know capabilities you've got to play with. Next we can consider time, different people use devices differently over the day and week. Using your tablet at 9pm is a different behaviour at 9am. We can also consider location - is the person moving or stationary? You can infer location but you can also ask a user for their location if you think it will make it a better experience. Does the person's location overlap with known places like a train station, a train line or say you were a retailer one of your stores (or close to it). These are just a few points that can create a whole bunch of different contexts that the user may be in. If I visit a site on my phone at about 8am every morning through the week and I'm moving chances are I'm on my commute. This is very different to me using a tablet in landscape mode at 9pm where I'm connected via a high speed wifi link from a static location. Context starts creating a significant number combinations of variables and this can quickly spiral out of control but start by just considering device, location, time and speed and you'll get a surprising number of contexts from them to consider in your design. Types of user experiences We've got all these different contexts so what can I do with this information? Externally adaptive experiences Traditional responsive design starts here looking at capabilities first and foremost. I can start shaping the type of experience based on the device. By looking at connection speeds I can start shaping what they see. A mobile phone on a WiFI connection is a fundamentally different to one on a 3G network especially when you change cells and the network has to do a hand off. As such we can change assets based upon this. As well as our media queries, we can send different quality images to users on poorer connections. Indeed we can even consider removing heavy images altogether and making them request based. Reacting to these types of external events can really make the difference between a great experience and a terrible one. Make the external factors that go into the experience something you can start to control. Task oriented contextualisation Now, a lot of companies when they “go mobile” have this belief they need to be able to offer everything on their site on the mobile site as well. This is rubbish. The user might tell you they want something but actually when it comes down to it, they'll do something else entirely. The reason for this is because of task oriented context. I've been told anecdotally that when ANZ came to build their GoMoney application for mobile devices it was based around the insight that the majority of users logged in to the existing web application on their phone, looked at their account balance and exited again. As such in their mobile app they put it front and centre and then tacked on making a payment as well as that was the number two task. Context is what drives need and requirements. When I'm out and about and I'm really mobile, I don't need the full capabilities of the entire ANZ online banking platform. I just want to see whether I've been paid and whether I have enough money to buy that new Vita game or not. Don't underestimate task oriented context as it's a massive factor in behaviour. As we all have smartphones and tablets available to us one of the big shifts you see is in starting to use micro moments to be more effective. Smashing out a quick tweet, taking a photo and uploading it somewhere, paying a bill, reading an email. These are all massively task oriented behaviours that are bound to the context of our locations and our devices. This works for desktop sites as well. For example I love the way when you're doing something in google docs all other Google services melt away. You can still access them when you need to, but the application becomes your primary context. So understand what the user is trying to do and get them into that mode as easily as possible and maximise their ability to work within it given the constraints of the external factors that drive the context. Adaptive contexts The last type of experience we can create is what I call adaptive contextualisation. Adaptive context is where all those context variables are being considered all of the time and they are constantly changing our experience on the fly. The only real example of this right now is the work google is attempting to do with Google Now. It doesn't really work just yet and is almost useless in Australia but it's a sign of the things to come. This is showing how the future of much of the web will be fragmented and will slide across our various devices in different ways based on the data that's coming from all around me. Google knows I'm likely to be going home about 5pm so it can start showing related information to me. This could pop up in a widget in chrome, come into my Android home screen or be beamed to my pebble watch (well maybe in the future it will be). This is where the web starts bumping up against the physical world. Where physical and web data starts seamlessly flowing back and forth and influences the way I interact with both. Imagine walking into a store and little highlights are shown where product is that you might like based on your previous purchases that ALSO includes availability of stuff that's in your size. This is where adaptive context starts to go once we get things architected the right way. Design process So how do we work this type of experience into design? This is really where system thinking really starts to take hold in order to make this work completely. Embracing chaos The first thing to do is to truly and totally embrace chaos. Contextually responsive experiences are complex systems. This is why they are so powerful as they are deeply adaptive. You can end up with some quirks so try to find out where the quirks happen and give the user the ability to take a decision that fixes it such as those I described before with behaviour. Intent To help with this we use intent. Intent gives you a framework without having to be prescriptive. To design with intent you should design and build prototypes rather than design in photoshop. Rules Once you have intent, you can then emit some rules for behaviour. These are your non-negotiables but the key here is to be sufficiently relaxed that you ONLY define the non-negotiables. This allows you to define really adaptive systems and maintain some standards but not have to define every single little thing which kills you in complex systems. Think of this as like an uber-style guide, where you're defining an approach to design rather than the specifics. Conclusion As I said at the start my aim has not been to turn you into data scientists but give you some thinking about how this notion of datatium can help you evolve much more complex and responsive experiences by looking at conditions, behaviour and context to do so. I want you all to go away from here and start creating highly responsive experiences in everything you do. I feel as though the web is about to hit another tipping point, where it is so ingrained into everything we are doing that it's about to morph again into these amazingly adaptive and responsive experiences that surround us every day, constantly shifting and changing. Hopefully the examples I've talked through will give you some ideas of where to start but I want to leave you with a couple of things if you take nothing else from this talk. Golden rules for creating responsive experiences using data Firstly here are my golden rules for using datatium to create responsive experiences: You don't know everything, be open to ideas and open to what the data tells you Data is worth more than opinion discussion shifts when there's data to hand. Be bold - design is about exploring a domain space. No real explorer we know about now got there by sitting on their couch. Make a judgement and go with it a lot of the time you'll be wrong - who cares at least you'll learn something. The other thing I want to leave you with is something I mentioned at the start. Data and data thinking is one of the most critically required skills of the coming decade of the web and society generally. Don't be afraid of data because you don't need a PhD in stats to do interesting things with it. Back in the 70s a magazine was launched to help you make a punk band. In it there was a page: Here's a chord, here's another, here's a third - go start a band. ![Graph of behaviours over time, change and then change of change](../../img/posts/behaviour_differentials.jpg)
*Behavioural differentials - image (cc) ajfisher* Well data science is like punk. It's all about exploring the possibilities of what data can do for user experience and break pre-existing rules. So here's my equivalents: Here's a question - What's the behaviour look like over a period? Here's another - How does this change from one period to the next? Here's a third - How does that change itself change over the period? Now go make some responsive experiences!","['conference', 'context', 'data science', 'media', 'mobile', 'responsive design', 'ux', 'web']","['web', 'media', 'mobile', 'conference', 'context']","[0.6431273882092212, 0.6052998092766743, 0.5980990509813193, 0.5788667602150869, 0.5731131763281868]",[],[],[],[],True,8
2012-11-20-a-clickster-fail-of-epic-proportions.md,The ClickFail of Australian Retail.,"['cloud computing', 'development', 'ecommerce', 'internet', 'media', 'rant', 'retail', 'web']","The ClickFail of Australian Retail.
There but for the grace of Web Gods, go I... In Australia tonight we were supposed to witness the coming of age of Australian Online Retail. Our first ""Cyber Tuesday"" - a moment where the industry said to Australians who have been lured to the sales of the US and Europe ""We can do this too"". And then we didn't. ![A screenshot of webpage with an error 'Server too busy'](../../img/posts/server-too-busy.png) We didn't because technologists were too arrogant to heed the lessons of ""Web Scale"" development that have been done in the rest of the world. We didn't because our retail industry has spent more time crying foul over the lack of GST on international retailers than gaining proficiency in doing online commerce well. And we didn't because we still have marketers in this country who can say and hype what they want but are not held accountable to delivering good results. I'm not happy. Not happy at all. I've spent just about my entire adult life working to stop exactly the type of problems that happened during the [Click Frenzy](http://clickfrenzy.com.au) debacle tonight. From designing web applications that could withstand the load of half the young adult population of the UK to listen to and download the latest track featured on a Smirnoff Ice advert. To ensuring the website for the Melbourne Cup could stay up when hundreds of thousands of people all decide to find out the winner at 3:15pm on the first Tuesday of November each year. Or maybe it's just designing ecommerce applications so that when a marketing director decides on a whim to do a 40% off sale with 3 hours notice over lunch time and then email several hundred thousand customers the website will manage to survive. For the first two hours of the 24 hour sale, <b>the website was simply unavailable due to meltdown</b>. Three hours in as I write this I can get a smattering of pages from the site but no deals to speak of. Most of the retailers have responded admirably, turning to their social media channels to direct customers to their own websites where they could get the offers anyway. This, for me, was a highlight, showing yet again the web's ability to route around failure. Indeed many smaller brands quickly capitalised on the fiasco, launching their own deals on their sites to try and lure in customers who were eager to spend - hijacking the twitter and Facebook back-channels to their own ends. Unfortunately, due to the huge amounts of PR in the lead up to Click Frenzy, many of our biggest retailers failed to withstand the traffic also - [Myer](http://www.myer.com.au), [David Jones](http://www.davidjones.com.au) and [Harvey Norman](http://www.harveynorman.com.au) all went down within minutes as customers started going to their sites directly. Not surprising really given these are businesses that have been dragged every inch of the way into online retail since its inception in the '90s. Australia was late to the ecommerce party. With an industrial boom that kept customers purchasing in store at inflated rates and high shipping costs holding off international competition they had it easy until the GFC and the resources slump. Since then they have woefully mis-invested in their ecommerce platforms. They bought into the sales hype of platforms like Magento and WebSphere Commerce from consultants that have been all too eager to get reseller fees and provide little value or experience alongside it. Most Australian retailers have shown little more than disdain for the channel. Staffing has been a nightmare - with juniors recruited because they are young, use Facebook  and ""get"" the Internet. <b>Never mind that they had no experience</b> and as a result, no ability to judge whether what their agencies or vendors were telling them was correct or a good idea. And then there was click frenzy - an organisation that hyped its ability to drive sales for lagging retailers yet was totally unproven. An organisation who outwardly presented such a level of arrogance in the face of what they were attempting that it can only be called hubris. This was a wasted opportunity and tomorrow, when the press releases go out, we'll see more arrogance from the team that created such a monumental disaster. Tomorrow it will be, ""The scale of traffic was unprecedented , ""We could NEVER have predicted this was going to happen"", ""This has never been done before in Australia"". Seriously STFU. Every aspect of this endeavour could have been anticipated. A simple bit of maths by someone who understands traffic and retail customer behaviour could have told you that you'd need to do something special. The sort of special that keeps the Ticketek site running when Justin Beiber releases tickets. The sort of special that keeps the Amazon site up when they launch a new gold box. The sort of special that keeps the home page of a newspaper running in the wake of a war or global natural disaster. Doing this maths is what keeps me awake at night leading up to big launches or events. Thankfully I've always had a stellar team around me - people like [Steve McDonald](http://github.com/stephenmcd) (Tech Lead on Melbourne Cup - now at Fairfax) and [Matt Black](http://github.com/mafrosis) (Product Lead on JBA real time behavioural processor). People I count on to think through all the problems and come up with solutions well before they are needed. People who have been there before and who are humble enough to not believe they know everything and will learn from other people's mistakes in order to prevent us making them as well. These are solved problems. <b>There was absolutely no reason why any of these sites needed to go down tonight.</b> Indeed looking around others managed to stay alive - [Target](http://www.target.com.au), [Deals Direct](http://www.dealsdirect.com.au), [Kogan](http://www.kogan.com.au) were all fine. There was no need for Click Frenzy to be running magento and the type of architecture it was running from watching it fail for a couple of hours suggested it was never going to deal with the traffic it was going to get (Magento is notorious for database overload which takes a lot to architect around). Likewise Myer, Harvey Norman and David Jones should all have good enough systems to be able to deal with these sorts of traffic spikes - what are they doing for Christmas and Boxing Day if they don't? From my research on the effects of trust on customers' purchasing behaviour in the wake of site outages, I can tell you that all those brands who went out tonight are going to see serious lags on their sales. Forget the money spent on advertising, the ongoing loss of sales from erosion of trust (where a customer decides to go elsewhere) will hurt a lot more in the long run. The chest thumping spin that will be in the media about ""we were just too popular"" doesn't wash in reality with consumers - it's insulting. Every second a site is out harms your brand and you have to work extra hard to regain that trust. That there was such a deep failure of our ecommerce systems shows that Australian Retail is not ready for a global stage. My hope in all of this is that next week, after the dust settles, after the fingers are no longer being pointed, that learning can begin and that collectively this industry learns from the mistakes. My fear is that it will be business as usual in Australian Retail - where this is used as yet another reason why ecommerce is not viable and investment and learning will evaporate. _Update: 2012-11-12 13:50 AEDT_ I mentioned in my post above that Kogan survived alongside other retailers such as Target etc. According to some people who have chatted to me, apparently Kogan did experience a small period out down time however I didn't see that as I was going back to the site every hour or so last night. Also I just want to point out for the record, as part of this post has been used in articles on The Age and SMH, that this was not written in my capacity as CTO of JBA. JBA work with a lot of retailers around crafting better customer experiences, who fully recognise the challenges of doing ecommerce at scale, and who are working hard to try and build or refactor platforms to deliver the type of experience that should have happened last night.","['cloud computing', 'development', 'ecommerce', 'internet', 'media', 'rant', 'retail', 'web']","['web', 'media', 'internet', 'development', 'rant']","[0.6350833744850694, 0.6211734561412887, 0.6080087186283408, 0.6061537747026698, 0.6019293310771957]",[],[],[],[],True,8
2013-03-20-jump-start-responsive-design-launch.md,Book launch of Jump Start Responsive Design,"['design', 'development', 'responsive design', 'web']","Book launch of Jump Start Responsive Design
Today, ['Jump Start Responsive Design'](http://www.sitepoint.com/store/jump-start-responsive-web-design/)
officially goes on sale. This is the first book I've been an author on and
it was great to work alongside [Craig Sharkie - @twalve](http://github.com/twalve)
on this project over the last 6 months. ![Cover shot of Jump Start responsive Design book](../..//img/posts/responsive_design.jpg)
*[""Jump Start Responsive Design"" - Sharkie & Fisher](http://www.sitepoint.com/store/jump-start-responsive-web-design/)* The book is squarely aimed at developers and designers who are looking to rapidly
get up to speed on current RWD techniques and just get going with them on their
projects. There's plenty of examples that show the current state of where things
are at and how things will also work as browser support increases over time. It was a pleasure to work on this project with Craig as well as the whole team
over at SitePoint. The dead tree version and eBook are available through SitePoint
as well as all the other usual sellers.","['design', 'development', 'responsive design', 'web']","['development', 'web', 'design', 'responsive design', 'mobile']","[0.6586606247498236, 0.6526384954999389, 0.5987078297263396, 0.5973620710956632, 0.3197078446213235]",['mobile'],[],[],[],True,4
2013-08-21-should-javascript-devs-build-real-things.md,Should JavaScript devs build real things?,"['development', 'essay', 'internet', 'iot', 'javascript', 'media', 'nodebots', 'open source', 'physical computing', 'robotics', 'ubicomp', 'web']","Should JavaScript devs build real things?
_The bent and broken pieces of the drone were lying scattered on a table in the office. There wasn't much worth looking at; most of the components shattered beyond repair. The PizzaCopter team looked at the mangled mess at the table. No one really wanted to be the first to talk about the crash._ _""Well,"" said the lead developer, ""it looks like there was a bug with the range sensor. The flight controller didn't contain a type check on the data and so when it corrupted it interpreted it as NaN and didn't know what to do. At that point it just sped up and became a high speed projectile with a pizza and smashed into the ground.""_ This is a riff on something [Glenn Siegman](https://twitter.com/gsiegman/) was joking about (quite astutely) on Twitter the other day  and something that has stuck with me since the launch of [technical.io](http://technical.io) earlier this week. I don't think things would have been quite that bad, and we've certainly seen rocket scientists crash very expensive spacecraft in the past ([the ill fated Beagle 2 mission for example](http://en.wikipedia.org/wiki/Beagle_2)), however, I've been asked a lot about what I think of the project, not least because it coincided with a talk I did this week called [Building Droids with Javascript](http://www.slideshare.net/andrewjfisher/building-droids-with-javassript) and because I've been working and playing at the intersection of the web and hardware for quite a number of years now. The launch of technical.io was met with the usual Hacker News crazy. One group of devs exclaiming, ""OMG this is the most awesome thing ever invented"", another, ""Dude, be a man and learn C - that's what the real hardware devs do"" and a final group that can only be summed up with, ""Lol, you're a JavaScript developer, man could you get any lamer? You probably use PHP as well"". <b>In all, the usual responses to an HN post discussing programming</b> and a perfect example of why I try to experience as much as the Web as possible without comments - though in this instance I read every single one - just in case there was some insight (in case you were interested - there wasn't). I've spent a while trying to articulate my thinking on this as it's a complex topic that touches on hardware, design, engineering, community and education. I don't profess to have all the answers but I hope writing about these topics will create discussion about the role of projects like this in the community. First up, let me give you some context as this may explain my ""mixed"" opinion on this bit of tech and about using hardware with JavaScript in general. Growing up a nerd As a kid I was much more into electronics than I was programming - interested in why a computer worked rather than how to run code on it. I didn't have access to much hardware but dismantled every toy, VCR, blender or TV I could lay my hands on to understand how they worked. As I got older and computers got more powerful I got lured to the software side due to the ability to make things happen faster - particularly as a result of the Amiga demo-scene of the early 90s. Eventually, my very first ""tech job"" was a summer job before writing software drivers for the very first resistive touch screens (Windows 3 and Amigas). These were used for multimedia installations in places like museums and were all custom built. I found it interesting and a lot of the software the screens interacted with was hypermedia. I realised then that I was actually very interested in how people interact with things rather than the things themselves. That went on to manifest itself in my degree choices (Psychology & CS) and then into working with the web very early on and that's been my career ever since. As a web developer I have always been much more interested in how and why someone interacts with something than the technology that underpins that interaction. Even though my day job is and has been web development for a considerable number of years I've always dabbled with hardware, particularly embedded systems and this increased significantly since 2007. The reason for this can be solidly accounted for by the robustness of Linux on the desktop and the availability of the [Arduino](http://arduino.cc). You'll note that neither of these things have anything to do even remotely with javascript. ![many different types of arduino boards](../../img/posts/8d6dfc02cd8211e1ad6922000a1e8aaa_7.jpg)
*image (cc) ajfisher* Having access to free development environments to tinker at a low level (initially with USB development kits) with Linux and then subsequently with the excellent hardware package that is Arduino brought me back to hardware in a big way. Since then I've been developing ""things"" for art, research, personal interest, fixing things for people, scratching itches and generally trying to join hardware with the web. I've spoken around the world on the topic and even helped provide feedback on new products being designed. Over this time I've used many different AVR based chips and boards, played with PICs, designed my own boards, blown many things up and have achieved a passable knowledge of how to build and use modern electronics - especially when you want to have a physical ""thing"" that is interactive and connected to the web. With that context in place, lets move on to JavaScript and Hardware. JavaScript all the things JavaScript is a powerful language. It has a bad rap as being a toy because of it's early days when it was. Over time JavaScript has been getting better, more powerful, more complete and more ""serious"". My entire career has been defined by the capabilities (or not) of JavaScript dating back to its first release as LiveScript. I don't consider it a toy but I do consider it poorly implemented in parts (but getting better). In my opinion the greatest strengths of JavaScript are its immediacy and its accessibility. It has plenty of weakness (insanely weak typing, implicit casting for comparison, terrible problems with numbers, fluid syntax, I could go on...). Regardless, these weaknesses are entirely overcome by those two points above. Having taught quite a few people to code, <b>the benefit of being able to open a text editor or a browser console and type code that can be immediately and reliably executed is incredible</b>. The power this brings to the learner is unmatched. When trying to learn new things it's important to get positive reinforcement very quickly and JavaScript has this ability in spades. Executing console.log(""hello world"") or window.alert(2+5-20) brings immediate feedback, makes you feel as though you're getting somewhere and that you are interacting directly with the computer as a programmer. For those of you old enough to own a Spectrum, C64 or Vic20 - BASIC (itself heavily derided) had the same benefit. ![Commodore 64 terminal screen](../../img/posts/4129346259_33d03514e0_o.jpg)
*[Image (CC) Taizo E.C.](http://www.flickr.com/photos/taizocurry/4129346259/sizes/l/in/photostream/)* Many of those in their 30s got their first intro to programming by doing this: Immediacy of feedback is a powerful learning step and one that simply cannot be replicated by languages like C. Download and install your build tools, create make files, do your compilation and linking steps. Oops, syntax error! Now go back and do this all again once you fix it. Even as a seasoned embedded developer I **HATE** going through this process a bajillion times a day. As for accessibility, JavaScript is accessible through the sheer amount of it out there. As a web language there's lots of it documented, web developers love to blog about it and there are libraries, snippets and howtos by the million. I fully accept there is a lot of bad javascript out there - Stack Overflow is absolutely full of the stuff. It's probably second only to bad PHP in terms of volume (I made that up - there's no data to support that statement). Having said that, I bet if we looked at your first couple of years of programming C, Pascal or whatever you learnt back in the day we'd find some coding practices that we shall say are, ahem, less than excellent? There's a lot of discussion about the bad parts of JavaScript blowing people's legs off because they don't understand them (eg everything being mutable so you can do things like redefine ""function""). This is often said in a way that only makes me think of worried parents saying ""no darling you can't go on the slide because you might fall off and break your arm"". As both a parent of a child who's done exactly that by being stupid and as a programmer that has done equally stupid things in C (off by one errors on a memory pointer anyone?) this is both condescending as an argument and misses the point about the benefits of failure in the learning process. JavaScript's accessibility and immediacy create a good opportunity to teach programming. If we are concerned, as a Computer Science community (and by that I mean all programmers, academic and professional), that JavaScript developers don't code the ""best"" way then <b>it is incumbent on all of us to educate rather than belittle</b>. What must be remembered is that students entering and graduating Computer Science degrees are at an all time low and have been declining for years. And yet the number of informally educated developers in the web community is astonishing, many of them doing excellent work every day. The ability to self-learn with nothing more than a web browser and an enquiring mind should be seen as the greatest gift the programming community has been given. From my perspective as a senior technologist it's certainly helped when it comes to availability of great developers to work with that our traditional educational systems have failed to provide. Given this combination of accessibility and immediacy we find ourselves with an increasingly powerful language that is being extended further and further into ""traditional"" use cases of ""real"" languages like C++ (and dare I say Java??) and for reasons that can only be considered protectionist this is met with resistance. At this point I will direct the reader to [""The innovator's dilemma"" by Clayton Christiansen](http://www.amazon.com/The-Innovators-Dilemma-Revolutionary-Business/dp/0062060244). The gist of which is this: A new tech comes along (JavaScript) and it's cheap (free) but it doesn't do everything a more mature tech (C++) can do. The incumbents write it off for lack of comparability, usually saying ""no one would use that - it doesn't do x, y, z"". Over time, users of the new technology get involved with its direction and the features they need to make it better get added - usually at a considerably reduced price and they get the benefit of learning from all the implementations that came before. Eventually the upstarts take large swathes of the market, seemingly overnight, and the incumbents are left with husks of their former positions - often unable to explain how they got to that point and were unable to see the threat. From cameras to cars to mobile phones to 3D printers this happens time after time so we shouldn't be surprised that JavaScript is doing this to established areas of technology (eg server side application development, embedded systems etc). Now we understand why JavaScript is popular let us consider the use of it on hardware. Droids in JavaScript The last 12 months have seen a significant shift in the amount of projects being done attempting to use JavaScript with hardware. Initially this has focused on using JavaScript to control hardware. For example the [library that was developed to control the ARDrone](https://github.com/felixge/node-ar-drone) by wrapping its network protocol and exposing a JavaScript client. This created a slew of [NodeCopter](http://nodecopter.com/) events, where developers would build things with the drones using JavaScript. All sorts of applications have been created - everything from making drones respond to external APIs (dancing on a twitter @ message), to refined control UIs through to full image recognition and manipulation. ![Close up of Parrot AR Drone](../../img/posts/8575918404_37e1b119bc_k.jpg)
*[Image (cc) nez](http://www.flickr.com/photos/nez/8575918404)* After that came the excellent [Serial library for node](https://github.com/voodootikigod/node-serialport) (removing my final objection to using JS with hardware). This meant that applications could control devices that are plugged in via USB. All of a sudden everything from controllable lights (eg [Blink1](http://www.kickstarter.com/projects/thingm/blink1-the-usb-rgb-led)) through to small scale robots started popping up. Coupled with [Firmata](http://firmata.org/) - a protocol for controlling embedded systems over serial - it then became possible to[ start manipulating hardware very directly from within JavaScript ](https://github.com/jgautier/firmata)over serial connections. Whilst focused on Arduino, any board that implements firmata is a viable target. This eventually led to the[ Nodebots / Johnny-Five project](https://github.com/rwaldron/johnny-five) (disclosure: I'm a big fan, have committed code to the project and helped run a nodebots day) that provides JavaScript objects for common hardware (servos, motors, sensors etc) for Arduino. ![Small, wheeled robot next to laptop computer](../../img/posts/nodle.jpg)
*Image (CC) ajfisher* So within just over 12 months the community has gone from almost no hardware capability at all to being able to control things that fly, crawl and walk, make things light up and sense the environment. Yes much of this stands on the shoulders of other protocols, libraries and hardware but that's not the point (all software if built on the shoulders of lower foundations all the way down). The point is that when something is technically possible people will start doing things with it. I've been playing around with web controlled ""things"" for years. For most of that time, particularly in Melbourne, it has felt very much like I was the only person doing it. There have been others dabbling from time to time but they were mostly coming at it from the engineering side (eg make a thing simply shift data over the network etc). Internationally this was reflected as well - <b>those working truly from a web perspective on hardware design for the last several years could be numbered in the small hundreds</b> at best. I used [Web Sockets to talk to hardware devices](https://github.com/ajfisher/django-arduino-socketio) very early on and was consistently dismissed (even ridiculed) because HTTP & WS are heavy protocols and there are technically better ways to do it (there are eg [MQTT](http://mqtt.org/)). Now this is nowhere near an extreme position for these types of comms. Why? Because immediacy gives you the ability to prototype rapidly. A web sockets server in JS can be implemented in 15 lines of code plus ""npm install express socketio firmata""). Accessibility means that you can find a LOT of developers who can do exactly that code above and actually know how it's going to work even without hardware knowledge. Try and do the same thing with tech like MQTT or [Protocol Buffers](http://en.wikipedia.org/wiki/Protocol_Buffers) and your pool of talent drops spectacularly. So as this hardware has become more accessible, more developers are attempting to work with it. This is a **GOOD THING** because through exploration of a design space we get more coverage with the more practitioners. This is why the web has taken over just about every facet of our lives, because we have designers and developers tinkering on new ways of doing things or new ways of conveying information all the time. This effect should not be underestimated and we are only at the start of it. One of my more contentious views is that your average web developer or designer in 2013 would have been a cabinet-maker, smith or instrument maker in 1913. I won't get into all the details of this but suffice to say that most developers and designers who work with the web have an intrinsic desire to ""make"" things. Most of them even refer to web work as a ""craft"" as much as a profession. Once you couple the skills of a few hundred thousand web developers and designers with the ability to design, build and fabricate actual physical things that talk to the web you start ending up with interesting things. [Robots controllable from mobile phones](https://github.com/ajfisher/ajnodebot), [house lights you can interact with](http://lifx.co/), art where data from a buoy in the middle of the ocean is [tele-present in the middle of a gallery in Poland](http://www.youtube.com/watch?v=0p3je4WGcM0). ![A matrix of coloured LEDs in a hexagon](../../img/posts/js_matrix_led.jpg)
*Web addressable LED matrix - Image (CC) ajfisher* Making hardware available to web developers is a desirable goal. Much of the web is given over to entertainment and solving first world problems. Being able to affect the real world provides an opportunity to fix actual problems and enable better quality of life for many. Web developers and designers intrinsically understand the ""hard place"" between systems and humans - making them uniquely placed to have a tangible impact in the real world. Abstraction creates magic So far I've painted a picture of how desirable it is for web developers to be working with hardware so you would assume that I'm entirely for this idea. Here comes the grey side of my argument and the areas I believe we need to be wary of. In working with developers coming across to hardware from software the single biggest knowledge gap is to do with the actual electronics. Many have never touched an electronic circuit of any kind (especially those that are younger). Whilst electronics is a completely learnable skill, it is a barrier to entry that needs to be overcome before being able to design something non-trivial. Time after time I see posts from people saying, ""I don't understand why it won't work"" and 99% of the time it's due to a fundamental knowledge failure of how a circuit or a component works. Nearly every one of my own problems falls into this category as well. Electronics components often either work or not and are much less tolerant of failure than code - not least because you can destroy a component, not realise it and then spend days debugging before you understand you have killed it. ![Photograph of control panel of abandoned power station](../../img/posts/5597955361_7174f21345_o.jpg)
*[Image (CC) brickman](http://www.flickr.com/photos/brickman_photos/5597955361/sizes/l/in/photostream/)* It is this facet of electronics that the embedded systems camp are coming from when they say ""do it in C"". Not necessarily because the language is better but because you are working at ""the metal"" and as a result you will get a much more visceral understanding of the electronics. I totally appreciate this position and my fundamental electronics understanding comes from a combination of this as well as building analog circuits. So now we get to technical.io and my concerns about this project and others like it. Fundamentally I think there's too much magic here and not in a good way. Abstraction is useful when it removes the need to do tasks that are low value or highly repetitive (eg finding the location of a character in a string or providing the routing for a URL to a page in a web app). For the record, what I'm about to say next is based purely on my observations of [technical.io's public code](https://github.com/technicalmachine), poring over images of their boards and reading spec sheets for the chips they are using and reading all of their blog posts and commit logs. I have not talked to any of the team (though I'd love to - I expect they are insanely busy). IE: I'm making some educated guesses, doing some speculation and reading between the lines. Technical.io attempts to build a board that runs JavaScript ""natively"". This isn't quite true. What happens is you require the tessel library and that provides you an abstraction of the board. Functions of the hardware are then exposed out via an API (eg led(1).blink() etc) that allows you to control pins etc. This is pretty much what firmata already does, though firmata doesn't provide an API to the underlying hardware it simply provides the mechanism to interact with it (analog reads and writes for sensors and PWM, digital on / off states for IO pins etc). Firmata has its problems (it's very geared towards Arduino, there's issues with the project, it's slow moving, it's bound to a serial baud rate for starters) however it has a good protocol and it's in very wide use. There's also bindings for JavaScript, C, perl, Python and others which makes it very portable. My bigger concern with this is that it would appear the libraries (and the plug in modules that provide additional functionality) ultimately wrap C libraries (which is pretty common in the node community anyway) however because this is a custom designed board with seemingly little access to  lower levels, the ability of non-core developers to add functionality will be significantly reduced. Thus <b>we land ourselves in the ""app"" world where the capability of our design is based on the ability of the hardware developers to expose APIs</b> for it (this will sound familiar to anyone that has dealt with Android or iOS?). I also have some concerns that there's some kludging going on with both the hardware and the software. This always happens to an extent, but when you're dealing with inexperienced hardware developers who will be using this there may be some problems. Consider the ""Servo"" library which you would use to control servo motors. Servos look simple but they are relatively complex devices. Unlike a standard motor which can just go forward or backwards, servos use pulsed signals (PWM) to tell the servo where to position the servo head. For example a signal of pulses that go high for 1.5ms usually means align the head to the centre - longer and shorter pulses moves the head in ranges away from that centre point clockwise or anticlockwise. The tessel board is using a chip designed to PWM LEDs (to make them brighter or dimmer or control RGB LEDs) in order to do servo control duty. This is a neat hack as it means you can control a range of different things with the one board but the biggest problem comes when a novice developer comes along, plugs in a high current servo, loads it up with something heavy and blows the board. Admittedly this can happen with an arduino (and I've done it) but it is a bit harder because you have to read more and you'll come in contact with good materials on using servos - most likely before you blow it up. Next we have the obfuscation of the OS. To run JavaScript we need an OS to run it on. Given the ARM M3-Cortex chip at the heart of this board, this probably means it's running a micro flavour of Linux. That's great just by itself even without JavaScript but it would appear all of that power is going to be hidden away behind an interface layer. Whilst I'm sure someone will make some mods to make Linux available in some way, most users won't bother with that. Contrast this with the Raspberry Pi or BeagleBone which provide full access to Linux as well as anything you want to run on it. ![Photograph of BeagleBone Black board](../../img/posts/9176951660_2a261dab3a_k.jpg)
*[Image (CC) stfnix](http://www.flickr.com/photos/stfnix/9176951660/sizes/l/in/photostream/)* In my opinion the BeagleBone provides the best mix of this - plug it in, connect over USB or network and you have Cloud9 IDE where you can write and execute JavaScript directly on the board. If you _want_ you can SSH onto the device and work at a Linux command line - you can work in perl, python, java or C quite happily. There's no requirement to do so but you get the power when you do. This provides immense longevity for the device and stops it sitting in a draw discarded 6 or 12 months down the line. Making hardware for JavaScript devs Far from being dismissive of the tessel / technical.io project I think it's a great sign of where we are at in the JavaScripting of hardware. As stated earlier I fundamentally believe there is a massive opportunity to solve a lot of problems with physical devices by getting web designers and developers working with them. However rather than build something simply to ""run JavaScript"" I believe a better approach is allowing JavaScript to be a first class citizen and provide a learning path that encourages the understanding of electronics. Arduino is an excellent example of this approach from a C perspective. The reason for this is Massimo, David and the rest of the team are all educators - as such they fundamentally understand that you need to provide opportunities to experiment and grow your capability with every step and not lock someone into a dead end. With an arduino it is extremely easy to do simple things. You can copy and paste code from the examples and it will work. Due to the framework it's easy to see that the LED is blinking because you're turning pin 13 on and off every 1000 milliseconds - you don't even need to be a programmer to understand that as a concept. This is why arduino has been successful with students who are not naturally inclined to try programming. ![Photograph of LEDs illuminated in heart shape](../../img/posts/2226419292_a91c6dafa5_o.jpg)
*[Image (CC) oskay](http://www.flickr.com/photos/oskay/2226419292/sizes/l/in/photostream/)* However once you get beyond this level of understanding it's perfectly fine and possible (and encouraged) to start writing ""real"" C code that manipulates registers and memory. Thus the pathway from novice to embedded system programmer is entirely visible. To construct this path with JavaScript we need to do two things. The first is to provide only enough abstraction so that the focus goes onto the electronics. Someone that re-implements the simplicity of the arduino learn package and examples libraries in JavaScript with say a BeagleBone would do a lot to achieve this goal. The second thing we need to do is provide a pathway for low level interaction. Ultimately this probably means working in C / C++ however an intermediate step may be able to do manipulation of hardware registers directly from JavaScript as well as be able to handle things like Interrupt Service Routines in a reliable way (so you know they will execute quickly and with priority). In embedded systems you can't get away from these requirements so we need to provide a means for developers to learn and understand them as part of the journey not hide it away as being ""too hard"" and therefore irrelevant. The ""Internet of Things"" needs web designers and developers At the moment, hardware devices that are being connected to the Internet are mostly being built by embedded systems engineers. Whilst these devices may be technically excellent, they often lack an understanding of good web design practice - particularly from the point of view of good user interface design, API creation and consumption as well as openness and extensibility. This may be perfectly acceptable for M2M type applications (at a stretch from my perspective) however for anything remotely consumer oriented, web designers and developers understand the human part of the Internet of Things. As designers and developers, getting a good grounding in electronics and hardware gives us an advantage when it comes to building these types of applications and there is a huge future in it due to the cheapness of computation and ubiquity of networks. If you're a web developer and you're looking at playing with hardware, don't shy away from the electronics. There are no magic bits of hardware that will give you full control of the physical world in a box - though there are plenty of attempts at this. Develop your knowledge the same way you do with the web - by reading, tinkering, playing with code and breaking stuff. Go join a hackerspace, get some learning materials, visit electronics shops, pull things apart and learn how they work. And seriously, if you design a PizzaCopter for actual use, please don't build it in JavaScript. _Update: There were some concerns expressed that my original fictional intro was a bit FUDdy. On re-reading I tend to agree with that sentiment - it was an artefact of my original version of this post due to me explaining my concerns to another JS dev using a similar story. I've kept the core element but removed the death and destruction._","['development', 'essay', 'internet', 'iot', 'javascript', 'media', 'nodebots', 'open source', 'physical computing', 'robotics', 'ubicomp', 'web']","['development', 'web', 'internet', 'open source', 'iot']","[0.6410843553243392, 0.6370275327674187, 0.6271524374338314, 0.6039488320065501, 0.6032846241007435]",[],[],[],[],True,12
2014-05-04-device-api-safari.md,A Device API safari,"['development', 'mobile', 'presentation', 'standards', 'web']","A Device API safari
The Device API allows browsers to have more access to the underlying hardware
on the host machine and allows it to appear more ""native"". Mostly this has been
aimed at mobile devices and incorporates the very well known Orientation and
Motion APIs. There are, however, a great many other Device APIs available,
some of which are well supported and some that are only new. This was a talk presented at [Web Directions Code 2014](http://www.webdirections.org/code14/)
and explored numerous facets of the Device API, including: Sensor APIs Web NFC Network APIs Proximity Battery Status Vibration Ambient light The presentation is embedded below: [A Device API Safari - WDC 2014](//www.slideshare.net/andrewjfisher/a-device-api-safari-web-directions-code-2014) The main aim of this talk was to have a large number of demos in the 20 minute
presentation in order to show case what was possible. All the code for these
demos is [available in the repo.](https://github.com/ajfisher/wdc) The demos are embedded below if you'd like to play with them in more detail noting
that support can be a bit hit and miss. Firefox is pretty much guaranteed. Proximity Support: all mobile devices with a proximity sensor [Proximity detection](https://wdc14.ajf.io/examples/proximity/) Battery Support: All modern browsers except IE (any) [Battery level](https://wdc14.ajf.io/examples/battery/demo.html) Vibration Support: Most devices that have vibration motor in them Application in HTML games: [Racer](https://wdc14.ajf.io/examples/racing_car/) Application in form error reporting: [Vibration form](https://wdc14.ajf.io/examples/vibrate/form.html) Ambient light Support: Firefox on desktop and most mobile devices Application in contrast modification: [Ambient light for contrast modification](https://wdc14.ajf.io/examples/ambient/contrast.html) Application in silliness: [Ghosts appearing over video stream](https://wdc14.ajf.io/examples/ambient/ghosts.html)","['development', 'mobile', 'presentation', 'standards', 'web']","['development', 'web', 'mobile', 'presentation', 'standards']","[0.6697368665034814, 0.6533519192752767, 0.6343183523480876, 0.6115774724937241, 0.5890612072996803]",[],[],[],[],True,5
2014-12-16-building-information-radiator.md,Building an information radiator,"['arduino', 'development', 'hardware', 'iot', 'physical computing', 'python', 'ubicomp']","Building an information radiator
Information radiators are an interesting, though under-explored area of IoT - probably
because they are difficult to make money from in anything other than very custom
builds. I've built a few of these over the years - all of which were for
custom data sets (often my own amusement). An information radiator is often a light (but could be any actuator)
that ""radiates"" information outwards by means of encoding information into the
light that is emitted. This may be through color, pulse duration, modulation
or some combination thereof. An information radiator is usually disconnected from the
source of that data which is often abstract in nature. In this post, I'll show you how to build an ""information radiator"" with a bit
of Python and some LEDs, which you can then use to make your own for your
own personal needs. Full post at Packt: Building an Information Radiator
[Part 1](https://www.packtpub.com/books/content/building-information-radiator-part-1)
[Part 2](https://www.packtpub.com/books/content/building-information-radiator-part-2) ![A light that indicates the forecast sitting on a bookshelf](../../img/posts/radiator.jpg)
*Temperature forecast radiator - ajfisher* Information radiators are fun to make, especially with kids or for workshops
as there are plenty of data sources you can use; weather, incoming tweets,
how full your email is or how often something has happened on your network. If
you can get a data source you can make it into a radiator.","['arduino', 'development', 'hardware', 'iot', 'physical computing', 'python', 'ubicomp']","['development', 'physical computing', 'iot', 'ubicomp', 'hardware']","[0.6432600498577085, 0.6259107926171822, 0.6189085679600259, 0.6114311210807553, 0.6095399262546642]",[],[],[],[],True,7
2015-01-21-context-in-ambient-technology.md,The role of context on ambient technologies,"['context', 'essay', 'iot', 'physical computing', 'ubicomp', 'web']","The role of context on ambient technologies
Right now, I seem to be the guy that is forever speaking about user contexts
and in particular, talking about the nature of how people behave in different
environments and their resulting use of technology within those environments.
My talk at [Web Directions 2012](https://conffab.com/video/datatium-radiation-free-responsive-experiences/)
focussed on this with respect to use of web tech, but this has also been a
primary part of the research that I set up Rocket Melbourne to look into. What has mostly inspired this essay is that it seems like every week a new
piece of ambient technology is being launched on kickstarter - often to almost
Apple-like levels of hype (OMG this is totally going to change the tweet
notification market forever). I'm not going to talk about any one of these
products specifically because I wish them all the best and more people doing
hardware is a great thing. Rather, I want to document some of my own findings, some insight from
observing (and purchasing) a lot of ambient technology products, and hopefully
highlight areas where people should be working in this space. What is ambient tech? As you read this, you probably have many pieces of digital ambient display or
technology around you. If you're on a PC, chances are there's a clock in one
of the corners of your screen. If you're on a mobile device when you go back
to your home screen you may have widgets (if you're on Android) or badges
(if you use iOS) showing how many emails or tweets you have unread. You may
be reading this while standing on a train station platform where there will be
signage indicating how long until the next train arrives. ![A glitched railway sign](../../img/posts/sign_glitch.png)
*Departure boards are great ambient tech - when they work* Or, if you live in a house like mine you'll have many gadgets, all sporting
lights that are blinking on and off various colours to indicate a stack of
different things that are going on around you; from numbers of people hitting
my blog, to chirping when I get @ed on twitter to hot / cold indicators showing
me my inbox level. And that's before we get to expert user systems such as the dashboard on your
car, which provides an inordinate amount of information to the driver at a
glance, and is being augmented further via smart heads up display (HUD)
technology projected onto the windscreen. Ambient technology can encompass all these things and a lot more besides.
In essence, it's a method of presenting information to consumers that is
""around you"". It's not typically ""sit down at a computer and get it"" type
information - typically it's embedded into our environment, hence the ambient
part of it. In many cases there is some form of socially-created encoding involved,
such as the signs for the availability of a bathroom on an aeroplane that
switch from red to green showing busy or vacant. With many pieces of ambient
technology you have to be told what it's doing or else build upon your
knowledge of similar icons in order to bootstrap that knowledge. The bathroom
light builds on our cultural knowledge of stop / go colours as well as
socialisation that teaches us about the states of bathrooms. Good ambient technology is also actionable - <b>it provides you with information
allowing you to make a decision based on the data encoded within it</b> - should
you choose to act on it. To continue the bathroom light example; you can decide
whether it's worth getting up out of your chair based on the bathroom state, or
consider going to one end of the cabin rather than the other. This provides
efficiency in movement, allowing aisles to be kept clear, and crew to move
around easily. It's worth noting also that ambient display information is ""nice to have"" and
not critical. It is different from, say, a warning sign or an alarm, which
requires attention and action to be taken. With the bathroom example, if you
ignore the light, you can still head to the bathroom, you'll just need to wait
when you get there. The bathroom status light is a simple example but one that is familiar and
creates an actionable outcome from very simply encoded data. Thankfully, this
will be the last time I talk about bathrooms on aeroplanes in this essay. Ambient display Ambient display is a very specific form of ambient technology. This is usually
referring to showing information in a visual mode - whether through the use of
light or more traditional display methods (screens, matrix boards etc). It's
fairly common, as we can produce displays very easily, however all the senses
can be engaged in ambient technology with the right design. What's all this got to do with context? Context is really important to how people use and interact with technology and
services. Anyone that spends a lot of time jumping between different computing
devices will know all about context and context failures. Try to reply to a message of some sort on your phone while you walk down a
crowded street (DO NOT try this if you're driving). ![Man in suit passing on the road](../../img/posts/pawel-janiak-8UzhdypkVzg-unsplash.jpg)
*[A man in suit passing on the road](https://unsplash.com/photos/8UzhdypkVzg) -
Pawel Janiak (Unsplash)* Observe the information you pay attention to when you're navigating somewhere
in a public space you don't know. What signs do you look at? When do you look
at a map? Can you hold a conversation and navigate at the same time? How do you perform when you have to process difficult information late in the
afternoon versus in the morning? All of these things are different aspects of context and it is something that
is constantly changing around us. There are many variables that shape our
context as well. I often talk about location, time, connection speed and device
capabilities for web tech, however context is driven by an almost infinite
number of variables. When we consider humans in an environment, we consider
cultural norms, symbolic education, proficiency with the service being used,
mental state, noise, distractions and all sorts of other things that affect our
behaviour. Any time we talk about humans and technology or services, context should be one
of the immediate things we consider. What I want to try and do with this essay is to consider the ways ambient
technology can be deployed and consider the contexts that work best for different
types of ambient information. A contextual model for ambient technology The model I've built uses two, four-quadrant comparison charts comparing three
variables. In the first part of the model, I consider the complexity of the information
being displayed against how mobile the display is within the environment.
Mobility of information is becoming more important to humans, primarily as a
result of always-connected smartphones which can allow themselves to operate as
a generic ambient display endpoint. This can be seen in the four-quadrant chart
below. ![Mobility v Complexity of Information](../../img/posts/context_mobility_quadrant.png) The second part of the model compares the variables of actionability against
the complexity of information instead. As we have seen from advances in Data
Science, taking large amounts of data and distilling it down is important, but
being able to trigger actions as a result of that information is even more
important and useful. This can be seen in the chart below. ![Actionability v Complexity of Information](../../img/posts/context_actionability_quadrant.png) Complexity of information is presented as the X-axis in both parts of the model
so will be discussed here. This represents how much information is encoded and
is being presented to the user. It is worth noting that the same piece of information can
be encoded in different ways and represent different levels of complexity.
Complexity comes down to how tolerant of precision we are in different
situations and the ambiguity inherent in the choice of information encoding. For example take a counter of some event such as unread messages in an inbox.
A board with the number shown has very low complexity. If we encoded that same
data on a scale from blue being zero to red being one hundred on a linear range
between, then this becomes more complex to understand without reducing precision.
Instead, the encoded data must be reduced in complexity to “a lot” or “not many”
rather than 78 or 3. The following sections explore the model in more detail and illustrate the
types of ambient technology that work well within each of the quadrants when
taking the mobility or actionability variables into account. Complexity of information versus mobility of display In the first part of the model, along with complexity, we consider mobility of
the display as our other variable and is represented on the Y axis. The chart
is repeated again here so you don't need to scroll back up. ![Mobility v Complexity of Information](../../img/posts/context_mobility_quadrant.png) Mobility in this case, represents how fixed the technology is to a specific
location. A mobile phone is obviously a highly mobile piece of ambient
technology however the flight status board fixed to a wall at an airport is
stationary so has very low mobility. ![Image (cc) by CAFNR http://www.flickr.com/photos/cafnr/14267599480](../../img/posts/phone_hand.jpg) There are some inherent assumptions that go along with mobility, namely that
the technology is able to be powered and probably has some type of connection
to data via a network or other means (e.g. displaying direct sensor data from
its local environment). The four types of of mobile ambient technology, with examples are highlighted
in the following sections. Type A: Peripheral display (Complexity:L / Mobility:L) Peripheral display is probably the most common type of ambient technology
currently deployed. This is the most common starting point for anyone new to
Internet of Things related ambient technology. In this category are mostly
lights that illuminate based on some arbitrary action (eg pulsing based on
tweets with a certain hashtag). This type of display can run the risk of being a distraction because it
often encodes information that may be peripherally available anyway. The
very common email notification light is an example of this - most people have
the status of their email in their pocket courtesy of their smartphone. As a
result, the information is too simple to be useful and redundant due to other
means of conveying it (thus leading to it becoming low value to the user). Where this type of ambient technology works best is when the encoded information
is not in the information space of the environment already (that is, it is not
redundant) as shown in the following examples. ISS Notify [This lamp lights up](https://www.kickstarter.com/projects/natronics/iss-notify)
every time the International Space Station passes over the
location where the lamp is employed. The idea was originally simply as a
visualisation that the ISS was passing overhead and to highlight that there are
humans permanently in space. NASA endorsed the project and the kickstarter was
well backed and supported. The value of this visualisation comes from the data
not being readily present in our environment especially as the ISS passes
overhead often through the day where it cannot be seen. ![ISS Notify - Nathan Bergey](../../img/posts/iss_notify_original.png)
*The ISS Notify device (image Kickstarter) - (c) Nathan Bergey* Smart lighting Becoming common in car parks, smart lighting is helping to solve the problems
of ""where can I park my car"". This system relies on a pressure sensor in the
floor (or ultrasonic range sensor to see if a car is below it) and a simple
bright LED above each car park which displays red if a car is parked in the
spot or green if it is available. Additional information can be encoded such as
blue for disabled car parks etc. Arguably, the value of this information is
relatively low, however given its increasing popularity in car parks around
the world there must be at least a perception of increased traffic flow within
the car park compared to the costs of fixture (which are now extremely low). Type B: Pocket Widgets<br/>(Complexity:L / Mobility:H) Low complexity, high mobility ambient devices are, at this time, heavily
skewed towards indicators that are present in our mobile devices in passive mode.
This distinction is that the mobile phone (or tablet) is in a restful
state - i.e. without the operator taking complex actions to get at information.
This is the information provided in the lock state of the device or in its
standard “home screen” mode. Smartphones are clearly capable of much higher function, however, for the vast
majority of the time, their use is in a low function passive mode, only one
step up from true standby. Regardless of their passive modality, the devices
are still permanently connected to the network and arguably it was the smartphone
which truly realised the way ""always on, always connected"" would pervade our
day to day rather than permanently connected Internet at home or work. Due to high levels of mobility whilst (mostly) maintaining network connectivity,
a passive mode smartphone can provide a large array of ambient information
that is very easy to understand with simply a glance at the device or via
auditory means as well via connected headphones (or speaker). This type of technology works best where there is a need to have information
of very low complexity available at any point in an environment that a
consumer may find themselves. This is why smartphone widgets and notifications
are currently driving this area of ambient tech. However, <b>this class of device can also encompass other, highly mobile but low
complexity means of displaying information such as bespoke, hand held sensor
devices</b>. An example would be a radiation dosimeter which shows the amount of
radiation a person has been exposed to and is highly contextual to the
individual using it and the location that they find themselves in but only
shows a very simple piece of information. Weather widget (Android) A simple glance at the screen provides current weather as well as a forecast
for five days ahead. Utilising well known cultural symbols, the weather widget
is a fixture on the home screens of most Android user's devices. Utilising the
sensors in the phone to understand location (GPS or coarse grained location
data) allows this data to be constantly updating no matter where the user is
in the world (so long as they have a working network connection to update from). Type C: Smart fixtures<br/>(Complexity:H / Mobility:L) When you combine high complexity of information with low mobility you move into
the realms of Smart Fixtures. These are devices that are fixed in their
environment - digital signage is an obvious example - but are afforded great
capability as a result. Being built into the environment generally results in
better power supply (eg mains power) and connectivity (eg wired rather than
wireless network). Reliable power, network and a largely fixed environment
affords greater options for display and processor speeds as well. Many of these devices tend to run on a more traditional PC-based architecture
rather than embedded systems as we see in other categories. In many cases, due
to the commodity nature of this hardware, the devices are drastically over
specified too. The side effect of this is that they are more capable of being
enhanced in place with additional capability over time and can also do on-site
data processing - something that is extremely difficult in memory constrained
embedded systems. The best environments for these types of systems are those where there is a
large volume of information that needs to be displayed or where there is a
large amount of change in the data being displayed. Smart fixtures are also
valuable where the data to be displayed requires a degree of precision to
convey useful information. Adaptive wayfinding Increasingly common in airports as well as shopping centres and conference
locations, adaptive wayfinding provides a means for signage to adapt to
external information. The classic example is the departure and arrivals board
at an airport or large train station. With the increasing prevalence of digital
signage in public spaces this will get more sophisticated and may eventually be
able to adapt to the individual standing in front of it. ![Flight arrivals board](../../img/posts/jeshoots-com-9qQTUYm4ss4-unsplash.jpg)
*Flight arrivals board - 
[Image jeshoots (Unsplash)](https://unsplash.com/photos/9qQTUYm4ss4)* Imagine for example, an RFID or NFC encoded boarding pass which updates the
displays in an airport as you walk near them in order to direct you to your
departure gate. No more mad dashing around unfamiliar spaces looking for that
transfer desk and subsequent flight you're almost late for. Fixed visualisations More and more buildings are starting to incorporate digital displays as part of
the material from which they are built. Whilst some are practical, such as the
ubiquitous stock price ticker you see in many financial locations, others can
be more artistic or abstract in nature. As this class of smart fixtures start to straddle traditional architecture, the
information that is visualised and the way it is presented (explicitly or more
abstract) helps contribute towards the overall feel of the environment and its
subsequent use. The team at the Rockwell Group lab are particularly adept at this as they are
constantly looking at ways to merge digital and architectural experiences. This example from a project they worked on called
[Plug in Play](https://www.labatrockwellgroup.com/plug-in-play) in San Jose uses
projection along with data fed in from a variety of social and internal sources
(eg tweets nearby or car traffic density) to help show all the data that is
being created within the community. This starts to draw a story about community
and citizenship and how people interact with the civic space it was designed for. One of my favourite versions of this was a project done out of
[Sydney University](https://design.sydney.edu.au/neighbourhood-scoreboards/)
that was extremely low tech so is not quite a ""smart fixture"" but
shows the potential for smart fixtures in our environment in the future. The
Neighbourhood Scorecards project highlighted energy usage on a series of black
boards attached to the front of some homes in Sydney. ![Neighbourhood Scorecards project](../../img/posts/neighbourhood_scoreboards.jpg)
*Neighbourhood Scorecard Project - Sydney Design Lab* The information was real though the means of updating was very manual. These
visualisations encode very complex information in an ambient manner where they
could be used to affect behaviour (those homes that had the displays decreased
their energy usage the most compared to controls who did not). Little printer This is probably one of the first Internet of Things devices that plays
directly into the Smart Fixtures category of ambient technology. Conceptually
this product makes a move beyond the ""twitter light"" style interactions
prevalent in Type A ambient technologies and forces a higher level of precision
of the content that is produced on the printer. The device itself is a [little thermal printer](https://nordprojects.co/projects/littleprinters/)
designed in a quirky body - not dissimilar to a receipt printer on a cash
register - that connects to the network and can print content supplied to it
via Berg's ""Berg Cloud"". Thus, the printer will deliver pieces of content such
as what are good things to cook, a summary of your calendar for the day or a
weather forecast (as well as a lot more by subscribing to channels) whenever
it is appropriate to do so. Arguably the true success of this product will be how many people replace the
printer roll and continue to consume the information. The interesting aspect to
this is how the device is being used to bring pieces of ambient information
into the physical world and bridge the digital back into a very tangible,
physical experience - after all you're delivered a piece of paper with real
information on it. Moreover it transcends the mobility issues by allowing a
piece of content to be removed from the physical installation and taken with
you (such as your diary snapshot) whilst the physical device remains in situ. Type D: Expert display<br/>(Complexity:H / Mobility:H) To have complex information available and have it highly mobile at the same
time as it being ambient in nature implies that it is probably Augmented
Reality or an extremely specialised mobile system (such as those used in
hospitals for patient monitoring). What I find interesting with this space is that it highlights the failings of a
lot of AR that has been made to date and I think also highlights some of the
contextual flaws that things like Google Glass may develop if left unchecked. From an AR perspective, this is really about heads up displays (HUDs) for
experts. What I mean by this is that the data is very complex and highly
environment specific. The types of applications where this type of ambient
technology will be most useful will be in military (and probably industrial)
contexts where additional complex information is overlaid with the real world
in order to support better decision making power. It is easy to imagine the military applications of this once it is reliably
mobile, lightweight and network connected. This type of display has
historically only been present in the visors of pilots who are strapped into an
aircraft equipped with sensors and jacked into a field from their command and
control systems. Arvika was exploring the use of data layered into their vision to help
mechanics when they are working on machinery (for example providing the
tolerances for components). I can envisage similar scenarios where field engineers are provided with
information by data science teams overlaid onto sites they are working on to
help them make better on-the-ground decisions. Similarly, <b>imagine surgery conducted where the surgeon could have a patient's
vitals in their peripheral field of vision</b> rather than on a machine that is
cluttering the operating theatre. Taken further, a similar system could overlay
imaging information over a patient, giving the practitioner a first person view
of what is going on within the patient they are treating. Unfortunately, this type of ambient technology is drastically less glamorous
than the Iron Man Mark VII HUD or Google Glass showing you what your friends
have just +1'ed. I think the killer use cases for this type of ambient display
will remain in industrial applications for the foreseeable future before
someone finds an appropriate consumer-oriented use case for it. Complexity of information versus actionability of data In the second part of the model we consider the actionability of information on
the Y axis. Again, the chart is repeated so you don't need to scroll back up. ![Actionability v Complexity of Information](../../img/posts/context_actionability_quadrant.png) Actionability in this case is an indicator of how well the person interpreting
the information can take action upon it if they choose to. For example an SMS
notification on a mobile phone is a highly actionable piece of data (you can
instant reply or open a dialogue to reply more fully with a single tap) but a
tube of water visualising my current inbox level has low actionability as the
data it encodes is distant from the means I use to action it (I can't read and
reply to my email via a tube of water). It's worth considering a definition of ""actionability"" for a moment because
it's a fuzzy concept. When I'm talking about actionability I'm
considering the ability of a human viewer of the system to take an action based on
the information conveyed, that is in direct response to the data presented.
There are two parts to this; the actionability as perceived by the user of the
system, and the actionability as perceived by the designer of the system.
Sometimes these can come into conflict; primarily because the designer hasn't
expressed the right context for their device - whether implicitly in their
design or explicitly by highlighting a use case. In this case when I'm talking about actionability I am suggesting the “desired”
action that can be taken either by the device itself or easily within the
environmental locale of the device. An example may be a display on your wall
telling you how many emails you have unread. <b>By itself, this device has low
actionability - there's not much you can do with that piece of data. Presented
with a computer nearby or your smartphone to hand, however, and this device has
high actionability as it can be used to prompt you to check your email and do
something about it.</b> Moreover, this same device can transition between low and
high actionability by considering the designer's intent and the way the user
ultimately uses it. Actionability makes no judgement on the complexity of the action that results
but it does assume some degree of action taken by the user. Type I: Distractions<br/>(Complexity:L / Actionability:L) Much of the ambient technology I see falls into this quadrant and this is
primarily due to the designer not having adequately considered the
actionability of the information conferred on the observer. To move out of this
quadrant, a designer needs to ask one fundamental question ""What does the user
DO with the information I am giving them?"" An acceptable answer may be ""Nothing - it's just pretty"" - at which case the
device moves out of this quadrant and becomes a Type III device. Often, as
expressed in the introduction to this part of the model, the desired action of
the designer and of the user are two different things and this causes Type II
devices to become Type I devices and become an unwanted distraction. In my experiments in this area I've been responsible for building many Type I
devices, so rather than criticising anyone else's work, I'll discuss my own as
anti-patterns. Twitter notification light I built a lot of these sorts of things when I first started playing with
networked arduinos. They allow computation to occur in one location (eg a
server) but display can be had in another. Similar examples which I won't go
into include email notification lights or some other notification that an event
has occurred which is untethered from a computer. Being untethered from a computer is important. In my research, this is what
tends to drive actionability down. In theory, having a light that displays when
you get mentioned in a tweet and illuminates without needing a computer sounds
useful. In practice it is not, it's a distraction at best and useless at worst. ![An information radiator](../../img/posts/radiator.jpg) This was probably more useful several years ago, but in the age of smartphones
that are typically less than a metre away from their owner at any point, they
are rendered useless. Location matters too, if the light is in my living room but I am in my bedroom,
the device's utility has entirely disappeared as a result of it not being
visible to me (thus no longer ambient). This goes back to the issue of mobility
discussed in the earlier sections. The worst possible combination for ambient
display is low complexity, low actionability and low mobility. This type of
device will be an occasional distraction and often completely redundant. Type II: Ambient technologies<br/>(Complexity:L / Actionability:H) Type II devices exhibit a powerful blend of having simple information
along with being highly actionable. As noted above,
the action to be taken may also be simple, however the user and designer are
aligned in what that action should be. When discovered, these types of devices become integral to the environment and
to the users of them. Their success lies in that they are “missed” when they
are no longer available to the user. <b>This should be the holy grail for
designers of ambient devices</b> and user testing can rapidly determine whether a
user feels lost when they have to give up a particular device after having it
in their environment for a period of time to habituate to it. Possibly one of the best examples of a Type II device is a clock - many people
feel as though something is missing when they no longer wear a wristwatch or
the clock on a wall is removed (or stops working). This is a fairly trivial
example, but it's that type of feeling of utility and reliance the designer
should be attempting to elicit when creating these types of devices. Blink(1) The [blink(1)](http://www.kickstarter.com/projects/thingm/blink1-the-usb-rgb-led)
is a USB device that plugs into any computer and is essentially a
scriptable USB powered RGB LED. In many ways, for a computer it is the same as
the Android notification LED mentioned above and will fill the same role. Again, high actionability comes because there will be a limited range of
information conveyed but it will be highly actionable when it is because it was
configured by the user which removes ambiguity from the display. One of my
primary use cases is that I have large data processing pipelines that take some
time to execute which occur in just one terminal window I may be using.
Historically I just switch back every once in a while to see if it has
completed. If I was being really fancy I could script an email notification but
that's just cluttering my email with messages saying “Complete” a few times a
day. In this context the Blink(1) works well because it can be triggered when the
job is complete and it will just change colour in my peripheral vision. If I'm
at my computer I no longer need to keep checking, if I'm across the room I can
see when it's done and go back if I need to. This is low complexity, high actionability at work - I can immediately use the
information to do something with it. Ambient umbrella Unfortunately no longer available (and they never worked in Australia), the
[Ambient Devices Umbrella](https://www.myambient.com/productDetail/UmbrellaSupportPage/serialPrefix/090/)
was a great example of a Type II device. The umbrella
had a radio chip and LED embedded into it which could highlight whether it was
forecast to rain at your current location that day or not. The use case was you left it somewhere you could see it (and keep it charged),
such as an umbrella stand near your door, and without looking at the forecast
you could glance at your umbrella to determine whether to take it with you that
day or not. This high actionability is the key to true ambient devices in our environment -
they allow us to glance at the information they provide and take immediate
action upon them as a result. The coupling to a device that is specialised
lends additional actionability - looking at your umbrella as you leave the
house is a natural thing one might do anyway and having a visual cue to prompt
you to take it with you drives that actionability. Type III: Ambient Art<br/>(Complexity:H / Actionability:L) Type III devices lend themselves towards interesting and beautiful pieces of
data driven ambient art. Their actionability is typically low as there's no way
to use the information provided to take action upon it directly. Instead, most
art provokes some kind of response that may be more introspective or societal
in action. For example a civic installation visualising crime locations and
volumes may inspire action by residents to take action - at the least
questioning what can be done to fix the problem. Before us is the Salesman's House This piece of generative art was commissioned as part of the Zero1 Biennele
(http://www.zero1biennial.org/) in San Jose, USA and installed in the eBay
campus there. Exploring the notion that databases will be the lasting cultural
artefact of the 21st Century, the piece blends real time data from eBay with
text extracted from a novel, each day starting with “Death of the Salesman”.
Elements from within the selected text are looked up using the eBay data,
visualising information about them historically before ultimately selecting a
new book and extracting some text and starting the cycle again. This type of ambient art is becoming more popular as a result of huge datasets
becoming available to be coupled with projection or other display media. Type IV: Command and control visualisations<br/>(Complexity:H / Actionability:H) At the extreme end of ambient technology are Type IV technologies, squarely
aimed at Command and Control based applications. The best of these are
typically envisioned in cinema (such as the battle display in the 80s film War
Games), however they are becoming much more prevalent in business. The key with Type IV displays is that they must be highly actionable otherwise
there is the risk of information overload which, in some command and control
scenarios, could even prove fatal as a critical piece of information goes
unobserved or misunderstood. In business contexts, the increasing use of tools such as Tableau
(www.tableausoftware.com) and Splunk (www.splunk.com) to bring critical
information to the eyes of decision makers (primarily through tablet use rather
than tying a consumer to a desktop application) is streamlining decision making
processes and speed at which decisions can be taken. To be truly Command and Control, technologies need to be highly specific and are
very contextual in nature. For example the C&C requirements of the traffic
management system for a major city are extremely different to that of the
commander of the rural bush fire services in Australia. A Network Operations
Centre display is another interesting example, it provides glanceability (all
systems are green) but it can also provide specificity to focus attention and
action (why is that specific server orange?). This highly contextual relevance drives many of the decisions about what to
display and how to display it for maximal effectiveness. Creating ambient technology as a function of context As illustrated above, different contexts are afforded through the combination
of mobility, actionability and complexity of information. Understanding the
forces applied by context in this way allows a designer to consider the
appropriate use of technology within this context rather than merely deploying
a piece of technology and hoping that it works (which happens a lot in the
ambient technology space). A designer's role is to explore the spaces created at the intersection of
constraints (contexts in this case) and technology and <b>there are still many
spaces to investigate given the emergence of this type of information design
and art form.</b> The examples given are by no means definitive, however they could
be considered current canonical references for deploying ambient technology in
the right way for a given context. Understanding how new technologies can enhance or disrupt the way in which
contexts drive the use of ambient technology means opportunities for new
products, displays or artworks that previously didn't exist. Avoiding the low actionability trap The worst place to be in the model is at the intersection of low actionability
and low complexity where you have created a distraction (Type I devices). As
such, how do you design your way out of this problem? Getting out means shifting one of the variables - either make the system highly
actionable or more complex. To increase actionability there are three ways to go about this. The first is
to set the correct designer and user expectations around actionability. The
second is to create a means to take action with the data and the third is to
change the data represented to something more actionable. You can also increase complexity in which case you want to consider how you
transition the display to be more artistic in nature and think about the
message you want people to take away (i.e. lean into the low actionability
nature of what you're doing). Finally, <b>there are just some data points that are very difficult to action
effectively</b> - getting @'ed on twitter is a prime example. Few interfaces are
more actionable than a twitter client on a mobile phone - which is probably
more proximate than the piece of ambient display anyway. In this case, it may
be more pertinent to think about other types of information that are also low
complexity but require less action as a result of them, or actions that are
more immediately viable given your interface restrictions. Conclusion As we rapidly proceed along the second function of Moore's Law (that a given
level of computation gets cheaper over time) we are witnessing the transition
to “computing as substrate”. Once achieved, this becomes the point where
computation becomes a material that can be used heavily in the design process,
as illustrated by
[Kuniavsky in “Smart Things”](https://www.amazon.com.au/Smart-Things-Mike-Kuniavsky/dp/0123748992).
Once computing as a substrate becomes commonplace, the amount of ambient
technology we are exposed to will accelerate rapidly bringing with it a
multitude of applications currently inconceivable. This transitional period is a defining one, as many products and designs are
not “consumer ready”. Rather than being despondent about this, a designer
should look to the areas where most traction can be had, in ambient art, C&C
systems as well as sketching with emergent technologies and ideas to explore
the other spaces. In many cases failures will occur as a result of not
correctly understanding the contributing factors to the context and how the end
result is shaped by these. However the documentation of and learning from these
failures is critical in the creation of more ambient technology and using it to
enhance our spaces - whether in the form of information rich environments, art
or simple informational knick knacks. Acknowledgements This was a long essay that took quite a lot of revision and input from
others to make possible. In the end I sat on this for a very long time due to
the amount of editing involved. To that end I would like to thank those who
gave excellent and detailed feedback,
[Mike Kuniavsky](https://www.linkedin.com/in/mikek/),
[Jessica Smith](https://www.linkedin.com/in/seniorcyberunicorn/) and 
[John Allsopp](https://www.linkedin.com/in/johnfallsopp/).
If my writing is more clear it's because of their good work - any failings in
that regard though are all mine. Notes on the model approach I've tried to express this nermous ways but
this version survived the longest. Obviously, this approach is not
expressed as a three dimensional model with three orthogonal axes - this is
because I'm unsure they are truly orthogonal. I believe that mobility and
actionability are facets of some higher function but am yet to work out what
that is though they drive different behaviours on the end results.
Possibly as we start to see more, higher level ambient devices in the
wild, this will refine my thinking on the subject further. Updates, corrections and modifications This essay was originally written in the first part of 2013, but took a long time
to pull together and went through many revisions. Due to work, life and the
curse of editing such a big piece, this document wasn't published publicly
until September 2023, a decade after it was started. Rather than let the content
rot in a google drive folder, I decided to release it, but back date
it to the time it was ""mostly"" done. More significant revisions were made in September 2023 to clarify various items,
update links to projects, and remove examples that have unfortunately disappeared
from the Internet.","['context', 'essay', 'iot', 'physical computing', 'ubicomp', 'web']","['web', 'essay', 'iot', 'ubicomp', 'physical computing']","[0.6284401383952865, 0.6018035561234013, 0.5987883487971835, 0.5823384138709304, 0.5815895866542313]",[],[],[],[],True,6
2015-04-15-make-js-robotics-launch.md,Book launch of Make: JavaScript Robotics,"['arduino', 'development', 'javascript', 'nodebots', 'nodejs', 'robotics']","Book launch of Make: JavaScript Robotics
My new contributed book, [Make: JavaScript Robotics](http://shop.oreilly.com/product/0636920031390.do)
goes on sale today after the last eight months working on it. It was absolutely
fantastic working on this project with 14 other people who pretty much represent
the core of the NodeBots community internationally. The book was curated by
[Rick Waldron](http://twitter.com/rwaldron) - the creator of
[Johnny Five](http://johnny-five.io) and had contributions from developers
all over the world with many different backgrounds but all sharing a passion
for JavaScript and hardware. It was so much fun working with the team on this project and there was a great
sense of community as all of us worked together on the build - as we all co-wrote
our chapters at the same time. The eBook and actual printed version are available now from all the usual book
stores.","['arduino', 'development', 'javascript', 'nodebots', 'nodejs', 'robotics']","['development', 'javascript', 'nodejs', 'nodebots', 'robotics']","[0.6592683984640603, 0.623929896910723, 0.6048999943881569, 0.5979399929822732, 0.5977015061158047]",[],[],[],[],True,6
2015-05-04-pebble-controlled-leds.md,Controlling networked LEDs using a smartwatch,"['development', 'hardware', 'iot', 'javascript', 'physical computing', 'ubicomp']","Controlling networked LEDs using a smartwatch
The ESP8266 has definitely become the hackers darling device, albeit with a
crazy learning curve on the tool chain. Once you get over that initial curve,
however, you can do some interesting things with the device pretty quickly. For this post, I put together a demo of some different things I had been working
on, making a strip of NeoPixel LEDs controllable via the ESP8266 using effectively
a ReSTful API. In terms of control, what better way to set your lighting mood
than to control the lights from your smartwatch - especially when you can
do it using JavaScript. I could build a simple web application that gets your latest train times or
Yelp reviews, but where’s the fun in that? Instead I’m going to pair a
Pebble with one of the other current darlings of the hacker community, the
ESP8266 WiFi module. The full post is over at Packt:
[Using your smartwatch to control networked LEDs](https://www.packtpub.com/books/content/using-your-smart-watch-control-networked-leds) If you want to dive into the code, [there's a gist](https://gist.github.com/ajfisher/ee6fadcd837a0f46be8d)","['development', 'hardware', 'iot', 'javascript', 'physical computing', 'ubicomp']","['development', 'physical computing', 'javascript', 'hardware', 'iot']","[0.6600895883731777, 0.6224772315140596, 0.6166361653121968, 0.6159020237498251, 0.6154794119744849]",[],[],[],[],True,6
2015-06-01-building-portable-minecraft-server.md,Building a portable minecraft server,"['gaming', 'physical computing']","Building a portable minecraft server
My son is pretty into minecraft - just like nearly all kids under the age of 14
at this point in time. He wanted a server that he could use to host a minecraft
world on that he and his mates could play on. Being the security conscious person I am, having some device wide open to anyone
wasn't going to fly. Instead we flipped the interaction to create a mechanism
where they could play and be physically present with each other. As a result of my robotics work there were plenty of Raspberry PIs and LiPo
batteries laying around so it was a fairly straight forward process to get it
all up and running. Minecraft is a lot of fun, especially when you play with friends. Minecraft 
servers are great but they aren’t very portable and rely on a good Internet
connection. What about if you could take your own portable server with you -
say to the park - and it will fit inside a lunchbox? The build process for this is published over at Packt
[Building a portable minecraft server for LAN parties in the park](https://www.packtpub.com/books/content/building-portable-minecraft-server-lan-parties-park) There's also [some code](https://gist.github.com/ajfisher/f61c89733340cd5351a4)
if you just want to get stuck in. ![RaspberryPi running minecraft in a lunchbox with a battery](../../img/posts/minecraft_inbox.jpg)
*Minecraft server in a box - image (CC) ajfisher* If you've got a child who has a group of friends who want to play together, this
is a nice safe way to do it where they get the benefit of collaboration along
with a device that can be more physically secured.","['gaming', 'physical computing']","['physical computing', 'gaming', 'development', 'web', 'hardware']","[0.6198818847741869, 0.589747198813881, 0.34955803074442926, 0.32396551267511736, 0.3116855616090113]","['development', 'hardware', 'web']",[],[],[],True,2
2015-08-08-ddd-jsiot-workshop.md,DDD JavaScript IoT workshop,"['arduino', 'development', 'hardware', 'iot', 'javascript', 'nodebots', 'nodejs', 'web']","DDD JavaScript IoT workshop
It seems like hardware and JavaScript has really hit a tipping point this year
with numerous workshops and nodebots events taking place all around the world.
I was invited to do a workshop as part of the [DDD Conference](http://www.dddmelbourne.com/)
this year. Given the other IoT leaning discussion sessions, I felt that instead
of building robots, we'd focus on a much more practical IoT session, getting
participants to learn some basic electronics and then build some very simple
IoT devices. The workshop presentation is below. The code used for the workshop is
[available in a github repo](https://github.com/ajfisher/jsiot-workshop). The
devices that were built were: Simple blinking an LED Gmail notifier twitter keyword blinker Weather forecast Ambient light visualisation Temperature data logger","['arduino', 'development', 'hardware', 'iot', 'javascript', 'nodebots', 'nodejs', 'web']","['development', 'web', 'javascript', 'iot', 'hardware']","[0.6807320599780119, 0.6469319612539266, 0.63402246002704, 0.6196760420315249, 0.6143878780230932]",[],[],[],[],True,8
2015-09-02-iot-mobile-practices.md,Applying the lessons of mobile dev to IoT,"['development', 'iot', 'physical computing', 'ubicomp']","Applying the lessons of mobile dev to IoT
I got the opportunity to write an opinion piece for [IBM Developer
Works](http://www.ibm.com/developerworks) on what lessons from other aspects
of technology could be applied to IoT. I drew from my own experience in mobile,
looking at: how decoupling services from avatars create more natural interaction methods assuming connectivity issues and adopting an offline first approach How the hardware & software design process unfolds as a result of interaction
refinement. This challenge is magnified when you consider the numerous contexts in which
your IoT product might be used. It might just be a sensor, but how do you
interact with it? Is it by using a mobile or web application? Is configuration
different than reporting? How usable are these interfaces? The list of
questions can seem endless. Full article at IBM Developer Works: [Best practices for IoT
development](http://www.ibm.com/developerworks/library/iot-mobile-practices-iot-success/)","['development', 'iot', 'physical computing', 'ubicomp']","['development', 'iot', 'physical computing', 'ubicomp', 'web']","[0.6535465056364764, 0.6081999920978352, 0.6047634883969216, 0.6026234070128746, 0.3334490882622506]",['web'],[],[],[],True,4
2015-09-07-js-not-just-language-of-the-web.md,JavaScript: not just the language of the web,"['conference', 'development', 'javascript', 'nodebots', 'nodejs', 'physical computing', 'presentation', 'robotics', 'ubicomp']","JavaScript: not just the language of the web
Over the last few years, JavaScript has been developing much more rapidly and
we are starting to see it move well out of the browser. Most people assume
this just means running server side as [NodeJS](http://nodejs.org) however
we're also starting to see it run in physical environments as well. Recently I was lucky enough to be invited to travel to Bangalore, India
by the wonderful people at [HasGeek](https://hasgeek.com/) to participate in
[JSFoo 15](https://jsfoo.in/2015/). This was a fantastic opportunity to talk
not just about NodeBots but how web connected hardware is where a lot of
development will be taking place over the coming decade and how web developers
in particular have useful skills to bring to bear in the hardware world. ![Drawing of robot with a heart symbol in a speech bubble](../../img/posts/robot_love.jpg)
*[""Cyber love"" - image (cc) Nani C.](http://www.flickr.com/photos/hiperbolica/3414999010)* The talk was on Droids, JavaScript & Web Connected hardware, the video is below: The full slides are available here:
[Droids, JavaScript & Web Connected Hardware](http://droidsjs.ajf.io/#/) Alongside my talk was a hardware workshop and I also wrote an article for
HasGeek detailing some of this transition we're starting to see. Over the last few years I have watched this community evolve from a group of
people sharing some code on GitHub and some pics on twitter to a truly global
movement where thousands of developers and designers have built real-world
physical things controlled with JavaScript. <b>Web developers in particular
love to make things but we tend to focus on the digital</b>. Even our language
speaks to this, where we talk about code as a ""craft"" as much as engineering
and we ""build"" a site. It's this aptitude and interest in building that is
one of the key elements in why NodeBots and JS hardware is taking off. I
have watched the satisfaction of someone who's only experience of hardware
is putting batteries into an object build a sensor that determines if the
the coffee machine is free or in use. Full article at HasGeek
[JavaScript - not just the language of the web](https://blog.hasgeek.com/2015/javascript-not-just-the-language-of-the-web/)","['conference', 'development', 'javascript', 'nodebots', 'nodejs', 'physical computing', 'presentation', 'robotics', 'ubicomp']","['development', 'javascript', 'presentation', 'nodebots', 'nodejs']","[0.6643441291581466, 0.6275974843384774, 0.6029230160692053, 0.602401459633525, 0.6022827935432171]",[],[],[],[],True,9
2015-09-09-datatium-material-for-contextually-responsive-design.md,Datatium - data as material for contextually responsive design,"['context', 'data science', 'design', 'development', 'mobile', 'responsive design', 'ux', 'web']","Datatium - data as material for contextually responsive design
A large focus of my work at JBA was UX related data science
and in particular how useful understanding of what someone is doing can be used
to create a better experience for them. Whilst most of this is oriented to
online experiences, the application of this applies to any experience really. The main aspect of this I work on (which even applies to my IoT work) is to
better understand context - how an experience can be shaped based in information
about the current context someone is in. This is immediately applicable to
our current responsive design trends as it's not sufficient to simply respond
to someone's screen size when there are night and day differences in things like
network speed for example. ![Image (cc) by CAFNR http://www.flickr.com/photos/cafnr/14267599480](../../img/posts/phone_hand.jpg) I was asked to talk about this topic at [Be Responsive](http://beresponsive.io)
to highlight how responsive design needs to move past the current fixation on
screen sizes (though we have thankfully moved on from simply pixel sizes) and
truly understand context first in order to be able to create good responsive
experiences. Large version is available at [datatium.ajf.io](https://datatium.ajf.io/) Update: JBA Digital was bought by the Ive Group and the website no longer exists.","['context', 'data science', 'design', 'development', 'mobile', 'responsive design', 'ux', 'web']","['web', 'development', 'mobile', 'design', 'responsive design']","[0.6613079967187135, 0.6599505940102687, 0.6278125798584312, 0.6103395484476682, 0.6048137234272443]",[],[],[],[],True,8
2016-01-27-road-to-interchange.md,The meandering journey of NodeBots Interchange,"['development', 'hardware', 'internet', 'iot', 'javascript', 'nodejs', 'open source', 'physical computing', 'ubicomp', 'web']","The meandering journey of NodeBots Interchange
It's been a long road, and one that has gone down some strange paths at times,
but finally node-interchange has hit v1. Node Interchange is a package and device manager for NodeBots related firmware,
however it didn't start out quite like that. This post discusses how the project
got to this point and how the tension between hardware and software drives
product development. Interchange was a project that was born out of the [Johnny-Five](http://johnny-five.io)
hack session that happened after [Robots Conf '14](http://2014.robotsconf.com/).
At this session (and prior to it) there had been a lot of discussion related to
how we provide support for new components that were not directly supported by
Firmata. In the way of some background; [Firmata](http://firmata.org/wiki/Main_Page) is
a firmware primarily designed for Arduino
that exposes a MIDI-like protocol for control of the board. In essence, Firmata
exposes an API to hardware so you can turn pins on and off, control servos, talk
to I2C devices and read the states of sensors. It's a great project, is very
mature, and is also the most common way someone will experience NodeBots for
the first time. The challenge was that in the second half of 2014, Johnny Five had moved to
IO Plugins. IO Plugins abstract the specifics of the board and the communications
transport layer away from the Johnny Five application. With an
IO plugin it became possible to easily run the same JS code against a Raspberry Pi,
BeagleBone or Arduino just by changing the IO Plugin and a bit of wiring. IO Plugins were expected to be able to implement certain low level operations such as
turn pins on and off, read and write to I2C and other basic functions. As
a result, any future extensions to the core of Firmata would create a requirement
to extend the other IO Plugins. This wasn't an ideal situation and one that created
a considerable amount of design discussion. The end point of this was to create a backpack - inspired by Adafruit
and others who had used this approach previously - which is used to provide additional
capability to an otherwise simple device. <b>The idea was to build a low cost
generic board which could have a firmware uploaded to it</b> in order to control the
component (eg a strip of NeoPixels). The backpack would then talk to the host
board using [I2C](https://en.wikipedia.org/wiki/I%C2%B2C), a protocol that just 
about all of the boards Johnny Five runs on could support. With that as the intent, going and actually building it started - a period
that took close to a year to complete off and on. Hardware backpack The initial concept was to use the cheapest microcontroller possible in order
to keep costs down. Part of the idea was that we would be in a position where
we may be able to give away backpacks at events or in kits. The main chip under
consideration was the ATTiny85 as it has USI (Universal Serial Interface) allowing
for I2C communications and is pretty cheap (sub-$1 in even small volumes). Given that the ubiquitous HCSR04 ping sensor was one of the main use cases for
building backpacks in the first place, this component was the
[first prototype of the approach.](https://gist.github.com/ajfisher/1d57c5f845c376f04fbb) ![Ultrasonic distance sensor](../../img/posts/ultrasonic.jpg)
*[Spark Core Ultrasonic Project, image(cc) Gareth Halfacree](https://www.flickr.com/photos/120586634@N05/22805671435/)* After some refinement with [Jeff Hoeffs](http://twitter.com/soundanalogous) and
[Rick Waldron](http://twitter.com/rwaldron) it became immediately apparent
that whilst the idea of the backpack was solid, using it was a nightmare. Specifically: The build process sucked - a result of Arduino's inability to properly
  deal with preprocessor directives (eg conditional includes) - meaning the end
  user had to manage included libraries and #defines in the code. Switching to avr-gcc helped resolve the technical issues but increased
  build complexity for the end user of the backpack. [INOTool](http://inotool.org/) had fragmented and became an effectively
  non-maintained project (which could have simplified the acv-gcc interaction though
  it meant a python build chain). These issues highlighted that many NodeBots end
users weren't close enough to the hardware build tools that we were familiar
with through years of use and we couldn't expect them to learn all of this just
to get a ping sensor working or have some NeoPixels to light up. Something would have
to be done to resolve this - we would have to have a documented build process
for each firmware and automate the production of binaries and ship them so end
users only needed to flash a hex file. With that approach in mind, the process continued on the hardware, taking the
other main use case - controlling NeoPixels and getting them to work with the
backpack. During this exploration, <b>it became apparent that the ATTiny chip was far too
underpowered in terms of capability</b> (IO as well as available RAM). Coupled
with no serial interface, it meant that as a developer it was a very time
consuming process to create a backpack that would work reliably. Debugging was
a huge frustration and relied on bit banging a serial interface which then
took up more RAM and IO on an already limited chip. At around this time, I was revising the [SimpleBot](https://github.com/nodebotsau/simplebot)
project for [NodeBots Day](https://github.com/nodebots/nodebotsday) and switched
to Arduino Nanos to get our project costs down and make them more accessible.
A Nano could be had for less than $2 a unit at moderate volumes. Further, Arduino
Micros (a nano without the USB interface) could be had closer to $1 per unit. ![SimpleBot - basic robot made from craft materials](../../img/posts/simplebot_basic.jpg)
*SimpleBot, image (cc) ajfisher* This started entering the price point that we were looking to achieve for the
backpack with the benefit that we would have a full serial interface for
debugging, a lot more RAM available and much more IO. As these boards
are all ATMega328p based, it means a backpack can be simulated or adapted using
any Arduino you had lying around. The decision to go this path meant a much more positive developer experience and
opened up a bunch of other software opportunities: The build process could be simplified to use the Arduino IDE Configuration could be done over USB Serial as could debugging More RAM and IO allows for more capability on the backpack With that decided, it was time to focus on the software side of the backpack
experience. Developing for developers One of the key things to come out of the initial prototyping phase was that
the build and deploy process was a disaster for anyone who wasn't familiar
with the traditional hardware development cycle. Changing code, understanding preprocessor
directives, installing libraries - these were all barriers to usability. My experience
of working with developers at numerous NodeBots events reinforced
the requirement that a backpack had to have low cognitive load. Learning a
whole new software stack just for building was a waste of time when they were
already having to learn hardware. The implication of this was fairly obvious in retrospect - keep the developer
within NodeJS and use tools she is already familliar with. This has the benefit
of minimising the cognitive load required to simply get a backpack working as well
as making it easier for future developers to contribute to the effort later. The first step of this process was producing the hex file to be flashed to the
board. [Grunt](http://gruntjs.com/) was chosen for this job due to its developer
familiarity in the JS world as well as being a mature piece of software. Arduino has some quirks around how it builds a binary and specifically it has an inability
to process sub folders to look for libraries. In the situation of both
[Node Pixel](https://github.com/ajfisher/node-pixel) and the HCRS04 ultrasonic
sensor, both a backpack and a custom firmata was required. Grunt
was great as <b>the two different core firmwares could be maintained independently but all the files
could be organised by grunt during build.</b> A secondary benefit of this approach
meant that upstream libraries like Firmata could be included using
[git submodules](https://git-scm.com/docs/git-submodule) allowing for even easier
management of C libraries in a backpack codebase. In a stroke of timing, the 1.6 release of Arduino introduced
the Arduino Command Line interface. This still required the full build of the IDE
however it meant that building bins could be scripted. The pertinent parts of the gruntfile ends up looking like this to make
it all work: [Full HCSR04 Grunt file](https://github.com/ajfisher/nodebots-hcsr04/blob/master/Gruntfile.js) With the hex files built, the only major task left was to get them onto the
board. Enter AVR Girl I'll let [Suz Hinton](http://twitter.com/noopkat) explain the
[motivations behind avr-girl](http://meow.noopkat.com/the-avrgirl-project-an-introduction/)
but suffice to say the project is brilliant and the ability to flash
boards using only JS meant complexity for interchange was simplified as a result. With the work Suz had done on avrgirl, she became a great advisor for me during the
latter parts of the Interchange development providing a valuable sounding board. At numerous
points along the way, use cases were refined as a result of the
joint work we were doing and it was great to see the NodeBots ecosystem evolve
in front of our eyes. After producing the first full end to end build and deploy to a piece
of hardware, the realisation dawned that Interchange could be used beyond
the context of backpacks and could streamline the problems with initial
Firmata install as well (many beginning NodeBots developers stumbled at the point
of the Arduino build process to get Firmata up and running). Further, in the
case of custom firmatas such as that used by
[mBot](https://github.com/Makeblock-official/mbot_nodebots) or
[Node Pixel](https://github.com/ajfisher/node-pixel), they could
be managed through the same interface as well. Interchange as package manager Suspending my other project commitments for a bit, I built towards
what was expected to be the 1.0 release. [Buzzconf](https://buzzconf.io/) was the
next NodeBots workshop and I was determined that we would not be using arduino
to flash firmware on the mBots used for that workshop. It was weird having to work on multiple parts of a stack at the same time. One
of the key features of Interchange is that you can query the board for things
like what what firmware and version is on the board and do developer friendly
things like be able to change the I2C address of a board without having to
rebuild the entire firmware. These decisions meant that Interchange had become a method of specifying your
firmware as well as a means of packaging it up and an API for interacting with it
from a management perspective too. Oh my! During this period - with a lot of testing and debugging support from Suz Hinton,
Derek Wheelden, Luis Montes and Anna Gerber - the core of Interchange got built.
This included the ability to query and install both backpack and firmata
firmwares from npm and github and support for numerous boards (thanks to avrgirl). Suz provided more board support into avrgirl and Derek
refined the command line interaction, including an interactive prompts to make
the installation process even easier. ![Interactive Interchange prompt](https://github.com/ajfisher/nodebots-interchange/raw/master/docs/assets/interchange.gif)
*Interchange interactivity example.* In the end, the deadline was met and the BuzzConf nodebots workshop went off
without any significant hitches - related to installing firmware at least. It was
immediately apparent how much faster the process was to get people up and running,
especially in the case of a custom firmata like that needed for the mBot. Version 1.0
was officially published npm and started to be used. Where next? After such an intense period on the project and nearly a year in development,
other than bug patches and questions, I've had to spend a bit of time away
from Interchange, spending some time making things light up with Node-Pixel instead. There's renewed interest in backpacks now the tools and use cases for them are being
established within the NodeBots community, so I expect more requirements will
manifest themselves. There's some syntactic sugar I want to implement with
respect to all the ways you can install binaries and there's a lot of work to
be done on the firmware ""database"" - which is currently a JSON file in the
Interchange repo. Overall I'm happy about where the project is and where it will go next.
I'm also really happy that I got to work with some great people on this project,
in particular Suz and Derek and I'm hoping to do more work with them in the future. If you want to check out more about Interchange here are some places to
dive in further: [Interchange repo](https://github.com/ajfisher/nodebots-interchange) [Raise issues here](https://github.com/ajfisher/nodebots-interchange/issues) [Interchange Gitter](https://gitter.im/ajfisher/nodebots-interchange) [Ping sensor](https://github.com/ajfisher/nodebots-hcsr04) [How to build a nodebots backpack](https://github.com/ajfisher/interchange-arduino) [Using a backpack - by Derek Wheelden](http://omit.io/2015/08/20/beginners-guide-to-backpacks/)","['development', 'hardware', 'internet', 'iot', 'javascript', 'nodejs', 'open source', 'physical computing', 'ubicomp', 'web']","['development', 'web', 'internet', 'javascript', 'iot']","[0.6772254241677386, 0.6475876799506601, 0.6223404000951774, 0.6211049874592027, 0.6144589135244302]",[],[],[],[],True,10
2016-02-11-moving-to-metalsmith.md,Making the move to metalsmith,"['development', 'internet', 'javascript', 'nodejs', 'open source', 'web']","Making the move to metalsmith
Over the last couple of months I finally bit
the bullet and migrated my blog off WordPress. WordPress served me well for a
long time, but the constant tinkering required to just keep it running wasn't
worth it and was stopping me from writing (which I enjoy). For the last few years I've found myself writing in other forms.
At work we use Google Docs for all docs and across both my books and various
open source projects, markdown is the main format used. This shift
has highlighted to me that no matter how good your CMS is (and WP isn't _terrible_)
it's always ""in the way"". Working in a mode where you can simply write is
the holy grail and no CMS really allows for this. As such, I decided to go
for a static site instead. Obviously, I'd considered other static site generators like [Jekyll](https://jekyllrb.com/)
but I really didn't fancy the Ruby learning curve. [Hyde](https://github.com/hyde/hyde)
and [Pelican](http://docs.getpelican.com/en/3.6.3/) are good options in the
python world but as I've been doing so much work in NodeJS recently, I felt that
JS was a more natural fit. [Metalsmith](http://metalsmith.io) has an interesting model in that
everything is pipelined - with the output of one function feeding
into the next. This has some quirks but eventually
becomes quite intuitive to work with and it's all javascript so suited my needs. I won't go into the getting started side of Metalsmith - there's an
[excellent series by Robin Thrift to get you going](http://www.robinthrift.com/posts/getting-to-know-metalsmith/)
and if that's not enough then [this list of resources will keep you going](https://github.com/metalsmith/awesome-metalsmith). Rather than rehash things that others have said here's a few things I wish
I'd known when I set out. The pipeline This seems obvious in retrospect, but wasn't entirely evident when I set
out when was I was wondering about how to order my plugins. At each step
in the processing chain, the input files will be the output of the
previous step. Conceptually it's like a multi-map process. This means that if you remove files from the list, they won't be available at
a later step. A good example of this is the drafts plugin - which will go through
each file in the list and remove anything with draft set in the front matter.
In this case, the plugin is removing those files from the list so they will
not be passed onwards. Likewise, if you change the contents of the file in a step, that's the content
that will be passed on. This is important when you transform markdown content
via your templates to HTML. Before transformation you're operating on markdown
content, afterwards you'll be operating on HTML. So order matters. My recommendation is to build your pipeline in steps. Start with a minimal
source and destination, then your template step and build up from there. If
you feel that the addition of a plugin is causing wackiness on your file list
then use a debug step to figure out what is happening. Something like
this defined in your index.js file will do the job: Then you can call .use(debug) in your chain before and after the plugin in question
to see what it's doing to the file list. A variation, to see how content has been changed can be
seen below. Note that outputs the first file only or you'll drown in text
from the console: Build your own plugin I held off doing this for quite a while on the basis that ""surely someone has
done this before"". The reality is that outside the core things
such as drafts, collections, layouts, markdown processing etc - the plugins
that nearly every metalsmith site uses - the reality is that the
plugin you're assessing may not have been touched in a couple of years and was
probably designed for a very specific use case. A good example of this is excerpts. It works fine for a very simple case -
find the first paragraph tag and return it. But you run into all sorts of
issues if you have an image in that paragraph as well as other boundary cases.
There was a commit in late 2015 but prior to that the previous one was early 2014.
I'd consider that unmaintained. However, if you're using markdown, it's trivially easy to
pull your own excerpt and update the post metadata if it doesn't exist. Here's
mine: Most of this code is just choosing the right file then applying the regex
I was after - in my case a line of text that ended with a new line
and started with an actual word. As markdown uses `![]()` to designate an image
it will skip right past it. For this sort of thing, it's often easier to write your own in a
couple of lines of code rather than try and grapple with someone else's use case.
And honestly, <b>I think this is the beauty of metalsmith</b> - you can create these
tiny little plugins that only do one operation on your file and makes your code
really tight. Another example of this was how I wanted to treat images. I really wanted to use
proper responsive images and `srcset` to specify different sized
images for different display types. Markdown to HTML processors can't really
deal with this and I didn't want to write all the image tags
out by hand in the markdown as that means I'm polluting my content with layout.
There's also the issue of captioning images which you can't do in CSS as the
image tag isn't a container so you can't use `::before` or `::after`. For my specific use case, I simply wrote a plugin that did what I wanted. I won't
show the code here but [you can see it in my site
gh.](https://github.com/ajfisher/ajfisher.me/blob/master/index.js#L112-L176)
It finds markdown images, pulls them out and replaces them with a properly
formatted `figure` that uses `srcset` and `figcaption`. You can see the treatment
of this below. ![Photo of a blacksmith's hands on a hammer and anvil](../../img/posts/forgehands.jpg)
*[""Blacksmithing workshop in Wojciechow, Poland"" -
image (CC) Poland MFA](https://www.flickr.com/photos/polandmfa/9286266649/)* Writing plugins is easy so definitely don't put it off as there's no magic
to it. Deployment My hosting needs are very straightforward - as the site is static I want
to use AWS S3. To get it there I need to upload all the files but there's
a few other considerations: Take hi-res images and make different sized versions for responsive images Some code changes should be applied from development to prod (eg turning on
google analytics and twitter share meta information etc) Physically put all the required files (but not the intermediate files) into
S3 with appropriate permissions. All of this is managed with a simple bash script which orchestrates the various
pieces. Images Images are resized using imagemagick-native. This is done as a separate
process from my main metalsmith pipeline as it can take quite a lot of time to
run and only needs to be done once in a while as new images are added to posts. If I add new assets that I need to preview locally I can run this component
independently to generate the required assets. In the future I'll probably move
this to AWS lambda so the images can be autoscaled when new assets are pushed to
S3. Code changes There are some things you don't want to run in dev eg switching off google
analytics code and twitter meta tags etc. There are some things you also want
to run in dev, the watch code and microserver for example. The way I deal with this is by passing a production argument into the command
line if I'm building for production. This will set a bunch of internals like
set a metadata value (so handlebars can turn content on or off) and remove
certain modules as needed. One quirk you have to deal with in scenario is that as metalsmith executes as
a chain, if you want to switch plugins off you can't conditionally call them. Here I just exploit the functional nature of javascript and do this: It's not elegant but it works, is reliable and I don't need to make
any modifications to my pipeline. File deployment Once the images are made and the site is built, it's a simple matter
to use `s3cmd` to synchronise the build directory with a bucket in AWS S3. This
bucket is set up as publicly accessible and to serve `index.html` pages as the
default document. I use the sync part of `s3cmd` rather than put as it will look up to see whether
the file has changed before pushing it - saving on bandwidth, which
may or may not be important to you (it is for me due to my usual home connection). Conclusion Overall I'm really happy with metalsmith - if you're very familar with JS and
you're looking for a static site generator then it's a good one to work with.
There isn't a huge amount of information about how to do some things but hopefully
this post will help out a little there. The entirety of ajfisher.me is [in it's own repo](https://github.com/ajfisher/ajfisher.me)
so feel free to dig around, run it up and use whatever helps in your own set up.","['development', 'internet', 'javascript', 'nodejs', 'open source', 'web']","['development', 'web', 'internet', 'javascript', 'open source']","[0.6621166469440093, 0.6440039221570684, 0.6124402352401902, 0.6010990507015593, 0.5893791825496211]",[],[],[],[],True,6
2017-08-12-embodied-bots.md,Building embodied bots with JavaScript,"['ai', 'design', 'development', 'javascript', 'presentation', 'robotics']","Building embodied bots with JavaScript
A key theme of my work over the last few years has been exploring how we, as
humans, interact with the devices and services around us—whether they are
physical or virtual. Much of what I do blends real and virtual environments,
creating experiences where these two realms intersect. More recently, we've gained the ability to do more straightforward language
processing on devices, and chat interfaces have exploded in popularity - think
Slack, Discord, or WhatsApp. This shift led me to experiment with virtual bots,
combining data or capabilities from the physical world into their design. I had the opportunity to dive into this topic at DDD Melbourne, where I hosted
a workshop. Together with participants, we built physical devices and connected
them to Slack bots. Through this process, the group began creating embodied agents - bots that could
sense and interact with their physical surroundings. These agents not only took
input from the real world but also reflected emotional responses in their
dialogue, driven by environmental cues. The slides and code from the session are embedded and linked below. Large version is available at [embodiedbots.ajf.io](https://embodiedbots.ajf.io/)","['ai', 'design', 'development', 'javascript', 'presentation', 'robotics']","['development', 'presentation', 'javascript', 'robotics', 'design']","[0.6590415592404365, 0.6194563558844791, 0.6164760120932088, 0.5983134923525215, 0.597011252843473]",[],[],[],[],True,6
2023-02-14-podcast-enterprise-ai.md,ChatGPT and Generative AI in the enterprise,"['ai', 'business', 'generative ai', 'innovation', 'podcast']","ChatGPT and Generative AI in the enterprise
I was invited to sit down with some other technology leaders for a podcast
where we discussed Generative AI and the Enterprise. Given how rapidly it has become the only thing everyone is talking about, we
started with the emergence of [ChatGPT](https://chat.openai.com/) and its use
in a business context. Very quickly we moved on to discuss the implications of Generative AI from a
regulatory perspective - especially if you work in heavily regulated industries
such as Finance or Health - as well as philosophical considerations such as
what is the value of huamn work and creativity. One of the areas we go into much more depth and is particularly applicable to
business use is the notion of Generative AI supporting specialists at the edge
of the organisation to support innovation as well as business models that may
exist in this new space. It was definitely great to be part of this discussion with other thinkers in
the space - we could have gone for many hours but managed to keep it short. The podcast was hosted by [Michaela Ferreira](https://www.linkedin.com/in/michaela-ferreira-183703249/)
and my discussion partners were [Hemil Deshmukh](https://www.linkedin.com/in/hemildeshmukh/),
[Gus Gollings](https://www.linkedin.com/in/gusgollings/) and
[David Jenkins](https://www.linkedin.com/in/davidjenkinshk/). You can listen to the full podcast on the embed below or else find it on
[SoundCloud](https://soundcloud.com/user-401188774/evo-78-chatgpt-and-generative-ai-in-the-enterprise) or
[Spotify](https://open.spotify.com/episode/0DTUCwTJnvbvpKz0RhxfNb?go=1&sp_cid=3e6861c48d329bf3ddac73deb865cab4&nd=1)","['ai', 'business', 'generative ai', 'innovation', 'podcast']","['business', 'ai', 'innovation', 'generative ai', 'podcast']","[0.6249294525031378, 0.6206071866621209, 0.5968450080251403, 0.5966547602007307, 0.5844974096438968]",[],[],[],[],True,5
2023-08-31-ai-works-now.md,AI in 2023 - it works well enough now,"['agents', 'ai', 'conference', 'generative ai']","AI in 2023 - it works well enough now
Recently, I was fortunate enough to get up to Sydney to attend the
[Web Directions AI conference](https://webdirections.com/ai) which provided a
good cross section to see where people are thinking and playing in this space now. I studied AI at Uni in both Computer Science and Psych, but then abandoned
it because one of the (many) [AI Winters](https://en.wikipedia.org/wiki/AI_winter)
set in and I was going to be unemployable. That said, I've maintained a
dedicated interest in the domain, and I have tinkered or worked with many of
the technologies that have led us to where we are today. The day itself was worthwhile – about half of the content I knew and was deeply
familiar with, but it was useful to see others explain it or how they are using
it which I find helps refine my thinking on a topic. The other half was either
new to me or was on an area I have familiarity on but is being used in a
completely new way – this stuff is great to shift the way I think about a given
topic and in particular my ideas about what use cases a particular tech is good for. Many people have asked me about my thoughts since the session and I think these
probably represent a summarised view of the day and my thinking about the area
as of August 2023. No doubt this will change again in a few months given the
pace of change. The excitement and hype are high, but different There have been some wild technology hype-cycles during the
[post-GFC](https://www.rba.gov.au/education/resources/explainers/the-global-financial-crisis.html)
period. Blockchain (and particularly Crypto, NFTs, Web3), Voice Assistants,
as well as AR/VR/XR and the various [Goggles](https://en.wikipedia.org/wiki/Quest_2)
have created an astonishing amount of noise but haven’t really delivered much
in the way of transformation. A lot of this boils down to use cases. In the context of AI, many concrete use
cases have been around for years if not decades, but the AI simply didn’t work.
By contrast, with some of the recent hype-tech we’ve seen interesting bits of
technology that have had to go searching for problems to solve (and are often
trying to solve problems that don’t materially exist) and so they land flat. Numerous speakers at the conference – particularly those who worked in research
pointed out that <b>for a very long time AI technology just didn’t work, but
suddenly, it’s become good enough to do meaningful work</b> and that’s why it’s
grabbing hold in many domains at once. A good example of this is voice and
handwriting detection. I worked on handwriting detection research in the mid-90s
using basic neural networks and it sucked – the training took forever, and the
detection rate was barely passable for someone with extremely clear printed
handwriting. It took another 20 years for that to become good enough to work
for enough people that we don’t even think about it as being cutting edge
technology anymore. Certainly, handwriting detection fails frequently as well
(especially for someone with writing as poor as mine) but for a very large
number of use cases, perfect is the enemy of the good – and good enough can
unlock vast amount of value. The current set of AI technologies are following a similar path as mobile
tech did in the 2000s-2010s. Rather than building on and enhancing what came
before it incrementally, the enhancement provided is by an order of magnitude
or greater. For example, the shift to mobile meant that computing was no longer
""something you sit at a desk"" to undertake. Instead, computing became permeated
into every aspect of our lives (for good and bad) and was as fundamental a
change as moving off mainframes to PCs. ![Mobile unblocked tremendous computing opportunities](../../img/posts/freestocks-hRVrvH9-dG0-unsplash.jpg)
*[Mobile untethered computing from desks. Photo by freestocks on
Unsplash](https://unsplash.com/photos/hRVrvH9-dG0)* By following a similar trajectory, AI is driving excitement as a result (in a
similar fashion as the move to mobile or the advent of the web for those who
bore witness to those periods). Even current AI tooling is getting good enough
to do new things, better deliver old uses or create new opportunities and
people are right to be happy about that (especially considering it’s taken
nearly 70 years of research and applied development to get to this point). The interaction model is undefined No one really has a good sense of what the AI interaction model looks like.
As humans our default interaction models are to use a tool directly (eg excel)
or to talk to a person (eg speak to a friendly data analyst). When we use tools,
in most cases a good tool (physical or virtual) gets out of the way and becomes
an extension of the wielder’s brain and hand to achieve the intended goal.
Likewise, if we are asking someone else to do some work, we say what we’d like,
have a conversation back and forth to clarify, then let them get on with using
the tools because they have expertise. AI ""tools"" as they exist right now, sit somewhere between these two
interaction models. Think of something like [ChatGPT](https://chat.openai.com/) / 
[Bard](https://bard.google.com/) or [Stable Diffusion](https://stability.ai/blog/stable-diffusion-public-release)
/ [Midjourney](https://www.midjourney.com/) and you’ve got to talk (chat) to
your tool to make it work. It doesn’t feel quite right to use. My sense is that in many cases this is why people initially try to get the
tools to do something silly (eg ""explain how a nuclear reactor works as
lyrics in a rap battle"") - because they haven’t got a strong mental model for
how this works. People clearly know they aren’t talking to a human so they
feel they need to give it instructions that they could never get a human
they know to follow. ![ChatGPT explains a reactor in the style of a rap](../../img/posts/reactor_rap_battle.png)
*ChatGPT explaining nuclear reactors, image (cc) ajfisher* The upside of this is that this means there are many opportunities for
developing what future mental models we’ll all use might look like. As a
result, this invites the opportunity for play, innovation, and research while
there’s no rules set in stone (or at least ""best practices""). The point of caution here though is that users have got a good radar for 
this already because it is so new. Because of this, it means that just
slapping ChatGPT onto your existing product will feel weird and just ""tacked on""
and customers won’t see the benefit especially if it’s in a human support role
where it can end up being dehumanising. How and where you build is up for grabs Risk was a huge topic. Many of the speakers touched on this as well as a large
number of people I talked to. With only a couple of viable players in town
(who are global) and with extremely limited Open Source options (LLAMA 2 sort
of aside) there was a lot of consideration being given to what happens if someone
goes bankrupt or faces significant legal or regulatory action (eg some of the
copyright considerations currently being levelled at OpenAI). If your business is ""all in"" on one provider to drive your product capability
then your business will be severely impacted. A lot of organisations, in their
rush to get something built, aren’t acknowledging the commercial risk they are
carrying as a result. The outtake here is that some clear-eyed members of the
business need to make their voices heard on this front so organisations are
taking a more robust approach. Aligned to this is where these models are running is important as well.
There’s wide acknowledgement that whilst having access to ChatGPT or BingChat
or Bard or whatever is quite cool, there’s inherently a stack of latency
involved which again makes those interaction models clunky. They also use a
stack of bandwidth if you’re thinking about low powered or poorly connected
devices out in the world that may want to consume these services. As a result everyone is looking to push AI to the edge. The next game in town
is really about being able to <b>push workable versions of those models down to
devices so they can run locally</b> (eg in browser) by optimising their contexts
and then remove 100% of the network latency which will make them way more
interactive and potentially offline capable. Recent advances with [LLAMA 2](https://ai.meta.com/llama/) and the ability to
run it on many targets
([including on a raspberry Pi](https://www.tomshardware.com/how-to/create-ai-chatbot-server-on-raspberry-pi) -
though infuriatingly slowly) highlight the desire to optimise for pragmatic,
""good enough"" models that can be run close to where the need is. Potentially by
sacrificing generalised models with wide capabilities for smaller, more focussed
ones we will see an upswing in the amount of AI at the edge in coming months. Everyone needs a co-pilot As part of the conference, we got to see 2 minute pitches from 20 businesses
in Sydney that were building products with AI. At one level it was great to
see a thriving start-up ecosystem in place in an Australian city but it
highlighted that a lot of people were building on top of a couple of AI APIs
and calling that a product (see many of the points above about the dangers of this). What was very evident from the pitches, as well as numerous examples given
by the speakers, is that there’s a huge amount of activity happening around co-pilots. This seems like it’s being driven by the unlock of
[LLMs](https://en.wikipedia.org/wiki/Large_language_model) - which have got quite
good in a general sense and can be fine-tuned with domain specific information
to focus their attention (and minimise hallucination). This is really speaking
to commercial models that are considering ""cost savings"" as a motivator though
it’s less about cutting jobs and more about being able to scale the ones you
have by making them more effective or eliminating less valuable effort for a
given individual. ![Github co-pilot is the model](../../img/posts/ai_copilot.png) The key with a lot of these products is going to be their interaction model and
how quickly you can get them to do the work. If I have to spend 30 minutes
crafting a prompt to save myself 40 minutes of work, arguably I could probably
just do the work and keep my brain on-task. Obviously we’ve seen [GitHub’s co-pilot](https://github.com/features/copilot)
in action for a while now and they seem
to have done a lot of good work thinking about how this tool sits alongside
the existing developer experience (if you use VS Code at least). How this
manifests in other domains and isn’t just an enhanced Clippy remains to be seen. There’s a lot more to come We’re seeing things now that have been struggling to get out of labs for over
20 years and they are just now good enough to do so. In achieving these
successes – particularly regarding GPU training and model execution on
devices – this has generated a lot of learning that will now be applied to
other domains. I don’t envisage this being a case of every problem will be solved by an LLM
or Stable Diffusion approach, but <b>the practical learning that has arisen from
these techniques can be taken and refine other tools</b> that we’ll be able to put
in our collective arsenal to solve an ever-widening set of problems. One area I haven’t really touched on in this post is the issue of ethics and
equity as it relates to AI. This was a topic that kept being touched on, however
it is evident that the need for more conversations about these aspects is
crucial if we want this technology to be used in ways that eliminate or
minimise harm. The technology is racing ahead however, regardless of the
ethical or equity considerations which for me is alarming. Overall, I’m glad I was able to get up to Sydney to attend the conference as
it was good to see a lot of thinking in one place and at a moment in time to
see where this all heads next.","['agents', 'ai', 'conference', 'generative ai']","['ai', 'generative ai', 'conference', 'agents', 'development']","[0.6162365519420198, 0.5872881491621578, 0.581613351738307, 0.5749584488866017, 0.3243349932175174]",['development'],[],[],[],True,4
2024-04-16-now-or-never-growth-opportunities-in-retail.md,Now or never: harnessing growth opportunities in retail,"['ai', 'business', 'growth', 'retail', 'strategy']","Now or never: harnessing growth opportunities in retail
If you’re not part of Big-Tech, Big-Finance, or Australia’s [Grocery
Duopoly](https://www.abc.net.au/news/2024-02-23/a-history-of-the-duopoly-coles-woolworths/103494070),
your business is likely navigating significant challenges. Investment in
additional headcount, new systems, or process is probably quite a way down your
list of priorities - behind a lot of optimisation, and just trading through the
rough patch. However, for growth-minded orgs with some financial
flexibility, there is an opportunity to acquire experienced talent to drive the
next wave of growth and innovation for the business. The COVID-19 pandemic forced a rapid acceleration in digital transformation,
prompting businesses to launch many initiatives. Yet, facing economic pressures
as consumers become more discretionary in their purchasing, many have since
scaled back - delaying or descoping these projects. ![Empty store for let](../../img/posts/the-blowup-0EQJEuCO9JA-unsplash.jpg)
*[Retail spaces have struggled to recover. Photo by the blowup on
Unsplash](https://unsplash.com/photos/a-black-and-white-photo-of-a-sign-on-the-floor-0EQJEuCO9JA)* While Big Tech and Finance have been the main beneficiaries of what growth has
happened in the last five years (eg [the Magnificent
Seven](https://www.linkedin.com/pulse/seven-samurai-mag-markets-rescue-aswath-damodaran-eu9mc/)),
they, and others, are now generating layoffs - about 50,000 people in the first
two months of 2024 so far. As we emerge from the bottom of the business
cycle, there is an opportunity for savvy Retail and Consumer organisations to
benefit. If your business is profitable, but faces cyclical challenges, such as Retail -
right now you are able to pick up some extraordinary talent.
Point them at your hardest business problems to get the groundwork
done, and you can capitalise as consumer sentiment improves and spending
increases again. For the purposes of this post, I’m mostly considering Retail, Consumer Products
and Services businesses as these are domains I know very well. Over the last six
to nine months I have had many conversations with leaders in these sectors that
have influenced my thinking on this topic. I'll outline some of the challenges businesses have had to
navigate over the last couple of years, why tech firms are laying off staff, and
what the opportunity is for organisations who can capitalise on it. Consumer businesses - between a rock and a hard place Even though COVID-19 dramatically impacted recent business performance, the
challenges began earlier. 2018 and 2019 already posed significant difficulties
for many organisations due to a decade of rising living costs and stagnant wages
after the Great Recession, compounded by global events like France's [Mouvement
des gilets jaunes](https://en.wikipedia.org/wiki/Yellow_vests_protests), Hong
Kong's [Water
Revolution](https://en.wikipedia.org/wiki/2019%E2%80%932020_Hong_Kong_protests),
and Australia's [Black
Summer](https://en.wikipedia.org/wiki/2019%E2%80%9320_Australian_bushfire_season). ![Hong Kong protests, 2019](../../img/posts/joseph-chan-I23WeOTsA8M-unsplash.jpg)
*[Over 1M people protested in Hong Kong in 2019. Photo by Joseph Chan on
Unsplash](https://unsplash.com/photos/aerial-photography-of-four-cars-surrounded-with-people-I23WeOTsA8M)* I highlight this pre-pandemic period because trying to hire into retail
businesses was already challenging. Businesses didn’t have a lot of spare cash
to invest in more headcount and candidates were scarce. This was because
Finance and Big Tech were well into their run up, as they started to
capitalise on technology advances to do with new architectural patterns (eg
[micro-services](https://microservices.io/) and composable architecture) and the
first shoots of AI and ML technologies showing benefits (eg voice, NLP,
classifiers etc). The implications of this was that in consumer businesses, that weren't digital
pure-plays, projects were already falling behind and teams had persistent
vacancies that were challenging to fill. Some outsourcing occurred to keep
projects moving, but this is not sustainable long term due to the cost. By March 2020, every consumer business in the world was facing the choice of
willingly or begrudgingly expediting their entire digital transformation, or
face almost certain collapse as a result of physical retail closing overnight.
At the same time, Big-Tech saw a rapid increase in sales due to vast numbers of
the population spending more time on screen and in their houses. The net effect was that Big-Tech and, to a lesser extent Finance, found
themselves in a position where they had money coming in at unprecedented rates
and were able to attract significant amounts of talent with high wages, who
could work from anywhere remotely and continue to drive their digital business
growth. On the flip-side, consumer businesses were faced with the impossible
task of completing two to five years of work in six months with increasing
uncertainty around their jobs. Consumer <b>organisations that managed to stay afloat faced stiff competition for
talent</b>, often being outbid by tech giants like Google, Meta, and Amazon, where
even junior roles commanded salary premiums of 40-90%, not to mention superior
benefits. Vacancies continued to grow. After COVID there has been a significant decrease in consumer sentiment and
spending and consumer businesses have found themselves in a precarious
position - grappling with significant revenue challenges lacking the willingness
to invest in headcount or expensive projects. Throughout 2023 and into 2024,
many organisations have faced into extreme prioritisation, scaling back
initiatives and managing costs ever-more aggressively - a necessary, but
short-sighted strategy, given the long-term potential of these projects. In 2024, from my conversations and interactions with numerous organisations,
this has become the dominant behaviour for many direct to consumer businesses.
Deliver core business well, drive profitability and, focus on a smaller number
of high-value opportunities. This all poses a question: After an astonishing boom and the sustained
dominance of Big Tech and Finance over the last half-decade, why are we now
seeing continued layoffs in these sectors? This shift is not just a market
correction for some COVID-19 over-hiring, but a signal of deeper changes afoot. These shifts could be a golden opportunity in the next business cycle. Inside out - tech’s first target is itself It's well-known that new technologies can displace workers, typically those in
lower-skilled roles, however the technology industry often focusses on itself
first, automating its operations and optimising internally before seeking to
impact other sectors. This internal focus stems primarily from an ongoing war for talent coupled with
a relentless drive for profitability. Technology sectors have historically grappled with a persistent shortage of
skilled workers. The demands on even entry-level technology professionals have
escalated significantly over the past two decades, intensifying the challenge.
Each year, the industry's demand for talent consistently exceeds the supply of
new graduates, a trend that shows no signs of abating and [looks to be getting
worse](https://www.gartner.com/en/newsroom/press-releases/2021-09-13-gartner-survey-reveals-talent-shortages-as-biggest-barrier-to-emerging-technologies-adoption). Given this persistent context, for technology-led businesses a long-term
beneficial strategy has been to invest heavily in automation to free up talent
to work on more difficult problems. This allows you to scale by removing
bottlenecks (instead of Jane being the only person who can do a task, now
everyone in the team can leverage Jane’s automations and she can move on to the
next hard problem) and it can drive profitability (I can have my team working on
more innovation or higher value work that I can charge more for rather than
routine work which quickly becomes devalued). ![Working to digitise processes](../../img/posts/scott-graham-5fNmWej4tAA-unsplash.jpg)
*[Photo by Scott Graham on
Unsplash](https://unsplash.com/photos/person-holding-pencil-near-laptop-computer-5fNmWej4tAA)* No part of technology has been spared from this effect. The virtualisation of computers spurred rapid advancements in automation,
streamlining the management of virtual machines and networking. This evolution
catalysed the growth of cloud-based infrastructure, which in turn facilitated
more sophisticated applications and data management strategies. These
technologies laid the groundwork for the development of complex machine learning
pipelines and on-demand AI models, further reducing the need for extensive human
intervention. Despite an exponential increase in applications driven by these technologies and
rising consumer demand, the workforce has not expanded at the same rate.
Automation enables existing professionals to manage larger technology ecosystems
more efficiently, thereby enhancing business value and profitability. In recent years, AI's viability has surged. <b>Before ChatGPT made headlines in
late 2022, tech organisations were already leveraging early tools to automate</b>
code generation, content validation, natural language tasks, and data analysis,
significantly easing the burden on overstretched teams. As more sophisticated AI tools landed, this has been like pouring petrol on the
fire of automation. With cultures of innovation, optimisation and automation entrenched in most tech
organisations, these tools have enabled even more rapid development and more
value creation. Given all of this, why would tech companies be laying people off? Surely they
are better retained in the organisation? In late 2022, the main factor was cost rationalisation. The boom that many tech
companies had experienced was COVID related and those gains began to reverse.
Many organisations decided to downsize for what looked like a recession and get
ahead of that. In 2023, for many markets, this recession didn’t occur, however
business conditions were more challenging and those businesses that shrank their
workforces were considerably more profitable (eg Meta, Microsoft and Amazon). Recently, additional layoffs have occurred that are smaller in total size,
however much more broadly based. Here too, businesses are rationalising their
cost base to show higher margins and profitability to the market (the days of
“burn baby burn” when it comes to cash with few profits are definitely behind
us) however they aren’t doing away with whole teams. Rather, as various AI and
automation tools are becoming effective they are taking a small chunk out of
many jobs so instead of a team of 10 to do the work, this may be rationalised to
a team of 9 instead. Hiring has much reduced from the heady days of 2020-2021 as
well, with fewer roles advertised - particularly for entry positions. ![An iPhone with many AI apps installed](../../img/posts/solen-feyissa-hWSNT_Pp4x4-unsplash.jpg)
*[AI tooling for teams has multiplied rapidly. Photo by Solen Feyissa on
Unsplash](https://unsplash.com/photos/a-person-holding-a-cell-phone-in-their-hand-hWSNT_Pp4x4)* When you look at the output however, you see the full picture - these slightly
smaller teams are delivering the same output (or more in the case of Meta in
particular). This is improving their margins and profit - so the rationale for
downsizing the workforce is well founded. A lot of this isn’t purely AI related, it’s the combination of opportunities
brought about by cloud technologies, automation and AI that have taken time to
pull together, however it is supercharging the productivity of teams. These factors occurring concurrently provide opportunities for those
businesses - particularly Retail - who are prepared to Zig while everyone else
continues to Zag. All of this means that there's an opportunity take advantage of to get ahead
while your competitors are still putting on their running shoes. Tech layoffs may be retail payoffs The persistent challenges in the consumer non-tech sector have squeezed
capabilities and hindered the delivery of transformational changes within
organisations. Meanwhile, technology-led organisations have created
disproportionate value by leveraging automation, AI, and data, relative to the
size of their teams. What should retail and consumer businesses do as digital sophistication rapidly
increases but funding for innovation remains scarce? Quite simply, you need to invest smartly but you need to go now - and I mean
right now - 2025 will be too late. Consumer and Retail businesses should grab the opportunity to strategically
hire experts in Architecture, Data, AI, and Automation. <b>Complementing these
strategic hires with eager juniors currently struggling to find roles can
maximise impact</b>. Start by hiring experienced team members who have direct, first hand experience
in: Architecting large, distributed applications and enterprise technology with
composability at its core and micro-services throughout. Data engineering to extract valuable data from the organisation and make it
available to  products and services. Pragmatic AI capabilities whether in using off the shelf models for enhancing
existing products or refining processes or leveraging AI-based tooling that
can improve productivity (eg engineers with AI-copilot or AI-DevOps
experience) Automation engineers who can help remove tasks from existing digital and
business teams and create opportunities for those staff to work on higher
value activities. To scale and innovate effectively, integrate enthusiastic early-career
professionals into your team, supporting them with AI copilot tools and DevOps
practices. This approach allows juniors to rapidly assume significant roles,
driving forward your transformation goals. This addresses the hiring side, with a view of seeding these skills into the
team. Alongside that needs to be a clear strategy that leveraging automation,
utilising AI-based tooling and copilots, and use of low or no-code solutions or
frameworks to achieve outcomes is critical to the ability of the organisation to
execute and scale efficiently. This focus on methods, and the change management required to support that in
existing teams, should help to start to create momentum inside the organisation
to deliver at a higher cadence. Simultaneously, <b>businesses must adapt by adopting AI copilots and adjacent
technologies</b> to automate processes, enhance classification, support services,
and improve customer experiences. Done right, this will help free up valuable time from over stretched staff who
can work on projects that further transformation, work on supporting higher
value customers, or helping expansion into new channels or markets. Additionally, the business should invest in low or no-code application platforms
and extensively train business users in their use. Many of the market leading
tools already leverage automation and AI capabilities for rapid delivery.
Layered onto a composable architecture and a well understood integration
ecosystem, business users can rapidly automate business processes, create
micro-applications to service their needs, and deliver rapid change themselves.
This will free up key technology resources to invest in innovation or high-value
platform creation. ![An image with the word change](../../img/posts/nick-fewings-5RjdYvDRNpA-unsplash.jpg)
*[Create opportunities for organisational changes. Photo by Nick Fewings on
Unsplash](https://unsplash.com/photos/a-black-and-white-photo-of-the-word-change-5RjdYvDRNpA)* This appraoch carries numerous benefits, however it also carries inherent
risks that must be managed to ensure successful outcomes. Before
going on this journey, here are some elements to think about: Prioritise architecture and full-stack engineering if your organisation lacks
architectural maturity such as insufficient micro-services or integration
layers. This foundational work is critical in supporting the approaches
discussed above. Implement clear guidelines for AI copilot usage, focusing on data safeguards
and team responsibilities to prevent inadvertent data leaks. Proper training
and governance are essential in ensuring safe and effective use. Support junior team members with robust mentoring and onboarding programmes to
integrate into their teams. Strong cultural processes are essential for their
success and their future growth in the organisation. Ensure the accurate assessment of capabilities in prospective candidates by
possibly engaging an external 'Advisory CTO' or similar expert for advanced
domains. This expertise is vital for recruiting senior roles, who can then
assist in onboarding more junior team members. Retail and consumer organisations, whilst they start behind, have a golden
opportunity to bring to bear a number of significant trends coupled with a
specific set of people who can drive innovation and opportunity for the
business. In case of emergency, break glass The convergence of available talent, cutting-edge tech, and urgent demand for
innovation presents a unique opportunity for retail and consumer
businesses. Capitalise on this by strategically hiring experts in
architecture, data, AI, and automation, and support them with eager,
early-career professionals. This combination will build a resilient,
forward-thinking team ready for rapid innovation and deployment. Act now. The talent is available, but won't remain so indefinitely, and
competitors may also be eyeing this advantage. New technologies provide an
opportunity for generational leap-frogging that will help you quickly create new
opportunities for profit or elevate your customer experience. Don’t hesitate;
those who act decisively have an incredible opportunity at their feet. Imagine a future where your business not only survives but thrives, leading a
rapidly evolving retail landscape. By going now, you're not just adapting;
you'll be setting the pace for innovation and success in retail.","['ai', 'business', 'growth', 'retail', 'strategy']","['business', 'ai', 'strategy', 'growth', 'retail']","[0.6388968739767741, 0.6167836782693428, 0.6000872446067863, 0.5997638122805666, 0.587478170423001]",[],[],[],[],True,5
2024-06-19-follow-me-i-think-i-know-what-im-doing.md,Follow me. I know what I'm doing... (I think),"['business', 'conference', 'growth', 'presentation', 'strategy']","Follow me. I know what I'm doing... (I think)
This week I had the privelege of [opening the leadership
track](https://www.webdirections.org/leaders24/speakers/andrew-fisher.php)
at [Web Directions Code](https://www.webdirections.org/leaders24/) with a talk
about how no one prepares you for stepping up from being a practice based leader
to a more general leader in the C-Suite. This drew on my own experience of having been in senior engineering roles for
an extended period of time, but when moving to an enterprise ""Chief"" role,
reporting to the CEO, I found there were a lot of knowledge gaps. The slides from the talk are embedded below, and the full transcript of the
talk with key slides is presented after that. A large version is available at [wdcl2024.ajf.io](https://wdcl2024.ajf.io/)
and a PDF of the slides, with notes [are available here for download (PDF
60MB)](https://wdcl2024.ajf.io/static/follow_me_talk.pdf). The full talk transcript follows: Where are we? We're all leaders here, and maybe a few soon to be leaders as well. So I want
to get a quick sense of where everyone is on their leadership journey. A quick
show of hands. ![A sketch of a map for a journey](../../img/posts/presentations/wdcl2024/map2.webp)
*All our journeys are different. (cc) ajfisher - Dall.E* Who has reports that are individual contibutors? Okay what about people who have 2 layers of reports? Anyone have bigger teams, maybe with 3 or more layers reporting into you? Okay, so we're mostly leaders who have ICs reporting into us. Now I want you to close your eyes... Imagine your team meeting Imagine, right now, you're standing in front of your team during a team meeting.
But, I want you to imagine that team is two levels up from where you report
right now. You're now also leading teams that aren't part of your
direct experience. Maybe you're looking after design or marketing for example. ![A female leader stands in front of her extended
team](../../img/posts/presentations/wdcl2024/large-team-perspective.webp)
*Everyone is looking to you for direction. (cc) ajfisher - Dall.E* Everyone is looking at you. They are expecting you to give them the direction and priorities for the next
quarter and your vision for where the team and the org is headed. Do you know what you'd say? There's probably a few of you in here thinking, ""Yes! Finally I have the power
to change all of the things that are wrong in this place!"". Some of you might be thinking, ""There's no way you can pay me enough to do that
job."" Wherever you fall, if you're serious about leadership as part of your career -
and I think all of you are by being here today - there will come a point where
your experience as a tech leader will be less valuable than your more general
management skills. New types of challenges I got an opportunity to take that step several years ago and honestly, even with
extensive leadership experience for more than a decade, I wasn't prepared. The gaps quickly became apparent and I realised this was going to be a steep
learning curve. In retrospect, it was the most difficult role transition I've
had since becoming a tech lead originally. ![A mountain climber ascends a perilous mountain](../../img/posts/presentations/wdcl2024/climber.webp)
*The learning curve is steep. (cc) ajfisher - Dall.E* Today, I want to talk to you about some of the gaps you're likely to have
coming out of practice leadership. But also give you some of the areas you can start
to develop, regardless of what stage you are in your career. The great news is
that management and leadership are skills, like any other - so you can develop
them if you work on them. Agenda Today we're going to focus on these three areas: Business strategy and drivers - Developing an understanding of the business
 strategy and organisational drivers. Communications and relationships - Look at ways to communicate as a leader
 and how to build relationships to supercharge your impact. And; People and team design - Give you some ways to think about your people, and
 team design. Let's dive in. Strategy and drivers We'll start by looking at the strategy and drivers and building that understanding
as well as getting to know your customers. I'm not going to touch on the real mechanical stuff like building a
business investment case or risk management etc. This is all pretty important,
but there are heaps of good examples out there for this. I suspect some of you
are probably feeding into or buiding these already. Understanding the strategy Let start at the top. When a business has a clear, well articulated strategy, everything just flows
outwards from that. When everyone is aligned to it, the organisation becomes
effortless. ![Blueprint of fictitious product](../../img/posts/presentations/wdcl2024/solarpunk-product.webp)
*A clear blueprint allows everyone to work together. (cc) ajfisher - Dall.E* At its heart, strategy is as much about what you are NOT doing as much as what
you are. Be clear about the goals However, if your strategy is not clear, or well understood, then everything
that follows will be out of alignment and compound in terms of error. ![Buildings misaligned](../../img/posts/presentations/wdcl2024/misaligned-buildings.webp)
*Miscommunication compounds in effects over scale. (cc) ajfisher - Dall.E* As a leader, one of your main jobs is to be very clear about the
immediate and wider goals. You want to start getting comfortable with asking
questions - especially about getting clear about what problem the team is solving
for. Focus on the why For example - in your next planning meeting ask lots of questions
that are less about the ""what"" and focus in on ""why"" this is important to your
customers or strategy and ""how"" what you're planning is joining up to the
organisational strategy. This will help you uncover the intent and anchor your
approach to maximise impact. Organisational drivers Now, alongside our business strategy which sets out our goals, are the business
drivers. Business drivers come down mostly to what are the main ways the org
makes or spends money. ![Factory making goods](../../img/posts/presentations/wdcl2024/factory.webp)
*Drivers allow the business to scale effectively. (cc) ajfisher - Dall.E* It really is as simple as this: Money in - Money out = Profit Where the complexity comes in, is how you go about doing that in your particular
organisation. But if you can understand how the core business functions, then
you can start to understand where you can focus to drive impact. Drivers scale your impact For example, if I'm a retailer and 10% of my sales come from online and the rest
from physical stores, there's a couple of ways to determine activities that
would create biggest impact. ![A home setting with a delivery man handing a box to a customer](../../img/posts/presentations/wdcl2024/ecommerce-interaction2.webp)
*Different channels have different impact. (cc) ajfisher - Dall.E* If I grow online whout sacraficing any physical store sales, I've just added
to top line revenue- so I've improved my money in. If, I can optimise something in my physical stores that touches every
sale, I can make 90% of my sales more efficient- so I've affected my money out. But, if I optimise something in my online channel, the mose I can impact is
10% of my total revenue. That might be more questionable in terms of importance. ![A retail setting with a staff member handing a bag to a customer](../../img/posts/presentations/wdcl2024/retail-interaction.webp)
*Optimise the right thing for maximum impact. (cc) ajfisher - Dall.E* When you understand how your business works, you can quickly determine whether
a strategy you're considering is a good idea or not to pursue. Know your customers Alongside our strategy and our drivers, we then have our customers. Hands up. Who has had a direct interaction with one of your end customers during
the month of June? Hands down if you're a consultant? As a leader, you need to know your customers first hand. You need to listen to
them and walk in their shoes. Evaluate impact Building this understanding means you're able to bring first hand intelligence
back to your team. It means you can validate approaches for things you are
planning and see the impact of the initiatives you're doing. ![A retail worker conducts a survey with a
customer](../../img/posts/presentations/wdcl2024/customer-survey.webp)
*Learn everything you can about your customers. (cc) ajfisher - Dall.E* Go ask your customer or marketing teams for their customer reports and dig in.
It's all too easy for us to sit in HQ and not iteract directly. But, if you talk to your customers, you start to appreciate the organisation's
drivers in action and see how your strategy is working. Get started: So here are some thing you can do right now to practice this: Organise a 1 on 1, 2 levels up from where you report to find out more about the
strategy Go talk to your finance team or channel leaders and really deep dive the drivers Next week, I want you all in the field having conversations with your direct
customers. We've covered strategy and drivers, now we're going to turn our attention
to communications and relationships to maximise our impact. Communications and relationships All of you will have seen how much impact both good and bad comms can have. Who here has ever said something to your team that was a bit loose and it's
been totally misunderstood as to your intent? Yep - we've all done it at some
point. When you get it right, good communications has a lasting impact across your
team and org. ![A leader speaks with her team](../../img/posts/presentations/wdcl2024/team-discussion.webp)
*Communications and relationships are a superpower. (cc) ajfisher - Dall.E* Alongside our comms, we also need to build relationships. Creating good relationships allows you to create impact across a much wider
span in your organisation. Now, developing both of these skills requires no particular
authority or seniority to work on them practically. We're going to touch on both communications and relationships. But lets talk about communications first. Communications Obviously, we want to be striving for clarity so we can get our message
across. With a good team, your goal is to give them as much great information as possible
so they can get on and do what's needed. There's a couple of techniques I find help with this. The first is focussed on asking lots of questions even if the question seems
stupid or obvious. Often as a leader, you CAN be the person who asks the unaskable
and you give permission to others to do the same. This allows us to uncover
assumptions quickly. Gather perspectives The other technique is when you're working on solutions and providing perspectives
in a group. You need to be mindful about your voice carrying more weight than
others as you get more senior. You can't avoid this happening. ![A leader consults with her team](../../img/posts/presentations/wdcl2024/perspectives.webp)
*Ask for the team's thoughts first so you don't bias their thinking.
(cc) ajfisher - Dall.E* To balance this, make sure you are the last person to state your thoughts. You
can be direct about that, ""I want to hear all of you first"", or just steer the
conversation that way. This will give you more diverse perspectives which may
inform your position further but additionally, it will also mean you don't tip
the scales towards your opinion and have some of the group just agree with you. Remember, your job isn't necessarily to have the answer - it's to facilitate
getting to that answer. Often, you're the one who takes accountability for
the decision of the team too. Relationships Now let's turn our attention to relationships - a skill area I think is a super
power in many organisations if you invest in it. Great leaders build a vast network of relationships across all levels and
functions of the organisation. Build understanding To start, this gives you valuable intelligence: What are the pain points that team has? Maybe we can help.
How is that project going? Their delay might impact our initiative. Mostly, this is about listening and asking questions of people in the org. But once you have a wide set of relationships you can also facilitate connections. Connect For example, if you're having a convesation with Alex and they have talked about
a pain point they are experiencing but you know Jo had to deal with something
similar, you can bring them together to collaborate on a shared objective. Now, how do we do this intentionally? Relationship mapping One way is to build a relationship map. If you're in a product squad you
have probably seen one of these already. It's a stakeholder map but for you. ![A network diagram of relationships](../../img/posts/presentations/wdcl2024/relationship-network.webp)
*Optionally do this with photos and pieces of red string
(cc) ajfisher - Dall.E* You're trying to understand who you should be spending time with across
your org to understand what is going on? Who do you need to spend time with
to get things done or unblock things? And who do you know is going to need time
so you can bring them on the journey for your projects as you're delivering. As you do this, don't forget externals. Make sure you include partners, key
customes or other parties in this map as well. With your map in hand, it's then about spending time with these people to
engage and listen. When you get a new role, this is really easy - you just reach out to all of your
predecessors contacts and ask to chat to them about how your team is doing, what's
good and bad etc. But even without doing that you can just reach out to people. People like it when you show a genuine interest to understand their area and how
you might work better together. Get started: Your homework, is to start building out your relationshhip map and by the end
of today, I want all of you to dash off a note to schedule time with someone
in your org you don't know very well. So now we've talked about communications and building relationships, let's turn
our attention to people and team design. People and team design When you lead bigger, and more multidisciplinary teams, success lies in the
agency of others. As a leader you generally get the opportunity to determine your people and the
ways your team work together. To that end, we're going to look at: What capabilities do we need? Direct team structure. Ways of working. Let's start by thinking about the makeup of your team and specifically your
immediate reports. Team skills It goes without saying that this team should be as diverse as you can make it to
get the best mix of viewpoints and drive better outcomes. That's a whole other talk
that others have done very well - you should conffab it. ![A balanced D&D party](../../img/posts/presentations/wdcl2024/party-capabilities.webp)
*A balanced party gets the treasure (cc) ajfisher - Dall.E* For your team, the things you want to think about are what do YOU do in the team
and what are *your* capabilities? And, what are each of your *reports* doing
and what are *their* capabilities so you're all playing to your strengths? This sounds obvious right? But I see teams not be clear about this and so they
aren't then clear about who is doing what. Building a capability model The way I think about this is by using a capability model. Start by breaking down all of the key capabilities the team needs to be good
at to be successful against our mission. With this, you need to overlay the areas that you are good at and what you are
bad at to help drive the structure. Team structure Start with the ""what are you bad at"" items and focus on that first. The way to address your gaps is by using the expertise of your directs to fill it. The person to fill this main gap should be someone that has extensive credibility
in the capability and should also be senior enough to be obviously your second
in command for the team. You need to delegate to this person, empower them and set them up to be the go
to expert in their domain. This is a role that can help scale your team's
communications and influence outcomes because now the two of you can be in
different places at the same time with a cohesive message. Team structure Now I want you to think about which area are you most strong at. Whatever that is, you need a capable person to step in and you need to step
away. Completely step away. How many times have you seen a leader spending too much time in the area they
know really well and being disruptive, whilst the others go begging. Don't be a meddler in your team. AS you know this area well, you also know what great looks like. So you should
be able to identity a fantastic candidate for this role, who can do it at least
as well as you can. Then delegate it out and have a great person look after it. Team structure Now, the other roles in your portfolio are where you can mix it up a bit. This is
where you can give people opportunities to step up, bring in a junior person or
give someone the opportunity to X-skill. This is where the capability model helps because you can be clear about what the
needs are and what is the best way to fill them. These roles are where you can spend a bit more time as a leader, growing the
capability of the team, knowing the other areas will be dealt with so well. Here you
can support on strategy or delivery as well as coaching and mentoring those
team members. You should encourage your other heavy hitters to be doing peer
based leadership and mentoring as well. Ways of working Once you have your team and how the structure will work, you should think about
how you're all going to work together. This is primarily about how are we going to
share information and who has authortity in different scenarios. ![A team works together on a whiteboard](../../img/posts/presentations/wdcl2024/workshop.webp)
*Who holds the pen and why? (cc) ajfisher - Dall.E* Being clear about this stuff as a team means no one is dancing around
afraid to step on each others toes. It also means the team are well informed
and helps empower them to just get on and get things done - knowing they have
backup. Your role as the leader in this is to facilitate the discussion and help surface
assumptions about implied responsibilities or capability gaps so that all comes
out on the table. Ways of working Many squads have a form of this using a team canvas or social contract. Use
whatever works for you and your team or what you're familiar with. The key is to be having the discussion as a team and being clear about how you
want to work together and who is doing what. Get started: So the obvious things to do here are to build out your capability model and
have a session together working on this stuff as a team. Now we've our team is organised and we know how to work together, lets
bring this all home and give you some resources. Things to consider ![A woman sits in a chair with a notebook
contemplating](../../img/posts/presentations/wdcl2024/contemplation.webp)
*Think about the things you can do to grow. (cc) ajfisher - Dall.E* As I wrap up, besides the homework I gave you, I want to leave you with a few
things to have a think about too. Train yourself Are there courses that are appropriate for you to go on? Does my business offer
leadership or management training? Can I get some training subsidised by work
or other programs? Get yourself a mentor. Do you know someone in the organisation who you think
is a great leader and you relate to their style or background? Are there people
externally who might be a good fit for you? With mentoring, just reach out to people. Worst case someone says no, but
is really flattered that you asked. Best case you get a mentor! Developing your skills No matter what level you're at, you can put many of the things I've talked
about today into practice right now. Start trying things out with your team and start developing some of these
skills and get the learning in before you need it. Summary We've covered a lot of ground today. Understanding strategy and drivers. Communications and relationship building. People and team design. We talked about the importance of understanding
the strategy and drivers of your organisation. We then went into being
effective in our communications and how to build relationships intentionally.
Finally, we touched on setting your people up the right way. It's your journey Being a leader is hard - but it is a privilege. When you create an impact, create great outcomes for your org and your customers
it is incredibly rewarding - especially at scale. I'm probably biased, however given technology and digital permeate every part
of the customer experience and enables all aspects of the organisation I think
as technology leaders we have a great deal to offer organisations in senior
leadership roles. ![A woman hikes along a valley
path](../../img/posts/presentations/wdcl2024/valley-hiker.webp)
*We all have different paths to walk. (cc) ajfisher - Dall.E* And, we're starting to see those roles appear and begin to get those opportunities
in non-tech businesses which is exciting. So it's time to get ready for them. Your career ceiling is no longer CTO or CIO
it's wherever you want to take it in the org. I wasn't really prepared for my step up out of practice leadership and into
a wider role and I had to learn fast. Fortunately, I was surrounded by a great
number of people who were truly vested in my success and supported me. The earlier you start on this journey, the easier it will be to develop these
skills and bring them to bear when you need them. Resources and acknowledgements [Additional resources](/leaders) can be found on a page dedicated to this
topic with links to books, podcasts, videos and other material. This talk was developed on the traditional lands of the Bunurong people,
Victoria. All images, unless otherwise attributed, produced using ChatGPT / Dall-E or
Stable Diffusion models.","['business', 'conference', 'growth', 'presentation', 'strategy']","['business', 'presentation', 'strategy', 'conference', 'growth']","[0.6135385515957007, 0.597082333828245, 0.5927158957947573, 0.591822742102822, 0.5857230921363487]",[],[],[],[],True,5
2024-10-28-software-engineering-reimagined-ai-native-era.md,Software engineering reimagined for the AI-Native era,"['ai', 'development', 'devops', 'essay', 'generative ai']","Software engineering reimagined for the AI-Native era
At the back end of 2024, [most developers at this point are using some sort of
LLM AI assistance](https://github.blog/news-insights/research/the-state-of-open-source-and-ai/)
in their coding practice. For some this might be [Github Copilot](https://github.com/features/copilot)
integrated into their IDE at work, for others this may be the use of
[Claude](https://www.anthropic.com/claude) or [V0 for first draft code
origination](https://v0.dev/), or it may be as mundane as using
[ChatGPT](https://chatgpt.com/) or [Gemini](https://gemini.google.com/) for
error clarification and debugging support. Software engineers are [mostly
considering AI a net
benefit](https://stackoverflow.blog/2024/07/24/developers-want-more-more-more-the-2024-results-from-stack-overflow-s-annual-developer-survey/),
helping them be more productive. This suggests that developers are, by and large, internalising the idea of AI
as a tool rather than a competitor. Also, developers are reinforcing their
belief that their value is less about lines of code produced and more about the
outcomes as a result of the problems solved. Software engineering has always had problem solving as its primary function,
however, in the period of extreme digitalisation through the late 1990s to mid
2010s, development started being seen by many parts of business as a volume play.
Lines of code produced and numbers of errors in production became the criteria
for success. Teams were measured on output against cost - leading to waves of
outsourcing, then offshoring, as code was treated as a manufactured good. All
the while businesses needed rapid process digitisation, volume of output was
the primary goal. But this came at a price. As we reach the midpoint of the 2020s, many organisations are dealing with huge
amounts of complexity, lack of explainability in their code bases (especially
with legacy code), and there are still systemic skill shortages of software
engineers in most markets, notwithstanding some of the big-tech layoffs. A software engineer is someone who looks both ways - even when crossing a one
way street. AI assisted development can help us keep pace with the volume aspects of modern
software engineering, however, as developers we are better utilised thinking
about and solving problems conceptually and spending less time
cranking out code. The code is the _byproduct_ of solving the problem not
the other way around. ![An office worker sketches ideas in a notebook at
her desk](../../img/posts/native-ai-sketching.png)
*Sketching an approach before starting work. (cc) ajfisher - Flux.Dev* Typically, most engineers write a quick sketch of what they want to do
before they start to write code in a rough form called pseudocode. Every
knowledge worker engages in this process to some extent, as dictated by the
medium of their work. This could be a dot point outline for a writer or
strategist, a literal set of sketches for a director or cinematographer, or a
set of unstyled slides by a manager creating a presentation. The method may change, but the purpose is the same. By sketching something out
conceptually, you think through the core problem you are trying to solve -
whether that’s telling a story, building the arguments of a business case, or
structuring the logic of a program. This is done before getting stuck into the
low level detail that necessarily entails a great deal of implementation
messiness (or, in the case of powerpoint, time spent nudging and styling). For inexperienced or learning developers (as with most skill-based professions)
this transition from high level conceptual thinking to low level implementation
can be tricky. Knowledge and experience both play a part in this but <b>ultimately
you need to get from a concept like “add the product into the user’s shopping
cart” to the nitty gritty details of how to do that</b> in the system and language
you are working with. This step is challenging because you need to map the
problem definition (what do I want to do?) to the capabilities of the tool
you’re going to use to do it (how does my programming language allow me to
implement this?). Even for experienced developers, there is cognitive load involved
in this activity that creates friction in the process - not least when you need
to read some pre-existing code and then turn that into a conceptual map in your
mind about what the code is doing in the system before you can tackle the
problem at hand. LLM AIs can assist this process because, fundamentally, they are *language*
tools. This means if I ask an LLM to write me some code that meets some
criteria such as “build a javascript function that takes two numbers and adds
them together”, it can do a pretty good job of translating that into something
that works (or works well enough). This is why a lot of junior developers have
jumped headfirst into using LLMs to support their development as it allows them
to pose a task and get an answer. More experienced developers use the same
tooling - but with more direction - to get the LLM to produce the boilerplate
code they know they will need and then assume that they will fill in the
details. ![Asking ChatGPT to make a function to add two
numbers together](../../img/posts/native-ai-chatgpt-js-two-numbers.png)
*ChatGPT is capable of producing good enough code in 2024. ajfisher* Both of these approaches work and have lead to some productivity
increases for some teams (at least for routine work). The AI tools we have available to us now are fairly capable for
boilerplate code or specific task generation (eg Copilot), but they are limited
in bridging the gap between concept and implementation. New reasoning models
like [o1](https://openai.com/o1/) or techniques like [Chain of
Thought](https://www.ibm.com/topics/chain-of-thoughts) bring this a step
closer, however they are really just improving task adherence and
completion rather than mapping from concept to implementation. Current AI tooling does provide non-trivial incremental improvement to
developer productivity however they remain reactive - focussing on filling gaps
in code rather than helping engineers structure and think about the solutions
at the conceptual level. Inherently, this limits their potential impact -
especially in more complex projects that solve real problems where the
challenge is in bridging between the idea and execution. Could we do better? If we assume we have good enough LLM AIs available to us, and they can be
sufficiently integrated into our work systems, could we reimagine the way we
shift between high level concepts _about_ a system and the low level
implementation _of_ the system? Could we integrate LLMs not just to help with
code generation but also maintain a bidirectional relationship between
pseudocode and executable code, increasing both developer productivity as well
as software quality? The elements I outline below might give us some of the steps we need to get us
closer to realising some of these opportunities. Pseudocode - a structured method for thinking In a ground floor classroom with steel security bars across the windows and a
double-lock door that was nearly always shut, I sat through my first formal
computer science lessons. In the early 1990s, my school was lucky enough to
have an actual “computer lab” - a vault-like room I found myself in a couple of
times a week from year 9 through to completion in year 12 (not accounting for
the time spent sitting in the corridor after been thrown out of that room for
being a “difficult” student, but that’s another post). Packed with 25 Apple
PCs, it was here we would take the work we had been doing in theory in a
regular classroom during our other computing lessons and apply it to actual
computers in the lab. The vast majority of my classmates didn’t have computers at home. At this
point, it was still rare to have a computer - some families had a games
console, but that was it. ![An illustration of a computer lab with old PCs
in it](../../img/posts/native-ai-classroom.png)
*Probably a little nicer than my Year 9 computer room. ajfisher - Flux.Dev* As a result, teachers couldn’t expect a student to have ready access to a
computer to write code. This provided my, and my classmates’ introduction to
pseudo code and structured logic. Computing being seen as part of mathematics,
it directly built on the logical reasoning skills we were taught in maths
lessons. By using pseudocode, teachers could ensure some degree of equity in a period of
unequal access, and also made things relatively easy from a homework and
assessment standpoint. Instead of programming a function to take two numbers
and add them together you would write out that function in pseudocode on a
piece of paper. Bad handwriting aside, it would have made marking pretty
straightforward for a teacher too. As you can see below, there is a little bit of structure to pseudocode, and it
vaguely looks like a  programming language. It’s just a series of
statements allowing you to express some logic. Even today, developers and teams
rely on similar approaches to think through how they will tackle a problem
conceptually. When we had access to the lab, our job would be to turn our pseudocode into
[Basic](https://en.wikipedia.org/wiki/BASIC) and see how well it functioned.
By having the structure of our approach already well thought through, it was
feasible to write the code in Basic during a lesson period and see if it
worked - thus beginning to anchor the relationship between problem solving
concept and the code that implements it. Using pseudocode, teachers provided a bridge between logical reasoning and
programming implementation. While this was driven from necessity, it was a good
way to build logical reasoning and conceptual thinking skills in students. As I left school and went to uni, my computer science courses built on this
further by teaching algorithms and formalised ways of reasoning about them in
terms of complexity, performance and accuracy. These formal methods were
anchored to programming in [Pascal](https://en.wikipedia.org/wiki/Pascal_(programming_language))
which maps very well to structured pseudocode and is remarkably readable
(before ultimately we were moved on to [C](https://en.wikipedia.org/wiki/C_(programming_language))
which is decidedly less readable). As we started building more complex
applications, the core methods remained, and were used much as they are
today - work through the logical approach before sitting down to write the code. The benefit of teaching like this is that you focus on the problem solving part
of the learning. You force the learner to think through the problem and break
it down into tasks, each of which can be broken down further. You also largely
remove syntax as a concern. As you can see, the jump from pseudocode to Basic
or Pascal brings with it additional syntactical structure, and these become
places where a learner fails - a missed semicolon in Pascal or a jump to the
wrong line number in Basic brings the program to a halt for example. The counter argument for this method of teaching is that it is astonishingly
dry. Formalised reasoning has its place, but being structured around the
formal, mathematical roots of computer science can be off putting.
Additionally, as computers became considerably cheaper and more accessible to
students, there was a desire to move more towards “getting outcomes” and
learning logic as a byproduct of the process. This was in part driven by the
goal of industry and government to produce “coders” not “computer scientists”. ![Using Scratch to add two numbers together](../../img/posts/native-ai-scratch-two-numbers.png)
*Scratch: learning to program with a cat is far more interesting. ajfisher* Using visual programming environments like Scratch or high level
pseudocode-like programming languages like Python, this approach took off.
Learners could jump right into an environment that was easy enough to learn
with few syntax quirks and then get a result - a cat that moves around a
screen in Scratch, or a program to interactively guess a number in python. The errors one experiences in getting an environment up and running or when
the code fails are all considered part of the learning process to help the
would be programmer learn how to debug as they graduate to bigger systems. This process is less formal, but over time builds logical concepts and
hopefully keeps more people interested, allowing them to transition into
considering programming as a career. Regardless of the way one learns to think through concepts, structured thinking
remains fundamentally at the heart of all knowledge work and it is particularly
useful for development. As teams work together, we use these methods of structured thinking to
collaborate. In most multidisciplinary teams, only a small fraction of those in
the team are software engineers wiring code. Thus <b>we use structured methods
such as requirements documents or business process maps so we can communicate
effectively and work through the fundamental concepts</b> of what we’re seeking to
achieve. This helps align vision and clarity across the whole team as you get
into implementation. Pseudocode is often a part of this process. As a software engineer goes through
the requirements, she may use those requirements to sketch out an approach,
which she shares with other engineers and team members who may add comments or
refine the logical design. From there, she is likely to turn that pseudocode
into comments in the first draft of some code and then start filling in
details. Beginning with all the boilerplate code and then “stubbing out”
functions or API calls she will implement later in more detail. This process of increasing fidelity is an extremely common pattern and used
across most knowledge workers. In late 2024, our software engineer above is
probably also dropping some of that pseudocode into an AI code generator such
as Github Copilot or ChatGPT, which is helping to produce the routine parts of
the first draft code. Pseudocode still serves as a valuable tool for structured thinking, however
with the increasing complexity of modern software and the expanding
capabilities of AI tools, there is an opportunity to rethink how we transition
between conceptual problem-solving and writing code. Coupled with AI tooling, pseudocode could be leveraged not just as a
transitional step but as a bridge that allows us to move seamlessly between
concept and implementation. But, can we push the tools to help developers spend
more time thinking conceptually and code more effectively? Bridging the concept to implementation gap Even though most engineers will at least start with some form of
pseudocode-like outline, potentially as comments in their files, as fidelity
increases these comments begin to disappear. The initial comments likely get
consumed into the implemented code and we lose some of the conceptual elements
along the way. A good team might maintain some solid comments that explain what the function
or the code is doing, and even how it relates to the wider system. However, as
the code ages, teams turn over, and more modifications are made, unless
outstanding processes are maintained on code documentation, there is likely to
be drift between meta commentary about the code conceptually and what the code
is actually doing. Unfortunately, most developers are KPI-ed on clearing
tickets and code shipped to production, not writing docs. ![An illustration of an overgrown cityscape](../../img/posts/native-ai-overgrown.png)
*It's easy to get overwhelmed and not maintain the documentation side of
systems when you have to deliver - (cc) ajfisher Flux.Dev* But what if we don’t drop down to the lower level in the first place? What if, instead of just doing a sketch in pseudocode then transforming that
into executable code, we wrote slightly more formalised and slightly more
detailed pseudocode and used an LLM tool to do the conversion into the
underlying programming language we want? We are currently so used to google, we inherently treat LLM AIs as _answer
engines_ - that is “Can you write me a function in javascript that adds two
numbers together?” We’re only just working out the implications of how we use LLM AIs
as _language engines_ instead? Style transfer lends itself well to programming We’ve seen examples where an LLM [converts text
from one language to another](https://about.fb.com/news/2020/10/first-multilingual-machine-translation-model/)
([increasingly in voice as well](https://www.youtube.com/watch?v=WzUnEfiIqP4)).
This form of style transfer lends itself well to programming languages because
there’s just so much programming content on the internet. A number of
programmers will take a function written in one language that they have copied
online and ask an LLM to convert it to their preferred language. This isn’t
new - but it is a powerful tool. Say we baked into our development tools a layer that can take developer created
pseudocode and then, in real time, the AI tool does the conversion into the
lower level language. For example, a developer might want to find the largest value in a list and so
write out the pseudocode below: We've added some additional structure and using a more formalised notation
with pre and post conditions to highlight expectations of how the function
performs. We also use a loop invariant to provide clarity over our assumptions
about what is happening inside the loop. With such instructions, using today’s AI tools, a lot of this conceptual
structure can get stripped out in the translation process. But, by preserving
these comments and maintaining formal structures, LLMs could produce more
readable and robust code. An example of what that looks like with our future integrated AI development
partner might be the JavaScript code below: You can see the mapping easily enough because the LLM has kept the comments and
the overall structure of the logic so this works pretty well. Even if I’m not a
great JavaScript developer, I could take that code, try it out, and see if it
worked. If I was a learner of the language, I could put the pseudocode and JS
side by side and start to map the conceptual logical elements to the underlying
language constructs quite effectively, improving my ability to understand
what’s going on. At this point we’re very much still in the territory of the current, albeit
quite manual, processes that Generative AI tools support in 2024. To take this further though, as the developer writes the pseudocode, the LLM
could provide realtime feedback, making recommendations or highlighting gaps in
the logic that need improvement. For example, the AI may suggest making
improvements to the original pseudocode to check for valid numbers and to
handle edge cases more gracefully such as the example below: As a learner, this gives insight to instruct me on best practices I should
adopt as I learn to program. For a more experienced developer, these are all
things I’d have most likely done anyway - even if I’d have glossed over them in
my sketch - because they are good practices. Now I can be more explicit about
what code I want to produce. With this structure, the LLM assistant could construct test cases based on the
pseudocode and as the produced code, supporting a rapid, iterative, test
driven development approach such as that below (snipped for brevity to just a
few cases): Having this joined up way of working allows the developer to think logically
and algorithmically to solve the problem at hand and relies on the LLM to
provide the immediacy of being able to create and run executable code then get
feedback. Some IDEs support aspects of this, but having it fully integrated
such that the developer primarily interacts with the logical layer and then
gets real time feedback and executable code iteration at the same time would be
a benefit for learners and experienced developers alike. The developer may need to start to handle edge cases or fill in
specific details about how APIs are called - especially if they are internal.
At this stage, they will probably want to make edits to the underlying
produced code to carry it forward. In our example above we might need to add
specific checks to ensure the function is called with an Array of items, or the
array has an item that contains `Infinity`. All this being said, as a byproduct of this process, the developer will also
produce an artefact that represents the logical approach for the code they have
produced - which can be stored and referenced by themselves, or others. This
could even be consumed by other systems such as documentation generators to
derive secondary high value assets. This approach has particular benefits for learners as it links together the
structured thinking (what I want to do) with an immediacy of outcome (I can see
it doing). This allows a learner to scaffold their knowledge as it directly
ties the algorithm back to the code that is produced. As mentioned above,
having <b>a feedback mechanism can support illustration of best practices</b> which
the learner can see implemented in a way that would normally occur by working
with a more senior engineer or through code review. In situations where an
inexperienced developer is working or learning solo (eg at school or in a very
small team) this feedback mechanism would actively support their learning
process and help prevent them from developing bad habits. Aspects of this exist in 2024 in some IDEs already, as well as developers
manually throwing code snippets or lists of requirements at ChatGPT or Gemini
and getting some code back. However, in most cases this process is
disconnected and misses a lot of context. Invariably, it involves a lot of
copying and pasting between applications to make it work(ish). Workflow challenges aside, this process does work and I know a number of
developers who use these LLM features to enhance their learning or improve
productivity by doing exactly the techniques above. A more integrated approach would undoubtably speed this process up, but
assuming we had a tightly integrated development environment, we could take
this idea even further. With the right integration, this process could go beyond just generating code -
it could create a dynamic, realtime collaboration between developers and AI,
allowing both to operate effectively at multiple levels of abstraction. An idea
of what this might look like is what we’ll explore next. Realtime, bidirectional human-AI collaboration Developers spend a lot of time reading code - many times the amount of time
spent writing it. Guido van Rossum, creator of the Python programming language observed, “Code is
read much more often than it’s written” - leading him to many of the design
decisions that underpin the core concepts of the language. As a result, Python
is probably the most readable programming language we have available for
general purpose programming. Even acknowledging the readability of Python code is generally outstanding,
anyone trying to wrap their head around an uncommented list comprehension for
the first time will likely struggle to understand what is going on. Take for
example the snippet below: The centre line, even with good naming, may be difficult for non Python
programmers to understand. In one very terse line that code: goes over the data that is in the list of _people_ noting that the _name_ is
always the first item and the _age_ is the second item in each set. If the _age_ part is greater than or equal to 18 then keep those elements,
throw everything else out. For those people that are left, take the  _name_ and convert it to uppercase. Assign the uppercase names as a list to the _adults_uppercase_names_ variable. That’s quite a lot of things happening in one very short line of code. Once you understand the structure, it is relatively straightforward to see
what’s going on, but it’s also ripe for being incomprehensible. I’ve seen some
extremely clever Python list comprehensions over the years that do nothing for
code readability (some with many paragraphs of explanation as to what is going on). ![Python code for text embedding](../../img/posts/native-ai-embedding-code.png)
*Some of the python code that drives the post recommendations on site - (cc) ajfisher* When a new developer starts on an existing project, the first thing they do is
start reading through the code alongside any documentation that exists. They
conceptually assemble all of the building blocks into a mental model that
allows them to understand how the system is functioning. Sometimes the
underlying logic lacks context or is so difficult to follow that the programmer
will just put it in a mental black box labelled, “I think this function does
X?” - but they aren’t sure, and will never tinker with it for fear of blowing
everything up. This process is similar to a builder doing a survey of a site to understand
where the electrical, gas, and water pipes are before they start digging and
potentially causing a lot of damage (or clean up). Even with good development hygiene (good naming, logical models, comments,
documentation, tests), <b>developers will spend a significant amount of time
mapping backwards from implemented code to their conceptual understanding</b> of it
so they can begin to reason about it. Once the programmer feels confident in
their understanding they start to work out how they would change the system. This is where I think an LLM AI partner can help improve this process. LLMs are incredible translation tools. As we saw above, we can write some
pseudocode to find the maximum number in a list and it produced code to do
this. We added some conditions and it refined the code, and made some test
cases to help validate it was working correctly. We could use this same process to go the other way as well. We provide some
code and ask the LLM to provide a pseudocode summary of that code. For example,
using [some existing code for a
plugin](https://github.com/ajfisher/ajfisher.me/blob/master/site/plugins/gatsby-remark-transformer-pullquotes/index.js)
I wrote for this site to build the pull quotes, we can generate the pseudocode
and get an explanation about what is going on. This is a pretty good representation of what’s going on, and the steps link
directly back to the implemented code. As well as our structured logical, model
it’s possible to get an even higher level summary: This is excellent context for a new developer on the project, especially if
they were still learning and weren’t sure what was going on. Even using manual processes to move information between development tools and
AI tools, this is helpful but in a more fully integrated environment this
creates a huge amount of power very quickly. Very quickly, I can see a reasonable summary of the code I’m working on and a
side by side representation of the pseudocode and the executable code. Having
all of this together starts to create some interesting opportunities for
development. With all of this in one place, and the AI tooling having a view of the code
windows, edits in one location can get translated to another in realtime. ![Theoretical IDE mocked up in vim](../../img/posts/native-ai-ide.png)
*Entirely mocked up, but with linked context and AI assistance this could
be powerful. (cc) ajfisher* By editing the pseudocode, changes become reflected in the code base. This will
help learners anchor their understanding on how the programming language
functions. A more experienced developer may recognise a logic gap in pseudocode
and address it, which immediately gets reflected in the underlying code. Going the other way, making edits to the lower level executable code will
result in the pseudocode getting updated in realtime. This means the code
repository will always have a structured, logical representation of what the
code is doing. Most importantly, this structured, pseudocode representation will always be at
*whatever level of abstraction I am looking at*. This could be a function, a
class, a module or a whole file. In a fully integrated environment, the system would maintain links between
blocks of code which will improve code translation integrity as the LLM’s focus
can be guided (it won’t be regenerating an entire function, just because a
small edit was made in one part of it). An early peek at this future is already
evident in [Artifacts in Claude](https://www.claudeaiartifacts.com/en/) and
[Canvas in ChatGPT](https://openai.com/index/introducing-canvas/), but this is
just the start. As a result of this bidirectional flow of change and context matching, the
barrier between what I do as a programmer and how I go about doing it begins to
break down. The translation all gets handled in the system directly, and I can
choose which level I want to engage with. As a developer using this system, <b>I
am likely to maintain a flow state more effectively and produce higher quality
outcomes</b> because I’m more directly solving problems in the most appropriate
way. This will bring with it some new edge cases. Notably this occurs when the
changes made to pseudocode are incompatible with the underlying code. The
development environment will need to surface this new type of error in a way
that helps the developer reconcile these incompatibilities. Similarly, in very
complex code that is harder to abstract, there is the potential for drift
between the conceptual and executable code layers. In either case, a developer may choose to opt out of realtime translation and
work more directly in the executable code layer, then rebuilding the pseudocode
at the completion of their work as a summarisation step instead (this could be
incorporated into build tooling). For some non-routine domains, <b>the LLM AI tools may even have specialisations
which can be added to the development environment</b> to assist the programmer.
This could be for applications that are more complex (such as gaming or
distributed event driven systems) or where highly specific knowledge is
required (such as finance, medicine or compliance systems). Taking this to it’s logical conclusion, one can envisage an integrated
environment where the tooling is also supporting the running of the executable
code produced. Great strides have been made in this area over recent years with embedded
execution consoles in our IDEs and we’ve had live debuggers for decades. But
all of this presupposes that the developer has got their environment up and
running properly in the first place. ![An illustration of a frustrated developer at his
screen](../../img/posts/native-ai-frustration.png)
*We all get frustrated when you can't work something out you think should be easy.
(cc) ajfisher - Flux.Dev* That process of environment set up is still a challenge - even for experienced
developers starting a new project or landing in a very mature one, and this is
even more challenging for a beginner. The number of beginners I’ve had come to
a workshop with old versions of NodeJS or Python that cause huge conflicts
because they don’t use virtual environments or containers is astonishing. It’s
because they don’t know how to do it or even that it’s a valuable way to set
up. Imagine a scenario where some basic questions or an instruction to the AI
tooling does the set up and configuration of a virtual development environment
for you using sensible defaults that reflect a set of current best practices
for developer experience, security, package management etc. This would probably lean on existing tools like docker for portability,
along with the ability to leverage great defaults, and a wide community base of
developed images and be extended to run the generated code from the development
environment. With tools like docker already integrated into most development
flows, once you had an LLM integrated development tool, linking this part up
would be comparatively straightforward. ![Example command line application](../../img/posts/native-ai-env-questions.png)
*A theoretical application creator using LLM support - (cc) ajfisher* For developers in a bigger team, this process would leverage existing patterns
for environment creation based on established DevOps guidelines set by the
technology function of the business. This would be an enterprise-wide
configuration - much like how organisations already use things like [Amazon’s
Well Architected
Framework](https://aws.amazon.com/architecture/well-architected/) to have a
sensible starting points and account landing zones that have good defaults
across the pillars. The final part of this advanced development environment would be to link the
debugging process to AI tooling to support programmers. Google has already released some [limited tools in
Chrome](https://developer.chrome.com/docs/devtools/console/understand-messages)
to help web developers debug front end code. It shows you potential reasons for
the error and can even use the context of the running code from the browser and
link that back into Gemini and Google Search to deliver a powerful debugging
experience to a web developer. Just this week as I was writing this the Chrome
team [have extended
this](https://developer.chrome.com/docs/devtools/ai-assistance/) to allow
prompting and styling assistance. ![Chrome debugging using Gemini AI](../../img/posts/native-ai-chrome-debugger.png)
*Chrome via Gemini, now supports AI debugging of front end code. ajfisher / Google* Building on these ideas, debugging can be augmented further by linking the
errors through the low level code back up to the higher level pseudocode. This
helps highlight the difference between errors such as type mismatches or syntax
problems with logical bugs like off by one errors or side effects. For learners, this will help them understand the nature of these issues so they
can see how they manifest and the different ways to resolve them. For more
experienced developers, this will speed them up considerably by helping them
zero in on where the likely causes might be and  identify the problems. A development environment that provides realtime translation between the
high-level, conceptual logic of pseudocode, and the lower level executable code
would be a benefit for experienced and beginning developers alike. Add to this
the ability to build and manage environments by answering a few questions, and
bring to bear a more advanced debugging capability and this all starts to
reshape what developer experience looks like. For over 50 years, development environments have had a drip feed of
enhancements that drive programmer productivity, however at their heart they
are mostly a text editor with some auto-complete smarts, a window into a file
system and a command line console. The integrations have got better, the
autocomplete is smarter and we can change our fonts or flip to dark mode. <b>A
programmer starting university in 2024 or 2004 or 1974 would all have
remarkably similar experiences of writing code</b> into a text file and then
getting the computer to run it. This concept reimagines what development might look like. An AI-native approach
to the development environment doesn’t do away with the text editor, but it
does fundamentally change the way a programmer authors code and runs it -
transforming the process from a series of discrete steps to one of partnership
and dialogue between the developer, the AI and the code. In the final section,
I’ll look at what a new model of development practice might look like. A different model of development Shifting toward a more AI-native model of development, that fundamentally
rethinks the role of the programmer in the process and their relationship with
their current tooling presents some interesting new opportunities for software
development. Using an integrated LLM AI as part of the workflow shifts from being a reactive
tool that is essentially a glorified autocomplete (eg Copilot or even Chat GPT
/ Claude in 2024) to being a proactive development partner - where the tool is
bridging multiple layers of abstraction and providing realtime translation
under the direction of the developer ([more like pair
programming](https://en.wikipedia.org/wiki/Pair_programming)). As with all good
partnerships, this is bidirectional - where the tool provides clear
(deterministic) feedback on inputs, as well as contextual (inferential)
insights to help improve the overall quality and clarity of the produced
artefacts. By taking an AI-native approach, many repetitive tasks can be pushed away from
the developer. We already do this by using frameworks, libraries, utility
functions and greater levels of abstraction and have done for decades. This
allows developers to keep more time focussed on the tasks that are higher
cognitive load and also more likely to be higher value. Utilising the LLM to do
the raw production work at scale will keep the developer more “in the flow”,
thinking about the problem they are working on and less likely to need to get
tripped up by trivialities. ![A programmer is working on a project](../../img/posts/native-ai-programming.png)
*Tooling will be enhanced under this model, rather than replaced - (cc) ajfisher Flux.Dev* Because this interaction becomes a dialogue between developer and AI Assistant
in realtime, constraints and assumptions will be expressed that can be used to
immediately generate a wide ranging battery of tests to prove the validity of
the code. Coupled with existing test automation processes, feedback can be
provided in real time on performance and test completion. This will naturally
lead to improved quality, but coupled with the other conceptual artefacts such
conceptual models and logical pseudocode, taken together, these artefacts will
raise the [reasonability of the
code](https://the-whiteboard.github.io/coding/debugging/2016/04/07/reasonable-code.html)
base for future developers and other team members. This changed model of creation is extremely empowering for learners and
experienced developers alike. Beginners establish a better understanding of the connection between concepts
and executable code - which they need to learn to become successful
programmers. More experienced developers get significant productivity
improvements on the code output side of things, allowing them to use their
brainpower to solve significantly more complex business problems - which leads
to better organisational outcomes and value creation. Risks and challenges of AI-native development It is at this point that it’s worth noting some of the downside risks and
potential flaws in this proposed development model. The most obvious concern, and one we are already beginning to see is that
developers start to become too dependent on AIs to write code. Some teams are
already [citing this
problem](https://blog.venturemagazine.net/has-ai-made-developers-dumb-e45eb769ef17)
and this isn’t just limited to junior developers using AI as a crutch. Development is a memory based skill and like any other, it will atrophy through
lack of use. Junior developers are particularly prone to this. As they copy and paste code
between Chat GPT or Gemini and their IDE without necessarily understanding the
logic behind it - they are inherently focusing on speed to complete their tasks
(see my opening points regarding output based KPIs). This potentially leads to
[security
issues](https://www.theregister.com/2024/03/28/ai_bots_hallucinate_software_packages/)
and leaving the developer entirely unable to reason critically about what the
code is doing or any errors that occur. Fundamentally, this is because the logical concepts of the problem are not
being linked to the produced code. This is why I believe this process needs to
be a realtime dialogue using structured methods like pseudocode to direct what
is happening as it intuitively links these two sides together. The other major concern with this model of development is whether the LLM AI
can perform in all contexts. For a number of general domains is likely okay
given the current crop of frontier models’ performance. That said, there are
undoubtably a number of complex domains - particularly in finance, medicine and
engineering that have extremely specific rules, algorithms and compliance
requirements and <b>the Developer Assistant will simply be at a loss for what
approach to take</b>. Fine tuning of the models or “plugins” that are used to hand off specific
scenarios to dedicated “specialist AI” components for domain specific needs
could be ways this problem is addressed. This would involve referencing other
sources of trust such as required compliance checks in finance or diagnostic
rules in medicine. These models will also need to be maintained to ensure
alignment with evolving standards - especially those related to compliance
needs. This is being viewed very much through the lens of current 2024 LLMs however,
and as has repeatedly been noted, these models are the least advanced AI will
ever be. So with time, perhaps generalised future models will have a sufficient
grasp of domain complexity that they will be able to perform acceptably. Regardless, this is likely to be a challenge for the foreseeable future so
methods for either hand off or being able to call internal APIs that “package
up” compliant methods consistently may be ways to address this particular
issue. This latter approach is no doubt already widespread as it assists with
audit, compliance and consistency anyway. Not Developer vs AI, Developer plus AI This model of development that I’ve outlined unfortunately doesn’t currently
exist as of October 2024, but the ways we see developers embracing LLM AIs,
code generation tools and Co Pilot-like assistants give pointers towards future
opportunities to rethink how software engineers work. [Research shows
us](https://blog.tidelift.com/how-much-time-do-developers-spend-actually-writing-code)
that developers are only spending about a third of their time actually writing
code. Another third of their time is spent doing “toil work” - writing tests,
doing documentation, debugging, or maintaining code. The final third is largely
meetings and other orchestration activities relating to collaboration. Even using an output-centric approach for assessing potential productivity
gains, the AI-native model of development I’ve proposed would be a benefit.
Improved code-generation would increase developer productivity, and improved
automation would decrease the toil work on an average developer. This would
create a virtuous circle - creating more developer time that could be spent on
creation which would then be completed at higher velocity. But, more code output doesn’t necessarily result in better outcomes. My view on this cycle of improvement due to AI-native development is that
removing some of the code and artefact generation from the developer will allow
them to spend more time thinking about and solving higher value problems. More
time available for creation and problem solving, backed up by a robust AI
development partner that can do a sizeable chunk of the code creation, will
allow developers to spend more time working through much more difficult
challenges. Over time, <b>this approach will yield competitive advantages for organisations
that can deploy their developer capital</b> towards these more challenging
problems. It will also lead to greater innovation opportunities as developers
are less constrained by putting out fires, testing or time-consuming
maintenance. It’s hard to innovate when you’re constantly doing hygiene
activities. I feel very optimistic about the opportunity that is beginning to manifest as I
look at the potential combination of developers augmented by AI partners. Right now, AI is already being used by engineers and while some are using it
effectively and collaboratively, it’s somewhat disconnected from our core
tooling. This results in lots of copy-pasting between systems which slows
developers down and potentially presents security risks. But the desire is
clear. By leveraging the power of an LLM to provide realtime translation between two
points, there is an interesting opportunity to be able to partner the developer
and AI assistant to go between the high level conceptual logic and the low
level executable implementation seamlessly. Augmenting this further via
bidirectional translation between the layers, realtime feedback loops,
automated test production and ability build and run development environments
and this fundamentally changes the developer experience. ![A developer looks at a futuristic display](../../img/posts/native-ai-working.png)
*Future development could be faster and very high value - (cc) ajfisher Flux.Dev* By bringing this all together into a new, AI-native approach to software
development, this could result in truly significant productivity improvements,
more creative problem solving and we enable more of our global software
engineering talent to work on harder problems. This could also act as wayfinding
for other professions who will follow behind software engineers and
need to look for patterns of integrating human and AI capabilities together. There is some way to go from our current development methods in 2024 to the
future I’ve outlined in this essay, however I think we’re on track to seeing
something like this become feasible in the next few years. And there will be
the need too. This will be driven by the next wave of digital and AI transformation in
business, yet again requiring more software engineering talent than the world
produces, and the inexorable process of automation that all developers embrace
to help improve productivity. Software engineers have always been forced to embrace change in working methods
and this transition to AI-native ways of working will prove no different. The
process itself will be uncertain, undoubtably with false starts and false
promised, but on the other side, there are some big opportunities to tackle
significant problems ahead. If you’re working on something like what I’ve described as AI-native
development, or have insights or similar challenges as I’ve discussed, or are
curious about this journey, reach out - I’d love to connect and share
perspectives on this topic or potentially support your efforts.","['ai', 'development', 'devops', 'essay', 'generative ai']","['development', 'ai', 'essay', 'generative ai', 'devops']","[0.6209449775369803, 0.6128619207607569, 0.5897646005627798, 0.5746313078981855, 0.5547546639133356]",[],[],[],[],True,5
2025-02-03-retail-improvements-australia.md,After the drought: first shoots emerge for Australian retail,"['business', 'ecommerce', 'growth', 'retail']","After the drought: first shoots emerge for Australian retail
Anyone working in retail in Australia (or globally) will tell you it has been a
very hard slog. The combination of slow growth into the pandemic, followed by
[supply chain
issues](https://www.ey.com/en_au/insights/supply-chain/how-covid-19-impacted-supply-chains-and-what-comes-next),
[interest rate hikes](https://tradingeconomics.com/australia/interest-rate)
then rapid inflation has meant discretionary retail has been in troubled waters
for a little while now. This week, [the ABS released its December 2024 retail spending
report](https://www.abs.gov.au/media-centre/media-releases/retail-spending-steady-december),
and while I doubt CFOs will be unlocking their budgets just yet, it does
show that there’s the chance we’ve turned the corner in Australia. It’s not all unbridled optimism though. If a large-scale trade war erupts -
especially due to US tariff policies and China’s reaction - the modest growth
we’re seeing here could easily wither over the coming quarters. Signs of growth - if you know where to look Overall, retail had the strongest December quarter it has had in years. At
best, accounting for inflation, it’s been flat - and the reality is it’s
probably been down once you take that into account. While December specifically was down month-on-month by a very slim 0.1%, this
was off the back of strong gains in October (+0.5%) and November (+0.7%). Consumers are beginning to feel more confident about the economy and a lot of
this is them just knowing where they stand financially. If your rent or
mortgage keeps going up every other month and the prices you pay at the
checkout keep changing, it is incredibly hard to plan your expenditure. As a
result, people stopped spending. To an extent, this was exactly the RBA’s plan - to cool the economy and curb
inflation. I won’t pass judgement on how they did that, other than to say for
the last 24 months, consumer spending has been low and discretionary spending
has been severely curtailed. For retail, this has had huge implications with many stores closing and has
been particularly hard on [restaurants and cafes who have seen record
failures](https://www.news.com.au/lifestyle/food/restaurants-bars/there-lies-the-problem-cafes-restaurants-failing-at-fastest-rate-on-record/news-story/d2267f48e9692f8d870cae9ba541d534). These latest figures indicate that consumers have finally got a read on their
finances. Inflation is back within target band for most items, and mortgage and
rental rates have largely stabilised (even if they are costing more of a
fraction of income than any time before). Additionally, many consumers have had
a pay rise over the last 18 months. Most consumers aren’t exactly flush with cash, but the economic landscape is
much more stable than before, fostering confidence and a slight loosening of
the purse strings. This means some additional discretionary spend. The data shows household goods and department store sales are up while clothing
and cafes are down. This makes sense - if you are going out less then you are likely at home more,
so you want your home space to be a bit more comfortable. A knock on
implication of this is that you need fewer clothes. We know the op-shops are
[doing very good trade
over](https://www.abc.net.au/news/2024-05-08/australians-turning-to-op-shops-in-cost-of-living-crisis/103809766)
the last 12 months as a result of people not buying new. We also know that
[Temu and Shein are proving
unstoppable](https://www.roymorgan.com/findings/9646-shein-and-temu-contintue-to-grow-strongly-august-2024)
for cheap fashion and homewares - none of which is really captured in the ABS
numbers for retail spending. Retail spending increased +0.5% per capita over the quarter which is the first
uptick in more than 2 years - a good sign of sustainable consumer confidence. Pulling sales forward Sales are moving from December and into November (or even earlier) - a trend
that’s been building for nearly a decade and is becoming more prominent than
ever. The impact of BFCM, Singles Day and Click Frenzy is pushing November
sales higher, away from December being the retail peak. Working with all my retail clients coming into the end of the year, this
behaviour was easily apparent and is very much in line with the long term
trend. This has implications for supply chains, seasonal drops and profitability over
the quarter and I’m not sure any retailers have fully worked through all the
implications of this now just being how consumers behave. In 2025 and 2026 I
believe we’ll see less blanket discounting with better targeting but also more
selectivity when it comes seasonal and new products than we’ve so far. Where to from here? Consumers have told the retail sector that they are prepared to spend again -
but you have to have a good product at a good price. Many buyers are being
extremely picky about their spending and are quite happy to wait until a sale
comes around so they can get a discount and keep hold of their hard-won
discretionary dollars. There is a great deal of variance across localities, verticals and audiences so
understanding exposure to this is imperative for retail leaders to manage risk
but also understand where the opportunities fall. Targeting of audiences from
both an acquisition and retention standpoint is going to be key here -
especially if you can frame additional benefit beyond price parity. Unlocking
initiatives that help enable this would be good investments of human and
financial capital. The last few years have been some of the most difficult I’ve seen in retail for
my entire career - reflective of it being a difficult period of time for
consumers. That said, the numbers for the December quarter are the most
positive they have been across the retail sector since the start of the
pandemic - multiple indicators suggest that while we aren’t out of retail
winter just yet, we might be entering a thaw and there are a few patches of new
growth that indicate spring may be on the way. Notes: _This post originally started as a [Bluesky
thread](https://bsky.app/profile/did:plc:gaf7g3frhn47hljbcipvidxj/post/3lhase3rwx22f)_","['business', 'ecommerce', 'growth', 'retail']","['business', 'retail', 'growth', 'ecommerce', 'mobile']","[0.6287373888154738, 0.5965406315336012, 0.5944312165297295, 0.5853589111476867, 0.3117295190903512]",['mobile'],[],[],[],True,4
2025-02-27-when-will-ai-disrupt-travel.md,When does travel planning get seriously upended by AI?,"['agents', 'ai', 'business', 'growth', 'innovation', 'predictions', 'strategy']","When does travel planning get seriously upended by AI?
One of [my colleagues](https://www.linkedin.com/in/jim-nelson-2881582b/) posted
an interesting question to our group chat this morning that got me thinking in
more depth about this topic. “Where is the AI lift in travel?” On the face of it, the opportunities for AI across the whole travel ecosystem
are many and arguably there already *is* a lot of AI in various elements of it
(eg pricing of flights, demand prediction etc). But where is consumer AI in all
of this? At this point in 2025, most of us who use AI tools have at least experimented
with a prompt that goes something like, “I’m going to Paris in September for 7
days. Can you give me an itinerary of things to do while I am there.
Additionally, can you give some recommendations for places to stay in the
Marais district?” Anyone who has done this will get an okay, but entirely beige travel itinerary
that is pretty much designed for the cruise ship set over 75 full of
wonderfully stereotypical suggestions for places to go. Louvre? check. Eiffel
tower? check. Notre Dame, Place des Vosges, Musée d’Orsay? Check, check and
check. You can try and push it a bit more by saying you’re in your 20s and want to
skip the touristy stuff. Something like, “Okay, I'm looking for something a
little more edgy. A little less well trodden path touristy. I'm traveling with
some late 20s and early 30s people and want something that is a view of Paris
from this angle. Let's not go beige and safe like I'm 60 years old and visiting
on a cruise tour.” I recognise the prompt above is ageist, but this does force the recommendations
to change. Interestingly, it generally pushes places to drink rather than
things to do. That said, it did recommend [Madame
Arthur](https://madamearthur.fr/) (Drag meets cabaret) which I am definitely
visiting the next time I’m in Paris. As with everything, we look at a new technology through the lens of what has
come before. In this instance the chatbot is really just a proxy for picking up
a brochure from Flight Centre, getting a guide book or reading some listicles
about the 10 best things to do in Paris. It’s providing a flavour of things
that are on offer, through a particular lens (the prompt in this case), and
then it’s up to you the user to turn  this into something meaningful and create
your itinerary from there. It’s a brainstorming tool. Are AI agents the solution? In our teams chat, everyone pretty much agreed that AI agents go a long way to
help solving this. AI tools that can hook into APIs, retrieve live data about
costs, availability etc would add texture to the experience as you can start to
have a realtime view of whether your trip is possible or not what it might cost
and what tradeoffs you might be making. This could be supercharged if those
agents might be able to execute “holds” in the system on your behalf as well
while you organise everything. AI agents currently feel a bit overhyped on the basis that for every problem, a
well trained “AI Agent” seems to be the solution. The question is how well do
you have to train said agent to be materially useful and solve the user’s need?
TBD on this for the moment outside of trivial use cases. Part of the problem I have here is that travel was one of the first industries
to be widely digitised and there’s been over 20 years of optimisation applied
to search and booking systems. As a result, the sheer speed at which I can now
select, book and pay for everything from transport to activities to hotels is
pretty incredible. For a little while yet, it also likely this will be faster
than briefing an “AI Trip Agent” to try and do this for you (not least due to
the friction that will be introduced to add checks and confirmations before
committing cash on your behalf). A high bar to get over The bar to solving this is pretty high when you think about it - and [agentic
AI](https://en.wikipedia.org/wiki/Agentic_AI) is a necessary precondition to
have any kind of chance at doing this. But it probably comes together as a
specialist application or service. At its heart you need a hyper local travel guide attuned to your *taste*, up to
date information available, high levels of accuracy and the ability to reason
through the relevant information to ensure the plan is actually feasible like
the best travel agents. Taking each of these in turn. Taste matters Just about every place of note is now mapped, reviewed and has at least some
basic online presence. Yes, there will be that bougie sandwich place not even
on insta that serves from a hatch in a laneway - but that’s the sort of thing
you’re only going to find in the moment. Taste cuts through the “everything” noise and provides opinionated perspective.
Most people don’t want more choice, they want one or two options attuned to
their needs and desires. Most people can’t really articulate their taste but
intrinsically know it when they see it - outsourcing this helps. A beige everything engine needs to be pruned back hard to provide that hyper
local knowledge and be opinionated enough to make good recommendations. A
classical nostalgic, history and culture centred trip to Paris is very
different to one centred around clubbing, music and shopping. Solving for this will probably mean fine tuned models that force results away
from the beige - very much like adopting a character or persona and then
putting any recommendations through that lens before surfacing. Trained well
enough, these agents could achieve results similar to the “locals list” that
friends give each other when visiting cities they know well. Up to date information Thankfully this one is relatively easy to solve given the wealth of online
information and APIs that exist around this area. This is one of the big
benefits of 20 years of digitisation in travel. But APIs and pages designed for
programmers and humans may need variations for AI agents so there’s probably
some other interesting work to be done on this side. By the same token, to have up to date information, AI agents will need to scour
the available information and then try and parse that back into a form the
orchestration agent can handle effectively. Accuracy We all know LLMs hallucinate, it’s part of their charm and anyone who has tried
the whole AI itinerary thing will know that they recommend places that sound
feasible and interesting but don’t exist. Again, digitisation of virtually every known place in any well known place
helps solve for this. There’s multiple ways to tackle this; whether it’s having a big database of
places the application can look up and validate against, or doing the same
thing with an AI agent simply doing a web search and visiting the site of the
place to confirm it. Whatever form it takes, it will be critical to push all
the recommendations through a filter of “does this place exist and is it still
open?” (and open when the user wants to visit). Flights and trains tend to be a bit easier in this regard as routes are well
defined and there are really great APIs that exist for availability, route
planning and travel times. Our current crop of tools like [Rome2Rio](https://www.rome2rio.com/),
[Kayak](https://www.kayak.com/) etc all solve some of this for the travel
element of this and tools like [booking.com](http://booking.com) etc solve the
accommodation side, but the long tail of “is this bar open on Wednesday night
past 11pm?” is quite specific, and agents will require some extra capabilities
to parse that information out of web pages (or images from Instagram posts). Orchestration Bringing all this together is the orchestration layer. An AI Agent will help
coordinate the various sub agents and tools to get all the information, however
bringing this into a form that the user can interpret and refine will be a
critical element to this. I’m not sure a chat interface or even a
[Canvas](https://openai.com/index/introducing-canvas/) /
[Artifact](https://support.anthropic.com/en/articles/9487310-what-are-artifacts-and-how-do-i-use-them)
/ [Google Doc](https://support.google.com/gemini/answer/15719111?hl=en) is the
right means for this. My sense is that you’d want some sort of custom interface that outlines the
itinerary but provides summaries of information, highlighting where travel
events versus activities versus accommodation etc. Behind the scenes, this orchestration system would need to calculate essentials
like managing to budget, dates and times and also how long it takes to do an
activity and get to the next place - especially considering model of transport
(walking from one place to another may be faster and more interesting than
catching a train or a bus or taxi). At this level, the user would need the ability to provide feedback - removing
items that are not of interest, giving feedback on various items or,
potentially selecting between a couple of heavily curated options. The user should also have some degree of “what if” scenario planning evident.
For example showing an alternative set of arrangements if the weather turns too
hot, or is pouring with rain etc. This could also extend to doing things like
dialling down the eating out budget but dialling up the amount spent on
activities. For instance, if my budget is $2,000 total, can the agent adjust accommodation
costs to free up money for a day trip or a special dining experience? This
requires an interface that clearly communicates tradeoffs. This is something
far more nuanced and detailed than a chat thread. Having an approach like this would also provide a live interface into the
workings of the system that would enable those crucial iteration steps that are
needed when you build a travel itinerary. Looks good. Book it for me… The real killer part of this will be making all the reservations and booking
things in one go for the user. Some of this can easily be done by API
(flights, rail, hotels and some restaurants or activities). Other parts will be
much more troublesome. Some text to speech might help here, with the booking agent able to call a
location on a user’s behalf and ask to book in for them. [Google did try this a
couple of years ago](https://support.google.com/business/answer/7690269?hl=en)
and got pushback, however I suspect there were [still enough glitches in turn
taking](https://www.theverge.com/2019/5/9/18538194/google-duplex-ai-restaurants-experiences-review-robocalls),
responsiveness and interpretation that it wasn’t really ready. Another year or
so will likely see this being good enough that any place that takes bookings
over a phone but not web could accept this. Similarly, an agent being able to navigate a custom booking system would also
be a requirement here due to venues potentially having rolled their own or
using something that is local to their market but isn’t so common it is well
defined. Side quirks such as dealing with providing additional information for an
experience (eg weight if you’re doing hang gliding or skydiving) would be
interesting weird things an agent would need to surface back to the user to get
feedback on before being able to commit to the booking. There’s huge privacy and liability implications in all of this as well. Any
tooling would have to have a huge amount of personal information available to
it to handle the myriad questions it may have to answer. There may be some
liability issues to tackle around misbookings or booking something the user is
ineligible for (eg booking a concession ticket when they don’t meet the local
criteria for it). Finally, handling exceptions to all of the above in a clean way that doesn’t
overwhelm the user would go a long way to opening this up. Since the disintermediation of the travel industry by digital technology, we’ve
now got two generations of travellers who have never used a travel agent to
book anything and had to DIY all of their travel entirely. We’re on the cusp of
being able to have better assistance and to make the organisation of travel
easier again for individual users but there’s still some work to be done. I think we’ll have some time to wait for all of this to come together but I
also feel that we’re likely to see some further advances on tools that we
already use. Persona driven, dynamic itinerary creation would be an
interesting, valuable addition to start and this might be the step that really
changes the way we organise our travel. For the moment, we’re likely to see incremental change - better trip planning
UIs and agentic tools that handle simple bookings seamlessly. As each piece
drops into place, travel may go through a revolution gradually… and then
suddenly.","['agents', 'ai', 'business', 'growth', 'innovation', 'predictions', 'strategy']","['business', 'ai', 'agents', 'strategy', 'growth']","[0.6074443296920071, 0.6062547853776808, 0.5871367558999562, 0.5845157394339895, 0.5796474615786626]",[],[],[],[],True,7
2025-06-26-hands-on-gemini-cli.md,Hands on with Gemini CLI,"['agents', 'ai', 'development', 'generative ai']","Hands on with Gemini CLI
It seems like the CLI-based agents are coming in thick and fast now with
[Google finally catching
up](https://blog.google/technology/developers/introducing-gemini-cli-open-source-ai-agent/)
to [Claude Code](https://docs.anthropic.com/en/docs/claude-code/overview) from
Anthropic and [Codex CLI](https://github.com/openai/codex) from OpenAI. And
that’s not to mention the adjacent world that lives in the IDE courtesy of
[GitHub](https://github.blog/news-insights/product-news/github-copilot-meet-the-new-coding-agent/),
[Cursor](https://www.cursor.com/), [Windsurf](https://windsurf.com/) and
[others](https://ampcode.com/). Since [I/O in May](https://io.google/2025/), Google has been emitting a steady
stream of PR releases on various AI tools and products they are making
available. The cynic in me feels this is all about Google trying to convince
the world that they are important and relevant after having been thoroughly
outpaced in the opening year or two of AI products coming to market. [AI
research at Google](https://ai.google/research/) does proceed at pace and
continues to make significant headway - but that doesn’t win  consumer
eyeballs. Today, Google released [Gemini
CLI](https://blog.google/technology/developers/introducing-gemini-cli-open-source-ai-agent/),
their command line based tooling primarily aimed at developers who want to not
just produce code, but also run commands related to it or orchestrate other
parts of their system. For me, very much a CLI-oriented developer, this feels much more aligned to my
way of working so I continue to play with these tools to see how they perform. One of my gripes with Codex CLI and Claude Code is you’re paying per token, and
trying to evaluate how many tokens you’ll need to do a task (especially with
chatty reasoning models) is almost impossible to determine ahead of time. So
it’s very unclear whether a task might cost $0.30 (very, very unlikely), $3.00
(relatively frequent) or $30.00 (not as infrequent as I’d like). In the Preview at least, Gemini CLI is more flexible, with high default usage
limits which recycle every day, and if you exceed the limit, you get dropped
down from Gemini Pro 2.5 to Gemini Flash 2.5 - a less capable but still very
good model (though this behaviour is undocumented). First tasks Set up was very [straightforward](https://github.com/google-gemini/gemini-cli). Dropping into the Gemini command line, it looks and behaves very much like
Claude Code and Codex CLI and so I started with the usual task of getting the
tool to give an overview of the application and see what it produced. ![Start up and ask some questions](../../img/posts/gemini-cli-start.png) Nothing about this task is too complex but it distills the key elements pretty
well. ![Description of the set up for this
blog](../../img/posts/gemini-cli-description.png) I put it through my usual routine, “explain this particular file” (which I know
is complicated), “look at the front end and suggest 3-4 high value
improvements”, “refactor this component to be more testable”. Against all of
this it performed exactly as I’d expect it to - it didn’t make fewer errors
than any other model, nor did it make more. Ultimately it’s on par with
everyone else. Except, we have that monster [1M token context window in
Gemini](https://ai.google.dev/gemini-api/docs/long-context). And, I’m not paying by the token during the preview. A bigger ask Let’s see if it can do something I’ve been putting off for months - modernising
an old front end application I built years ago that is very creaky. So I gave it a brief to build a new front end project in my repo; move to vite
with react and typescript, get rid of Styled Components
([RIP](https://x.com/mxstbr/status/1908201327811059926)) and refactor using CSS
modules and also remove react-redux. The plan it came up with was solid: ![Start up and ask some questions](../../img/posts/gemini-cli-plan.png) I let it start with Phase 1, which it completed without any dramas and, inside
a few mins, had everything in the right place without too much trouble. I then moved it on to Phase 2 - which proceeded remarkably smoothly… until it
didn’t. The first warning I got was seeing a 429 error (too many requests) which I
thought was weird as it wasn’t going that fast and google claimed it could go
at 60 requests per minute. Certainly visibly it wasn’t going that fast. Pausing for a minute then continuing on I then got rate limited. Apparently, in
about 10 minutes I had exhausted the daily 1K request limit for Gemini Pro
which isn’t visible in the CLI tool itself. ![Rate limited](../../img/posts/gemini-cli-rate-limit.png) Unfortunately, in the transition to Gemini Flash instead which you can continue
to use, the process got stuck in a loop that persisted and there was no way to
exit. The gemini CLI team are aware of these issues with a number of github issues
raised and they seem to be actively patching pretty quickly. So I expect these
little hiccups will resolve. That said, the bit of refactoring work I got it to do before falling over was
genuinely solid. It established a structured approach to convert components and
it proceeded methodically, it just burnt a tonne of requests doing it and then
didn’t quite have the methods to handle that failure. Several months ago even I’d have never even attempted something this complex as
a brief - even just the component refactor is over 100 individual components
needing changes and management. So the baseline expectation of what these tools
can do is still moving upwards rapidly. Final thoughts on Gemini CLI My core grumble with these tools, is that it’s almost impossible to understand
how many tokens / requests are going to get burnt executing the task and what
the recovery mode is when it does. In many cases the people using these tools
are either getting free tokens (ie staff) or have no budget constraints (ie
burning someone else’s money) - visibility over this side is critical to drive
better adoption and cost prediction. What I’d love to see from Gemini CLI is the ability to simply throttle all the
way back and then pick up the task when the request limit refreshes. Better
yet, being able to gracefully suspend then restore to run at a later point from
where it left off would be great. Will I keep using Gemini CLI? Yes, definitely for smaller, self-contained under
my orchestration. Even with the limits, the time saved makes it worthwhile. A weekend project might be to find another problem to throw at that wild
1M-token context window and see how it goes.","['agents', 'ai', 'development', 'generative ai']","['development', 'ai', 'generative ai', 'agents', 'web']","[0.6343463137904906, 0.6115809044751209, 0.5917190522668905, 0.5871001733323548, 0.326866125627965]",['web'],[],[],[],True,4
2025-07-02-qantas-breach-toxic-waste.md,The Qantas breach proves personal data is toxic waste,"['business', 'privacy', 'security']","The Qantas breach proves personal data is toxic waste
Data breaches come with such regularity now, that getting annoyed about any
one in particular feels nonsensical. That said, while the frequency may be
increasing, we can't accept this becoming normal. We’ve hit the point where essentially no personal information given to a
business can be considered secure, and that it’s only a matter of time before a
breach occurs. This doesn't mean surrendering and letting bad actors run
roughshod, it means managing this risk as though this is the case. It wasn’t really a surprise then, that this week Australia’s flagship airline,
Qantas, [announced that they had a data
breach](https://www.qantas.com/au/en/support/information-for-customers-on-cyber-incident.html)
that affected 6M customers. In the grand scheme of the hundreds of millions of
people affected in recent breaches, this barely ranks at all. Even in Australian
terms it’s not an [Optus](https://en.wikipedia.org/wiki/2022_Optus_data_breach)
or a [Medibank](https://en.wikipedia.org/wiki/Medibank#2022_cyberattack) in
terms of scale. Exhibiting a bit of gallows humour, as I was about 99% confident my details
would be in the data, I took to
[BlueSky](https://bsky.app/profile/ajfisher.social/post/3lswvoeq7o22w) and
[LinkedIn](https://www.linkedin.com/posts/andrewfisher_privacy-qantas-security-activity-7345975837722034178-_IzI/)
to note that Qantas would now work through the “Data Breach PR Playbook”: Acknowledge the incident (only because of the [mandatory breach disclosure
laws from 2018](https://www.oaic.gov.au/privacy/notifiable-data-breaches)) Downplay the impact of the data loss (no credit card, passport info of
passwords leaked) Send out some comms to affected customers that reiterates the above but adds
""be on the alert for scams that look like they are from us"". (What I called
""hearts and minds"" comms). The dismissiveness regarding personal information that accompanies this
playbook irritates me no end. In 2025, changing a password or blocking and reissuing a Credit Card are so
trivial as to almost be a non-event for most people. However, information like my name and date of birth are effectively immutable
and, in a highly digitised economy like Australia, being forced to change my
phone number or email address is going to affect everything from my utility
bills, to notifications from my kid's school to contact details with my doctor.
Changing them is possible, but it’s practically very difficult and time
consuming - with big implications when I do. ![Email from Qantas about the breach](../../img/posts/qantas_breach_letter.png)
*Screenshot of email sent from Qantas about data breach* When it came time to issuing their statement to affected customers a few hours
later, Qantas even doubled down on this message, reiterating that no card
details or passwords had been stolen. They mentioned the other points that had
been lost in passing (and only really because the law forces you to have to say
what was disclosed). Proliferating fraud potential Yes, credit card numbers and identity theft are real problems, and cost the
community a huge amount annually. But in terms of fraud, this is becoming small
beer. [Targeted, sophisticated, personalised
scams](https://en.wikipedia.org/wiki/Pig_butchering_scam) are now estimated to
be worth hundreds of billions (yes, with a B) of dollars a year and growing. And
that could be underestimated. These scams don’t require credit card numbers or identity - what they
require is trust and connection. With a data breach of this type, information like date of birth
allows scammers to do segmentation and potentially target messaging
at particular cohorts in different ways to maximise effect (eg a professional
connection vs a potential love interest). ![Illustration of a scammer building up a target](../../img/posts/scammer.png)
*The more data for personalisation the better for scammers. (cc) ajfisher - Flux.Dev* This data, along with that from other breaches, adds to the potential detail a
scammer can draw on to craft a plan to make contact with, then swindle their
intended victim. Downplaying the importance of these details being breached is an absolution of
responsibility on behalf of the company who held that data in the first place.
However, it also doesn’t alert the customer to the potential implications of
this data being leaked, and disempowers them in the ongoing fight against scams. Not withstanding more sophisticated scams, the ability of fraudsters to build a
replica of the Qantas rewards store to capture login credentials is virtually
trivial. These could then be used to login as a customer, redeem their points
against gift cards and then be launder them for cash - a potentially
lucrative pay day with almost zero recourse. Personal data is toxic waste The teams I work with get sick of me talking about this. We might need to
capture personal information to facilitate outcomes via digital platforms (eg
you will need to fill in your personal info if you want something shipped from
an online store) - but only capture what is necessary and only send it as far
as is required. Yes, there are tradeoffs inherent in this decision but in many organisations
the desire for more data, ""just in case"", is a powerful force driving that
discussion. ![Data is a form of toxic byproduct](../../img/posts/data_waste.png)
*Consider long term PII as a toxic byproduct of our systems* Qantas clearly care about the security of personal information so much that
they let a third party have access (noted by them) to personal details of 6
million customers. I suspect the reason for this is entirely mundane, and is something like
managing an outsourced contact centre to deal with customer support. This is
speculation on my part, but is not uncommon for many enterprises in my experience. Given 6 million records is probably the full active base of customers Qantas
have, why would a third party need access to all of that information? Why are
the whole customer records being synced? Even assuming it’s a customer contact automation platform of some type (eg
Salesforce), why would there be a level of access that could cause that type of
breach? And why that level of personal information stored in it (such as dates
of birth)? These will be some of the questions that need to be answered as part of this
process - though I suspect they won't be tackled head on because orgs only care
about ""scary"" details like passport numbers, credit card details and passwords
due to customer perception that this is ""serious"". Personal data storage needs a rethink If you design systems assuming that eventually they may be breached, your
design decisions fundamentally change. This assumption starts a different line of questioning regarding what happens
if a breach occurs in a system. Organisations need to completely rethink their privacy and data storage
practices and orient towards an assumption of disclosure and the implications
of that, rather than the mistaken belief they can protect all data in all
systems all the time. This is provably incorrect. If you adopt this mindset then the design of your system changes: The best security of personal information is not capturing it in the first
place. Do you actually need this data and if so, what for? Expire and then purge data when it’s no longer needed (compliance and
regulatory requirements may drive the timing of this). If the process
requiring the data is finished, why hang on to it? Tokenise sensitive data, refer to it and then use it “just in time” to do the
action you require. Why do we need someone’s email address in every system?
Why not hold a reference to an encrypted version instead right up to the
point of sending an email. Privacy by design takes more effort up front and requires architectural
discipline to achieve in a meaningful way across the enterprise. Likewise, many
vendors need to support things like just in time token exchange in their
systems. But, just because something is hard, doesn’t mean it isn’t worthwhile. It is becoming increasingly rare for major data breaches of credit card
information to occur. This is a result of legislation and fines, ensuring that
businesses are taking this seriously as well as technology systems being
improved to no longer require storage (such as card tokenisation for repeat or
recurring purchases). The <b>improvements made relating to card security has been a sustained and
collaborative effort by all players</b> in the system. This came by recognising
that there was a problem that needed action, and then working through the detail
over long periods of time to drive the outcome. None of this stuff is easy, but as we have seen this week with Qantas and the
dismissiveness that still occurs around the disclosure of personal information,
we're still some way away from getting everyone to agree that there’s a problem
that needs solving here. I'm hopeful we'll get there eventually, and also hopeful that governments
legislate harder to create incentives for organisations to design
appropriately. In the same way that environmental and waste laws drive
organisational behaviour, if we start treating personal data as a toxic
byproduct of digital services then legislation to protect from these byproducts
makes sense. Legislation like the
[GDPR](https://en.wikipedia.org/wiki/General_Data_Protection_Regulation)
(with the teeth that come from fines) and the
[CCPA](https://en.wikipedia.org/wiki/California_Consumer_Privacy_Act) are good
examples of a starting point but need to go wider, deeper and have tough fines
so the calculus of deterrence makes sense for companies to take action.","['business', 'privacy', 'security']","['business', 'security', 'privacy', 'web', 'rant']","[0.6230435447258529, 0.5995996814765618, 0.5867791392071053, 0.3226728371061907, 0.3087578491256337]","['rant', 'web']",[],[],[],True,3
2025-11-05-strategy-ai.md,Strategy is still a human activity,"['ai', 'business', 'growth', 'innovation', 'strategy']","Strategy is still a human activity
For someone who spends a lot of time working with AI and building AI / ML
systems, the last week was almost the complete opposite. It was all travel,
presentations and workshops with various clients and being deep in the messy
work of innovation and strategy. AI had a role to play in some of the prep work, and definitely helped with
note-taking, summarisation, concept tagging afterwards. However, the act of
getting a bunch of smart domain experts in a room, with decades of collective
experience, to test out ideas, debate approaches and to shape strategy is still
an area where humans excel. Some AI maximalists are probably thinking, ""sure, but I can have multiple
agents collaborate and compete to develop strategy in a simulation"". Yes, you
can - and I'm working on tools that do exactly that. However, just as an LLM
produces beige content when unguided, these tools can augment the process but
can’t replicate the intuitive leaps that happen when high-performing teams
tackle big challenges together. There's also a point here about colocation and synchrony. You can Teams-meet
all you like, and for routine work that's perfectly fine. But for deep,
creative or strategic work get your best brains in a room, without
distractions, and have them spark off each other in unexpected ways. As more AI assistance rolls through orgs, I'd like to see more focus not just
on automating  the low-value work (capturing minutes, tracking actions), but
also on amplifying the high value work. For example, imagine AI tools that support facilitators by spotting topics that
haven’t had enough airtime, reducing recency bias, or ensuring everyone’s voice
is heard. Great facilitators do this instinctively, but not every team has
access to that skill. Likewise, tools that automatically cluster concepts and
opportunities could be useful timesavers (the
way [Figma FigJam](https://www.figma.com/figjam/) does when it's behaving). While I’m definitely pro-AI and want to see broader, smarter adoption across
organisations, I’m also firmly pro-human and especially pro-creativity. The
future I want to see is one where AI removes the toil and gives teams more time
for creative, highly rewarding, and impactful work.","['ai', 'business', 'growth', 'innovation', 'strategy']","['ai', 'business', 'growth', 'strategy', 'innovation']","[0.6257552143775289, 0.6204033764946703, 0.6038065562205922, 0.6035523896768117, 0.5954091806215474]",[],[],[],[],True,5
